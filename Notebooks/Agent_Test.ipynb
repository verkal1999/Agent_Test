{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaebad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein Zustandsautomat (auch endlicher Automat genannt) ist ein mathematisches Modell, das aus einer endlichen Anzahl von Zuständen besteht und durch definierte Übergänge zwischen diesen Zuständen auf Eingaben reagiert. Er wird häufig verwendet, um Abläufe oder das Verhalten von Systemen eindeutig und formal zu beschreiben.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1) Key aus Datei lesen (nur der Key in einer Zeile)\n",
    "key_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MA\\OpenAI_API_Key.txt\")\n",
    "api_key = key_path.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "# Optional: simple Plausibilitätsprüfung\n",
    "if not api_key or not any(api_key.startswith(p) for p in (\"sk-\", \"sk-proj-\")):\n",
    "    raise ValueError(\"API-Key in der Datei wirkt ungültig (Präfix fehlt).\")\n",
    "\n",
    "# 2) Client mit Key initialisieren\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 3) Testaufruf (Responses API, empfohlen)\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    input=\"Erkläre in 2 Sätzen, was ein Zustandsautomat ist – auf Deutsch.\"\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddd7121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objekt-Typen:\n",
      "  GVL: 7\n",
      "  POU: 50\n",
      "\n",
      "Beispiele je Typ:\n",
      "\n",
      "== GVL ==\n",
      "- GVL -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\GVLs\\GVL.TcGVL\n",
      "- GVL_Diagnose -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\GVLs\\GVL_Diagnose.TcGVL\n",
      "- GVL_HRL -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\GVLs\\GVL_HRL.TcGVL\n",
      "- GVL_MBS -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\GVLs\\GVL_MBS.TcGVL\n",
      "- GVL_SST -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\GVLs\\GVL_SST.TcGVL\n",
      "\n",
      "== POU ==\n",
      "- AutomaticColorDetection_nichtfertig  [FunctionBlock/NWL]  IO(in=7, out=3, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\POUs\\AtomicSkillsSchablonen\\AutomaticColorDetection_nichtfertig.TcPOU\n",
      "- AxisControl_MultipleInputSensors  [FunctionBlock/NWL]  IO(in=10, out=6, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\POUs\\AtomicSkillsSchablonen\\AxisControl_MultipleInputSensors.TcPOU\n",
      "- AxisControl_Encoder  [FunctionBlock/NWL]  IO(in=13, out=3, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\POUs\\AtomicSkillsSchablonen\\AxisControl_Encoder.TcPOU\n",
      "- CompressorControl  [FunctionBlock/NWL]  IO(in=23, out=3, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\POUs\\AtomicSkillsSchablonen\\CompressorControl.TcPOU\n",
      "- SecuringWorkpiece  [FunctionBlock/NWL]  IO(in=7, out=3, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\SPS_Demonstrator\\POUs\\AtomicSkillsSchablonen\\SecuringWorkpiece.TcPOU\n",
      "\n",
      "Summary: PLCProjs=1, Objects=57, ST-POUs=1\n",
      "\n",
      "Export:\n",
      " - C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0_objects.json\n",
      " - C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0_pous_st.json\n",
      "\n",
      "--- ST-POU IO-Details (erste 3) ---\n",
      "\n",
      "POU FB_MyOpcUaMethod (FunctionBlock)\n",
      "  VAR_INPUT:\n",
      "    - in1: INT\n",
      "    - in2: INT\n",
      "  VAR_OUTPUT:\n",
      "    - result: INT\n",
      "  VAR_IN_OUT:\n"
     ]
    }
   ],
   "source": [
    "# TwinCAT: POUs/DUTs/GVLs/VISUs sammeln + ST-IO-Variablen extrahieren (Jupyter-ready)\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import re, json, xml.etree.ElementTree as ET\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def read_text(p: Path) -> str:\n",
    "    return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "def strip_ns(xml_text: str) -> str:\n",
    "    # Default-Namespaces entfernen -> XPath wird einfacher\n",
    "    return re.sub(r'\\sxmlns=\"[^\"]+\"', '', xml_text, count=1)\n",
    "\n",
    "def strip_st_comments(s: str) -> str:\n",
    "    # ST-Kommentare entfernen: (* ... *) und // ...\n",
    "    s = re.sub(r'\\(\\*.*?\\*\\)', '', s, flags=re.S)\n",
    "    s = re.sub(r'//.*', '', s)\n",
    "    return s\n",
    "\n",
    "def detect_impl_lang(impl_node):\n",
    "    \"\"\"Finde ST/FBD/LD/SFC/IL auch wenn ein NWL-Container dazwischen sitzt.\"\"\"\n",
    "    if impl_node is None:\n",
    "        return None, \"\"\n",
    "    for tag in (\"ST\", \"FBD\", \"LD\", \"SFC\", \"IL\"):\n",
    "        n = impl_node.find(f\".//{tag}\")\n",
    "        if n is not None:\n",
    "            return tag, (n.text or \"\").strip()\n",
    "    # Fallback: erster Child-Tagname (z. B. 'NWL')\n",
    "    if list(impl_node):\n",
    "        c = list(impl_node)[0]\n",
    "        return c.tag, (c.text or \"\").strip()\n",
    "    return None, \"\"\n",
    "\n",
    "# ---------- IEC/ST Deklarationsparser ----------\n",
    "_var_stmt_re = re.compile(\n",
    "    r'^\\s*([A-Za-z_]\\w*)'               # Name\n",
    "    r'(?:\\s+AT\\s+([^:]+))?'             # optional AT-Adresse\n",
    "    r'\\s*:\\s*'                          \n",
    "    r'([^:=;]+?)'                       # Typ (inkl. ARRAY[..] OF ...)\n",
    "    r'(?:\\s*:=\\s*([^;]+?))?'            # optional Initialwert\n",
    "    r'\\s*;\\s*$', re.M | re.S)\n",
    "\n",
    "def _extract_var_block(text: str, scope_keyword: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extrahiert Variablen aus einem Block VAR_<SCOPE> ... END_VAR.\n",
    "    scope_keyword: 'INPUT' | 'OUTPUT' | 'IN_OUT' | 'GLOBAL' | 'TEMP' | etc.\n",
    "    \"\"\"\n",
    "    txt = strip_st_comments(text)\n",
    "    # Nicht-gierige Suche inkl. evtl. Zusätzen wie CONSTANT/RETAIN nach VAR_<SCOPE>\n",
    "    m = re.search(rf'VAR_{scope_keyword}\\b.*?\\n(.*?)END_VAR', txt, flags=re.S | re.I)\n",
    "    if not m:\n",
    "        return []\n",
    "    block = m.group(1)\n",
    "    vars_ = []\n",
    "    # Auf Semikolons getrimmt parsen\n",
    "    for m2 in _var_stmt_re.finditer(block):\n",
    "        name, at_addr, typ, init = [g.strip() if g else None for g in m2.groups()]\n",
    "        vars_.append({\n",
    "            \"name\": name,\n",
    "            \"address\": at_addr,\n",
    "            \"type\": re.sub(r'\\s+', ' ', typ).strip(),\n",
    "            \"init\": init.strip() if init else None\n",
    "        })\n",
    "    return vars_\n",
    "\n",
    "def extract_io_from_declaration(declaration: str) -> dict:\n",
    "    \"\"\"Liest IO-Variablen aus der ST-Deklaration.\"\"\"\n",
    "    return {\n",
    "        \"inputs\": _extract_var_block(declaration, \"INPUT\"),\n",
    "        \"outputs\": _extract_var_block(declaration, \"OUTPUT\"),\n",
    "        \"inouts\": _extract_var_block(declaration, \"IN_OUT\"),\n",
    "        # Optional: lokale Blöcke, falls gewünscht\n",
    "        \"temps\": _extract_var_block(declaration, \"TEMP\"),\n",
    "    }\n",
    "\n",
    "# ---------- Parser für TwinCAT-XML ----------\n",
    "def parse_tc_pou_anylang(pou_path: Path):\n",
    "    txt = read_text(pou_path)\n",
    "    root = ET.fromstring(strip_ns(txt))\n",
    "\n",
    "    pou = root.find(\".//POU\")\n",
    "    name = pou.get(\"Name\") if pou is not None else pou_path.stem\n",
    "\n",
    "    # Typ (Program / FunctionBlock / Function)\n",
    "    ptype = (pou.get(\"POUType\") if pou is not None else \"\") or \"\"\n",
    "    decl_node = root.find(\".//Declaration\")\n",
    "    declaration = (decl_node.text or \"\").strip() if decl_node is not None else \"\"\n",
    "    if not ptype and declaration:\n",
    "        m = re.match(r\"\\s*(PROGRAM|FUNCTION_BLOCK|FUNCTION)\\b\", declaration, re.I)\n",
    "        ptype = (m.group(1).title().replace(\"_\", \"\") if m else \"\")\n",
    "\n",
    "    impl_node = root.find(\".//Implementation\")\n",
    "    lang_tag, impl_text = detect_impl_lang(impl_node)\n",
    "\n",
    "    io = extract_io_from_declaration(declaration) if declaration else {\"inputs\":[], \"outputs\":[], \"inouts\":[], \"temps\":[]}\n",
    "\n",
    "    return {\n",
    "        \"kind\": \"POU\",\n",
    "        \"name\": name,\n",
    "        \"pou_type\": ptype,                  # Program | FunctionBlock | Function\n",
    "        \"implementation_lang\": lang_tag,    # ST | FBD | LD | SFC | IL | NWL | None\n",
    "        \"declaration\": declaration,\n",
    "        \"implementation\": impl_text,        # bei FBD/LD meist leer (grafisch)\n",
    "        \"io\": io,\n",
    "        \"file\": str(pou_path)\n",
    "    }\n",
    "\n",
    "def parse_tc_dut(dut_path: Path):\n",
    "    txt = read_text(dut_path)\n",
    "    root = ET.fromstring(strip_ns(txt))\n",
    "    dut = root.find(\".//DUT\")\n",
    "    name = dut.get(\"Name\") if dut is not None else dut_path.stem\n",
    "    # Typ (STRUCT/ENUM/ALIAS/UNION) steckt i. d. R. in der Declaration\n",
    "    decl_node = root.find(\".//Declaration\")\n",
    "    declaration = (decl_node.text or \"\").strip() if decl_node is not None else \"\"\n",
    "    # heuristischer dut_kind\n",
    "    dut_kind = \"\"\n",
    "    m = re.match(r\"\\s*(TYPE\\s+)?(STRUCT|ENUM|UNION|ALIAS)\\b\", declaration, re.I)\n",
    "    if m:\n",
    "        dut_kind = m.group(2).upper()\n",
    "    return {\n",
    "        \"kind\": \"DUT\",\n",
    "        \"name\": name,\n",
    "        \"dut_kind\": dut_kind,\n",
    "        \"declaration\": declaration,\n",
    "        \"file\": str(dut_path)\n",
    "    }\n",
    "\n",
    "def parse_tc_gvl(gvl_path: Path):\n",
    "    txt = read_text(gvl_path)\n",
    "    root = ET.fromstring(strip_ns(txt))\n",
    "    gvl = root.find(\".//GVL\")\n",
    "    name = gvl.get(\"Name\") if gvl is not None else gvl_path.stem\n",
    "    decl_node = root.find(\".//Declaration\")\n",
    "    declaration = (decl_node.text or \"\").strip() if decl_node is not None else \"\"\n",
    "    # Variablen in GVL stehen üblicherweise in VAR_GLOBAL ... END_VAR\n",
    "    globals_ = _extract_var_block(declaration, \"GLOBAL\")\n",
    "    return {\n",
    "        \"kind\": \"GVL\",\n",
    "        \"name\": name,\n",
    "        \"declaration\": declaration,\n",
    "        \"globals\": globals_,\n",
    "        \"file\": str(gvl_path)\n",
    "    }\n",
    "\n",
    "def parse_tc_vis(vis_path: Path):\n",
    "    \"\"\"\n",
    "    VISU-Metadaten aus .TcVis (Seitenname). Struktur ist XML; wir lesen den Wurzelknoten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        txt = read_text(vis_path)\n",
    "        root = ET.fromstring(strip_ns(txt))\n",
    "        vis = root.find(\".//Visualization\")\n",
    "        name = (vis.get(\"Name\") if vis is not None else None) or vis_path.stem\n",
    "    except Exception:\n",
    "        name = vis_path.stem\n",
    "    return {\n",
    "        \"kind\": \"VISU\",\n",
    "        \"name\": name,\n",
    "        \"file\": str(vis_path)\n",
    "    }\n",
    "\n",
    "# ---------- .plcproj Utilities ----------\n",
    "def list_artifacts_in_plcproj(plcproj: Path):\n",
    "    \"\"\"\n",
    "    Sucht referenzierte .TcPOU/.TcDUT/.TcGVL/.TcVis und zusätzlich inline-Objekte im .plcproj.\n",
    "    \"\"\"\n",
    "    txt = strip_ns(read_text(plcproj))\n",
    "    root = ET.fromstring(txt)\n",
    "    out = []\n",
    "\n",
    "    # 1) Referenzen in ItemGroups\n",
    "    for item in root.findall(\".//ItemGroup/*\"):\n",
    "        inc = item.get(\"Include\") or \"\"\n",
    "        inc_l = inc.lower()\n",
    "        p = (plcproj.parent / inc).resolve()\n",
    "\n",
    "        try:\n",
    "            if inc_l.endswith(\".tcpou\") and p.exists():\n",
    "                out.append(parse_tc_pou_anylang(p))\n",
    "            elif inc_l.endswith(\".tcdut\") and p.exists():\n",
    "                out.append(parse_tc_dut(p))\n",
    "            elif inc_l.endswith(\".tcgvl\") and p.exists():\n",
    "                out.append(parse_tc_gvl(p))\n",
    "            elif inc_l.endswith(\".tcvis\") and p.exists():\n",
    "                out.append(parse_tc_vis(p))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Fehler beim Parsen {p}: {e}\")\n",
    "\n",
    "    # 2) Inline-POUs/GVLs/DUTs (falls Multiple Project Files nicht aktiv war)\n",
    "    for pou in root.findall(\".//POU\"):\n",
    "        name = pou.get(\"Name\") or \"\"\n",
    "        ptype = pou.get(\"POUType\") or \"\"\n",
    "        decl = pou.find(\".//Declaration\")\n",
    "        impl = pou.find(\".//Implementation\")\n",
    "        lang_tag, impl_text = detect_impl_lang(impl)\n",
    "        declaration = (decl.text or \"\").strip() if decl is not None else \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"POU\",\n",
    "            \"name\": name,\n",
    "            \"pou_type\": ptype,\n",
    "            \"implementation_lang\": lang_tag,\n",
    "            \"declaration\": declaration,\n",
    "            \"implementation\": impl_text,\n",
    "            \"io\": extract_io_from_declaration(declaration) if declaration else {\"inputs\":[], \"outputs\":[], \"inouts\":[], \"temps\":[]},\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "    for gvl in root.findall(\".//GVL\"):\n",
    "        name = gvl.get(\"Name\") or \"\"\n",
    "        decl = gvl.find(\".//Declaration\")\n",
    "        declaration = (decl.text or \"\").strip() if decl is not None else \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"GVL\",\n",
    "            \"name\": name,\n",
    "            \"declaration\": declaration,\n",
    "            \"globals\": _extract_var_block(declaration, \"GLOBAL\"),\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "    for dut in root.findall(\".//DUT\"):\n",
    "        name = dut.get(\"Name\") or \"\"\n",
    "        decl = dut.find(\".//Declaration\")\n",
    "        declaration = (decl.text or \"\").strip() if decl is not None else \"\"\n",
    "        m = re.match(r\"\\s*(TYPE\\s+)?(STRUCT|ENUM|UNION|ALIAS)\\b\", declaration, re.I)\n",
    "        dut_kind = m.group(2).upper() if m else \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"DUT\",\n",
    "            \"name\": name,\n",
    "            \"dut_kind\": dut_kind,\n",
    "            \"declaration\": declaration,\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "    # VISUs sind selten inline; falls vorhanden:\n",
    "    for vis in root.findall(\".//Visualization\"):\n",
    "        name = vis.get(\"Name\") or \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"VISU\",\n",
    "            \"name\": name,\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "def find_tsprojs_in_sln(sln_path: Path):\n",
    "    txt = read_text(sln_path)\n",
    "    tsprojs = []\n",
    "    for m in re.finditer(r'Project\\(\".*?\"\\)\\s=\\s*\".*?\",\\s*\"(.*?)\"', txt):\n",
    "        rel = m.group(1)\n",
    "        if rel.lower().endswith(\".tsproj\"):\n",
    "            tsprojs.append((sln_path.parent / rel).resolve())\n",
    "    return tsprojs\n",
    "\n",
    "def find_plcprojs_near(tsproj: Path):\n",
    "    return list(tsproj.parent.rglob(\"*.plcproj\"))\n",
    "\n",
    "# ---------- Pfad zu DEINER SLN ----------\n",
    "sln_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0.sln\")\n",
    "\n",
    "# ---------- Sammeln ----------\n",
    "tsprojs = find_tsprojs_in_sln(sln_path)\n",
    "plcprojs = []\n",
    "for ts in tsprojs:\n",
    "    plcprojs.extend(find_plcprojs_near(ts))\n",
    "plcprojs = sorted(set(plcprojs))\n",
    "\n",
    "all_objs = []\n",
    "for pp in plcprojs:\n",
    "    try:\n",
    "        all_objs.extend(list_artifacts_in_plcproj(pp))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Fehler beim Parsen {pp}: {e}\")\n",
    "\n",
    "# ---------- Auswertung ----------\n",
    "kinds = Counter([o.get(\"kind\") for o in all_objs])\n",
    "print(\"Objekt-Typen:\")\n",
    "for k, v in kinds.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Beispiele je Typ\n",
    "by_kind = defaultdict(list)\n",
    "for o in all_objs:\n",
    "    by_kind[o.get(\"kind\")].append(o)\n",
    "\n",
    "print(\"\\nBeispiele je Typ:\")\n",
    "for kind, items in by_kind.items():\n",
    "    print(f\"\\n== {kind} ==\")\n",
    "    for o in items[:5]:  # max 5 Beispiele\n",
    "        if kind == \"POU\":\n",
    "            io = o.get(\"io\", {})\n",
    "            io_sum = f\"in={len(io.get('inputs',[]))}, out={len(io.get('outputs',[]))}, inout={len(io.get('inouts',[]))}\"\n",
    "            print(f\"- {o['name']}  [{o.get('pou_type','?')}/{o.get('implementation_lang') or '—'}]  IO({io_sum}) -> {o['file']}\")\n",
    "        elif kind == \"DUT\":\n",
    "            print(f\"- {o['name']}  [{o.get('dut_kind') or '—'}] -> {o['file']}\")\n",
    "        else:\n",
    "            print(f\"- {o['name']} -> {o['file']}\")\n",
    "\n",
    "# Nur POUs mit ST-Implementation zeigen + deren IO-Variablen\n",
    "st_pous = [o for o in all_objs if o.get(\"kind\")==\"POU\" and (o.get(\"implementation_lang\") or \"\").upper()==\"ST\"]\n",
    "print(f\"\\nSummary: PLCProjs={len(plcprojs)}, Objects={len(all_objs)}, ST-POUs={len(st_pous)}\")\n",
    "\n",
    "# Optional: Dateien schreiben (JSONs neben der SLN)\n",
    "out_base = sln_path.with_suffix(\"\")\n",
    "Path(str(out_base) + \"_objects.json\").write_text(json.dumps(all_objs, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "Path(str(out_base) + \"_pous_st.json\").write_text(json.dumps(st_pous, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"\\nExport:\")\n",
    "print(\" -\", str(out_base) + \"_objects.json\")\n",
    "print(\" -\", str(out_base) + \"_pous_st.json\")\n",
    "\n",
    "# Beispielhafte Ausgabe der IO-Listen und ST-Implementierung (gekürzt) für die ersten 3 ST-POUs\n",
    "print(\"\\n--- ST-POU IO-Details (erste 3) ---\")\n",
    "for o in st_pous[:3]:\n",
    "    print(f\"\\nPOU {o['name']} ({o.get('pou_type','?')})\")\n",
    "    io = o[\"io\"]\n",
    "    for label, lst in [(\"VAR_INPUT\", io[\"inputs\"]), (\"VAR_OUTPUT\", io[\"outputs\"]), (\"VAR_IN_OUT\", io[\"inouts\"])]:\n",
    "        print(f\"  {label}:\")\n",
    "        for v in lst:\n",
    "            addr = f\" @ {v['address']}\" if v['address'] else \"\"\n",
    "            init = f\" := {v['init']}\" if v['init'] else \"\"\n",
    "            print(f\"    - {v['name']}: {v['type']}{addr}{init}\")\n",
    "    # ST-Code (falls vorhanden) leicht gekürzt\n",
    "    impl = (o.get(\"implementation\") or \"\").strip()\n",
    "    if impl:\n",
    "        preview = impl if len(impl) < 800 else impl[:800] + \"\\n... [gekürzt] ...\"\n",
    "        print(\"\\n  ST-Implementation (Preview):\\n\" + preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efbfdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene PLC-Projekte: ['TIPC^SPS_Demonstrator^SPS_Demonstrator Project']\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "\n",
    "# 1) JSON einlesen\n",
    "json_path = pathlib.Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0_objects.json\")\n",
    "with json_path.open(encoding=\"utf-8\") as f:\n",
    "    objects = json.load(f)\n",
    "\n",
    "plc_names = set()\n",
    "\n",
    "# 2) Für jedes Artefakt den Elternordner durchsuchen, bis .plcproj gefunden wird\n",
    "for obj in objects:\n",
    "    fpath = pathlib.Path(obj[\"file\"])\n",
    "    # inline-Einträge haben \" (inline)\" am Ende, deshalb originalen Pfad extrahieren\n",
    "    try:\n",
    "        fpath = pathlib.Path(fpath.as_posix().split(\" (inline)\")[0])\n",
    "    except Exception:\n",
    "        pass\n",
    "    for parent in fpath.parents:\n",
    "        for plcproj in parent.glob(\"*.plcproj\"):\n",
    "            plc_names.add(plcproj.stem)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "# 3) Aus PLC-Namen Lookup-Pfade bauen\n",
    "lookup_paths = [f\"TIPC^{name}^{name} Project\" for name in sorted(plc_names)]\n",
    "print(\"Gefundene PLC-Projekte:\", lookup_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987dbb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywin32 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (311)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc5925c",
   "metadata": {},
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Ausnahmefehler aufgetreten.', (0, 'TwinCATPlcControlx64', \"File 'C:\\\\Users\\\\Alexander Verkhov\\\\OneDrive\\\\Dokumente\\\\MPA\\\\twincat2\\\\TwinCAT\\\\export.xml' already exists!\\r\\nParametername: bstrFile\", None, 0, -2147024809), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mcom_error\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# PLCopen-Export ausführen:contentReference[oaicite:2]{index=2}\u001b[39;00m\n\u001b[32m     50\u001b[39m import_export = plc_project          \u001b[38;5;66;03m# impliziter Cast zu ITcPlcIECProject\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mimport_export\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPlcOpenExport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_xml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mXML-Export erstellt:\u001b[39m\u001b[33m\"\u001b[39m, export_xml)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<COMObject LookupTreeItem>:2\u001b[39m, in \u001b[36mPlcOpenExport\u001b[39m\u001b[34m(self, bstrFile, bstrSelection)\u001b[39m\n",
      "\u001b[31mcom_error\u001b[39m: (-2147352567, 'Ausnahmefehler aufgetreten.', (0, 'TwinCATPlcControlx64', \"File 'C:\\\\Users\\\\Alexander Verkhov\\\\OneDrive\\\\Dokumente\\\\MPA\\\\twincat2\\\\TwinCAT\\\\export.xml' already exists!\\r\\nParametername: bstrFile\", None, 0, -2147024809), None)"
     ]
    }
   ],
   "source": [
    "import json, pathlib, win32com.client as com\n",
    "\n",
    "# ----------------- PLC-Namen aus der JSON (siehe oben) -----------------\n",
    "json_path = pathlib.Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0_objects.json\")\n",
    "with open(json_path, encoding=\"utf-8\") as f:\n",
    "    objects = json.load(f)\n",
    "\n",
    "plc_names = set()\n",
    "for obj in objects:\n",
    "    fpath = pathlib.Path(obj[\"file\"].split(\" (inline)\")[0])\n",
    "    # nach *.plcproj im Elternverzeichnis suchen\n",
    "    for parent in fpath.parents:\n",
    "        for plcproj in parent.glob(\"*.plcproj\"):\n",
    "            plc_names.add(plcproj.stem)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "lookup_paths = [f\"TIPC^{name}^{name} Projekt\" for name in sorted(plc_names)]\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# TwinCAT-Projekt öffnen\n",
    "sln_path   = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0.sln\"\n",
    "export_xml = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\export.xml\"\n",
    "\n",
    "dte = com.Dispatch(\"TcXaeShell.DTE.17.0\")  # Version ggf. anpassen\n",
    "dte.SuppressUI = False\n",
    "dte.MainWindow.Visible = True\n",
    "solution = dte.Solution\n",
    "solution.Open(sln_path)\n",
    "\n",
    "# SystemManager aus dem TwinCAT-Projekt holen:contentReference[oaicite:1]{index=1}\n",
    "project = solution.Projects.Item(1)  # erstes TwinCAT-Projekt\n",
    "sys_mgr = project.Object             # SystemManager-Instanz\n",
    "\n",
    "# passenden PLC-Knoten finden\n",
    "plc_project = None\n",
    "for path in lookup_paths:\n",
    "    try:\n",
    "        plc_project = sys_mgr.LookupTreeItem(path)\n",
    "        break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if plc_project is None:\n",
    "    raise RuntimeError(f\"Kein PLC-Projekt gefunden – prüfen Sie Namen: {plc_names}\")\n",
    "\n",
    "# PLCopen-Export ausführen:contentReference[oaicite:2]{index=2}\n",
    "import_export = plc_project          # impliziter Cast zu ITcPlcIECProject\n",
    "import_export.PlcOpenExport(export_xml, \"\")\n",
    "print(\"XML-Export erstellt:\", export_xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f929e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "NS = {'ns': 'http://www.plcopen.org/xml/tc6_0200'}\n",
    "\n",
    "def parse_io_vars(pou):\n",
    "    \"\"\"Liefert Listen der deklarierten Inputs und Outputs aus der Interface-Sektion eines POU.\"\"\"\n",
    "    inputs, outputs = [], []\n",
    "    interface = pou.find('ns:interface', NS)\n",
    "    if interface is not None:\n",
    "        input_vars = interface.find('ns:inputVars', NS)\n",
    "        if input_vars is not None:\n",
    "            for var in input_vars.findall('ns:variable', NS):\n",
    "                name = var.attrib.get('name')\n",
    "                if name:\n",
    "                    inputs.append(name)\n",
    "        output_vars = interface.find('ns:outputVars', NS)\n",
    "        if output_vars is not None:\n",
    "            for var in output_vars.findall('ns:variable', NS):\n",
    "                name = var.attrib.get('name')\n",
    "                if name:\n",
    "                    outputs.append(name)\n",
    "    return inputs, outputs\n",
    "\n",
    "def build_node_mapping(fbd):\n",
    "    \"\"\"Erzeugt ein Dictionary localId -> externer Ausdruck für inVariable/outVariable-Knoten.\"\"\"\n",
    "    node_expr = {}\n",
    "    for inv in fbd.findall('ns:inVariable', NS):\n",
    "        lid = inv.get('localId')\n",
    "        expr = inv.find('ns:expression', NS)\n",
    "        if lid and expr is not None and expr.text:\n",
    "            node_expr[lid] = expr.text.strip()\n",
    "    for outv in fbd.findall('ns:outVariable', NS):\n",
    "        lid = outv.get('localId')\n",
    "        expr = outv.find('ns:expression', NS)\n",
    "        if lid and expr is not None and expr.text:\n",
    "            node_expr[lid] = expr.text.strip()\n",
    "    return node_expr\n",
    "\n",
    "def extract_call_blocks(fbd, pou_names_set, node_map):\n",
    "    \"\"\"Sammelt die Aufrufe von Unterprogrammen (block.typeName in pou_names_set) und deren I/O-Mapping.\"\"\"\n",
    "    calls = []\n",
    "    for block in fbd.findall('ns:block', NS):\n",
    "        type_name = block.get('typeName')\n",
    "        if type_name and type_name in pou_names_set:\n",
    "            call_info = {\n",
    "                'SubNetwork_Name': type_name,\n",
    "                'instanceName': block.get('instanceName'),\n",
    "                'inputs': [],\n",
    "                'outputs': [],\n",
    "            }\n",
    "            # Eingänge der Subfunktion auslesen\n",
    "            for var in block.findall('ns:inputVariables/ns:variable', NS):\n",
    "                formal = var.get('formalParameter')\n",
    "                ext = None\n",
    "                cpin = var.find('ns:connectionPointIn', NS)\n",
    "                if cpin is not None:\n",
    "                    conn = cpin.find('ns:connection', NS)\n",
    "                    if conn is not None:\n",
    "                        ref = conn.get('refLocalId')\n",
    "                        if ref:\n",
    "                            ext = node_map.get(ref, f'localId:{ref}')\n",
    "                call_info['inputs'].append({'internal': formal, 'external': ext})\n",
    "            # Ausgänge der Subfunktion auslesen\n",
    "            for var in block.findall('ns:outputVariables/ns:variable', NS):\n",
    "                formal = var.get('formalParameter')\n",
    "                ext = None\n",
    "                cpout = var.find('ns:connectionPointOut', NS)\n",
    "                if cpout is not None:\n",
    "                    expr = cpout.find('ns:expression', NS)\n",
    "                    if expr is not None and expr.text:\n",
    "                        ext = expr.text.strip()\n",
    "                    else:\n",
    "                        conn = cpout.find('ns:connection', NS)\n",
    "                        if conn is not None:\n",
    "                            ref = conn.get('refLocalId')\n",
    "                            if ref:\n",
    "                                ext = node_map.get(ref, f'localId:{ref}')\n",
    "                call_info['outputs'].append({'internal': formal, 'external': ext})\n",
    "            calls.append(call_info)\n",
    "    return calls\n",
    "\n",
    "def map_pou_io_to_external(pou, node_map):\n",
    "    \"\"\"\n",
    "    Ordnet deklarierten Inputs/Outputs eines POU den externen Variablennamen zu,\n",
    "    sofern sie in den in/out-Variablen des FBD-Blocks erscheinen.\n",
    "    \"\"\"\n",
    "    inputs, outputs = parse_io_vars(pou)\n",
    "    mapped_inputs = []\n",
    "    mapped_outputs = []\n",
    "    # Reverse-Mapping: Wenn das Ausdrucks-Suffix dem internen Namen entspricht, wird es als externe Variable verwendet.\n",
    "    for inp in inputs:\n",
    "        ext = None\n",
    "        for expr in node_map.values():\n",
    "            if expr.split('.')[-1] == inp:\n",
    "                ext = expr\n",
    "                break\n",
    "        mapped_inputs.append({'internal': inp, 'external': ext})\n",
    "    for out in outputs:\n",
    "        ext = None\n",
    "        for expr in node_map.values():\n",
    "            if expr.split('.')[-1] == out:\n",
    "                ext = expr\n",
    "                break\n",
    "        mapped_outputs.append({'internal': out, 'external': ext})\n",
    "    return mapped_inputs, mapped_outputs\n",
    "\n",
    "def analyze_plcopen(xml_path):\n",
    "    \"\"\"Analysiert die PLCopen-XML und erzeugt eine Liste aus Programminformationen und Subnetz-Aufrufen.\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    pou_names = {p.attrib.get('name') for p in root.findall('.//ns:pou', NS)}\n",
    "    result = []\n",
    "    for pou in root.findall('.//ns:pou', NS):\n",
    "        name = pou.attrib.get('name')\n",
    "        fbd = pou.find('.//ns:FBD', NS)\n",
    "        node_map = build_node_mapping(fbd) if fbd is not None else {}\n",
    "        inputs, outputs = parse_io_vars(pou)\n",
    "        mapped_inputs, mapped_outputs = ([], [])\n",
    "        if fbd is not None:\n",
    "            mapped_inputs, mapped_outputs = map_pou_io_to_external(pou, node_map)\n",
    "        else:\n",
    "            mapped_inputs = [{'internal': n, 'external': None} for n in inputs]\n",
    "            mapped_outputs = [{'internal': n, 'external': None} for n in outputs]\n",
    "        subcalls = extract_call_blocks(fbd, pou_names, node_map) if fbd is not None else []\n",
    "        result.append({\n",
    "            'Programm_Name': name,\n",
    "            'inputs': mapped_inputs,\n",
    "            'outputs': mapped_outputs,\n",
    "            'subcalls': subcalls\n",
    "        })\n",
    "    return result\n",
    "\n",
    "# Beispielaufruf:\n",
    "xml_file = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\export.xml\")\n",
    "mapping = analyze_plcopen(xml_file)\n",
    "with open(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\program_io_with_mapping.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mapping, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e3bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse abgeschlossen. Ergebnisse in C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\variable_traces.json\n"
     ]
    }
   ],
   "source": [
    "import json, xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Hilfsfunktionen ===\n",
    "def base_name(expr: str) -> str:\n",
    "    return expr.split(\".\")[-1] if expr else \"\"\n",
    "\n",
    "# === Daten laden ===\n",
    "json_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\program_io_with_mapping.json\")\n",
    "xml_path  = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\export.xml\")\n",
    "\n",
    "pou_map_data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "pou_map = {entry[\"Programm_Name\"]: entry for entry in pou_map_data}\n",
    "\n",
    "# Hardwarevariablen (xDI/udiDI, xDO/udiDO) aus der export.XML auslesen:contentReference[oaicite:0]{index=0}\n",
    "NS = {\"ns\":\"http://www.plcopen.org/xml/tc6_0200\",\"html\":\"http://www.w3.org/1999/xhtml\"}\n",
    "root = ET.parse(xml_path).getroot()\n",
    "var_doc = {}    # Variable -> physische Adresse\n",
    "hw_inputs = set()\n",
    "hw_outputs = set()\n",
    "for var in root.findall(\".//ns:variable\", NS):\n",
    "    name = var.attrib.get(\"name\")\n",
    "    doc = var.find(\".//html:xhtml\", NS)\n",
    "    if doc is not None and doc.text:\n",
    "        doc_text = doc.text.strip()\n",
    "        var_doc[name] = doc_text\n",
    "        if doc_text.startswith((\"xDI\",\"udiDI\")):\n",
    "            hw_inputs.add(name)\n",
    "        elif doc_text.startswith((\"xDO\",\"udiDO\")):\n",
    "            hw_outputs.add(name)\n",
    "\n",
    "# === Variablen‑Graph erzeugen ===\n",
    "# Knoten: Variablen-Basisname; Kanten: (Program, neues Basisname)\n",
    "var_graph = defaultdict(list)\n",
    "for entry in pou_map_data:\n",
    "    pname = entry[\"Programm_Name\"]\n",
    "    # externe Eingangs- und Ausgangsvariablen sammeln\n",
    "    in_bases  = [base_name(inp[\"external\"]) for inp in entry[\"inputs\"] if inp.get(\"external\")]\n",
    "    out_bases = [base_name(out[\"external\"]) for out in entry[\"outputs\"] if out.get(\"external\")]\n",
    "    for b_in in in_bases:\n",
    "        for b_out in out_bases:\n",
    "            var_graph[b_in].append((pname, b_out))\n",
    "\n",
    "# === Rekursives Tracing von Variablen zu Hardware ===\n",
    "def find_paths(start_base, visited_bases=None, depth=0):\n",
    "    \"\"\"Gibt für eine Variable (Basisname) alle Pfade (Programmkette und Variable) bis zur HW zurück.\"\"\"\n",
    "    if visited_bases is None:\n",
    "        visited_bases = set()\n",
    "    if start_base in visited_bases:\n",
    "        return []\n",
    "    visited_bases.add(start_base)\n",
    "\n",
    "    # direkter HW‑Treffer: keine weiteren Programme\n",
    "    if start_base in hw_outputs:\n",
    "        return [[]]\n",
    "\n",
    "    paths = []\n",
    "    for prog, new_base in var_graph.get(start_base, []):\n",
    "        for sub_path in find_paths(new_base, visited_bases.copy(), depth+1):\n",
    "            paths.append([(prog, new_base)] + sub_path)\n",
    "    return paths\n",
    "\n",
    "# === Programmausgabe: Pro Programm alle Outputs und Pfade ===\n",
    "trace = {}\n",
    "for pname, entry in pou_map.items():\n",
    "    prog_outputs = []\n",
    "    for out in entry[\"outputs\"]:\n",
    "        internal = out[\"internal\"]\n",
    "        ext      = out.get(\"external\")\n",
    "        if not ext:\n",
    "            continue\n",
    "        b = base_name(ext)\n",
    "        if b in hw_outputs:\n",
    "            prog_outputs.append({\n",
    "                \"internal\": internal,\n",
    "                \"external\": ext,\n",
    "                \"hardware\": True,\n",
    "                \"paths\": [[(pname, b), {\"hardware\": var_doc.get(b)}]]\n",
    "            })\n",
    "        else:\n",
    "            chains = []\n",
    "            for path in find_paths(b):\n",
    "                chain = [{\"program\": pname, \"variable\": b}]\n",
    "                for step_prog, step_base in path:\n",
    "                    chain.append({\"program\": step_prog, \"variable\": step_base})\n",
    "                if path:\n",
    "                    last_base = path[-1][1]\n",
    "                    chain.append({\"hardware\": var_doc.get(last_base)})\n",
    "                chains.append(chain)\n",
    "            prog_outputs.append({\n",
    "                \"internal\": internal,\n",
    "                \"external\": ext,\n",
    "                \"hardware\": False,\n",
    "                \"paths\": chains\n",
    "            })\n",
    "    trace[pname] = prog_outputs\n",
    "\n",
    "# Ergebnis als JSON speichern oder weiterverarbeiten\n",
    "out_file = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\variable_traces.json\")\n",
    "out_file.write_text(json.dumps(trace, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(f\"Analyse abgeschlossen. Ergebnisse in {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8cbb901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph erfolgreich erweitert. Neues File: D:\\MA_Python_Agent\\ParamDiag_Agent_populated.ttl\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, RDF, Literal\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# Hilfsfunktionen\n",
    "def base_name(expr: str) -> str:\n",
    "    return expr.split(\".\")[-1] if expr else \"\"\n",
    "\n",
    "# Pfade anpassen\n",
    "ontology_file = Path(r\"D:\\MA_Python_Agent\\ParamDiag_Agent_populated.ttl\")  # bestehende Ontologie\n",
    "json_path     = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\program_io_with_mapping.json\")\n",
    "xml_path      = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\export.xml\")\n",
    "\n",
    "# 1) Ontologie laden\n",
    "g = Graph()\n",
    "g.parse(ontology_file, format=\"turtle\")\n",
    "\n",
    "# Namespaces definieren (müssen zur Ontologie passen)\n",
    "AG = Namespace(\"http://www.semanticweb.org/AgentProgramParams/\")\n",
    "DP = Namespace(\"http://www.semanticweb.org/AgentProgramParams/dp_\")\n",
    "g.bind(\"ag\", AG)\n",
    "g.bind(\"dp\", DP)\n",
    "\n",
    "# 2) JSON laden und XML-Dokumentation (Hardware-Adressen) auslesen\n",
    "data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "NS   = {\"ns\": \"http://www.plcopen.org/xml/tc6_0200\", \"html\": \"http://www.w3.org/1999/xhtml\"}\n",
    "root = ET.parse(xml_path).getroot()\n",
    "var_doc = {}\n",
    "for var in root.findall(\".//ns:variable\", NS):\n",
    "    name = var.attrib.get(\"name\")\n",
    "    doc  = var.find(\".//html:xhtml\", NS)\n",
    "    if name and doc is not None and doc.text:\n",
    "        var_doc[name] = doc.text.strip()\n",
    "\n",
    "# 3) Tripel hinzufügen per Graph.add()\n",
    "for entry in data:\n",
    "    p_name = entry[\"Programm_Name\"]\n",
    "    p_uri  = AG[f\"Program_{p_name}\"]\n",
    "    g.add((p_uri, RDF.type, AG.class_Program))\n",
    "\n",
    "    # Inputs\n",
    "    for inp in entry[\"inputs\"]:\n",
    "        ext = inp.get(\"external\")\n",
    "        if ext:\n",
    "            b_name  = base_name(ext)\n",
    "            v_uri   = AG[f\"Var_{b_name}\"]\n",
    "            g.add((v_uri, RDF.type, AG.class_Variable))\n",
    "            g.add((p_uri, AG.op_hasInputVariable, v_uri))\n",
    "\n",
    "    # Outputs\n",
    "    for out in entry[\"outputs\"]:\n",
    "        ext = out.get(\"external\")\n",
    "        if ext:\n",
    "            b_name  = base_name(ext)\n",
    "            v_uri   = AG[f\"Var_{b_name}\"]\n",
    "            g.add((v_uri, RDF.type, AG.class_Variable))\n",
    "            g.add((p_uri, AG.op_hasOutputVariable, v_uri))\n",
    "\n",
    "    # Subprogramme (Subcalls)\n",
    "    for sc in entry.get(\"subcalls\", []):\n",
    "        s_name = sc[\"SubNetwork_Name\"]\n",
    "        s_uri  = AG[f\"Program_{s_name}\"]\n",
    "        g.add((s_uri, RDF.type, AG.class_Program))\n",
    "        g.add((s_uri, AG.op_isSubProgramOf, p_uri))\n",
    "\n",
    "# 4) Hardware-Adressen als Dateneigenschaft hinzufügen\n",
    "for var_name, addr in var_doc.items():\n",
    "    v_uri = AG[f\"Var_{var_name}\"]\n",
    "    g.add((v_uri, AG.dp_hasHardwareAddress, Literal(addr)))\n",
    "\n",
    "# 5) Ergebnis nicht in die ursprüngliche Ontologie schreiben, sondern separat speichern\n",
    "output_file = Path(r\"D:\\MA_Python_Agent\\ParamDiag_Agent_populated.ttl\")\n",
    "g.serialize(destination=output_file, format=\"turtle\")\n",
    "print(f\"Graph erfolgreich erweitert. Neues File: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
