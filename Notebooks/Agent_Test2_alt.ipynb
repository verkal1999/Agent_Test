{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaebad5d",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1) Key aus Datei lesen (nur der Key in einer Zeile)\n",
    "key_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MA\\OpenAI_API_Key.txt\")\n",
    "api_key = key_path.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "# Optional: simple Plausibilitätsprüfung\n",
    "if not api_key or not any(api_key.startswith(p) for p in (\"sk-\", \"sk-proj-\")):\n",
    "    raise ValueError(\"API-Key in der Datei wirkt ungültig (Präfix fehlt).\")\n",
    "\n",
    "# 2) Client mit Key initialisieren\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 3) Testaufruf (Responses API, empfohlen)\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    input=\"Erkläre in 2 Sätzen, was ein Zustandsautomat ist – auf Deutsch.\"\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddd7121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objekt-Typen:\n",
      "  GVL: 2\n",
      "  POU: 8\n",
      "\n",
      "Beispiele je Typ:\n",
      "\n",
      "== GVL ==\n",
      "- GVL -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\GVLs\\GVL.TcGVL\n",
      "- OPCUA -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\GVLs\\OPCUA.TcGVL\n",
      "\n",
      "== POU ==\n",
      "- FB_Automatikbetrieb_F1  [FunctionBlock/ST]  IO(in=5, out=2, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\POUs\\FB_Automatikbetrieb_F1.TcPOU\n",
      "- FB_Betriebsarten  [FunctionBlock/NWL]  IO(in=8, out=9, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\POUs\\FB_Betriebsarten.TcPOU\n",
      "- FB_Diagnose_D2  [FunctionBlock/ST]  IO(in=1, out=2, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\POUs\\FB_Diagnose_D2.TcPOU\n",
      "- FB_InitFahrt_A6_A2  [FunctionBlock/ST]  IO(in=2, out=1, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\POUs\\FB_InitFahrt_A6_A2.TcPOU\n",
      "- FB_ProduktionMitStoerung_D3  [FunctionBlock/ST]  IO(in=1, out=2, inout=0) -> C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\Proj1\\POUs\\FB_ProduktionMitStoerung_D3.TcPOU\n",
      "\n",
      "Summary: PLCProjs=1, Objects=10, ST-POUs=7\n",
      "\n",
      "Export:\n",
      " - C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents_objects.json\n",
      " - C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents_pous_st.json\n",
      "\n",
      "--- ST-POU IO-Details (erste 3) ---\n",
      "\n",
      "POU FB_Automatikbetrieb_F1 (FunctionBlock)\n",
      "  VAR_INPUT:\n",
      "    - Automatikbetrieb_Starten: BOOL\n",
      "    - AutoRestartEnable: BOOL\n",
      "    - PeriodicFaultEnable: BOOL := TRUE\n",
      "    - PeriodicFaultPeriod: TIME := T#60s\n",
      "    - FaultPulse: TIME := T#100ms\n",
      "  VAR_OUTPUT:\n",
      "    - Automatikbetrieb_Fertig: BOOL\n",
      "    - Stoerung_erkannt: BOOL\n",
      "  VAR_IN_OUT:\n",
      "\n",
      "  ST-Implementation (Preview):\n",
      "//GVL.Start := TRUE;\n",
      "IF GVL.Start THEN\n",
      "\tAutoRestartEnable := TRUE;\n",
      "END_IF\n",
      "// === Flanken bilden ===\n",
      "rStart(CLK := Automatikbetrieb_Starten);\n",
      "rStep1(CLK := Schritt1);\n",
      "\n",
      "// === Startsequenz auf positive Flanke, nur wenn nicht bereits aktiv ===\n",
      "IF (AutoRestartEnable AND NOT (Schritt1 OR Schritt2)) OR (Stoerung_erkannt AND GVL.Weiter) THEN\n",
      "    // Reset aller Zustände\n",
      "    Automatikbetrieb_Fertig := FALSE;\n",
      "    Stoerung_erkannt        := FALSE;\n",
      "\tGVL.Weiter := FALSE;\n",
      "    // Start in Schritt 1\n",
      "    Schritt1 := TRUE;\n",
      "\tOPCUA.lastExecutedProcess := 'ExTechnProcess1';\n",
      "    Schritt2 := FALSE;\n",
      "END_IF\n",
      "\n",
      "// === Timer an die Schritte koppeln ===\n",
      "tSchritt1(IN := Schritt1, PT := T#55S);\n",
      "tSchritt2(IN := Schritt2, PT := T#55S);\n",
      "\n",
      "IF rStep1.Q THEN\n",
      "    lastSkillIsOne := NOT lastSkillIsOne;\n",
      "    IF lastSkillIsOne THEN\n",
      " \n",
      "... [gekürzt] ...\n",
      "\n",
      "POU FB_Diagnose_D2 (FunctionBlock)\n",
      "  VAR_INPUT:\n",
      "    - Diagnose_gefordert: BOOL\n",
      "  VAR_OUTPUT:\n",
      "    - Diagnose_beendet: BOOL\n",
      "    - Alt_gefunden: BOOL := FALSE\n",
      "  VAR_IN_OUT:\n",
      "\n",
      "  ST-Implementation (Preview):\n",
      "// 1) Startflanke erkennen\n",
      "rtReq(CLK := Diagnose_gefordert);\n",
      "\n",
      "// 2) Einmalig triggern (nur wenn noch nicht \"Busy\"):\n",
      "IF rtReq.Q AND NOT Busy THEN\n",
      "    Busy := TRUE;\n",
      "\tAlt_gefunden := FALSE;\n",
      "\tOPCUA.TriggerD2 := TRUE; \n",
      "\tOPCUA.bool1 := TRUE;\n",
      "END_IF\n",
      "\n",
      "  // {attribute 'OPC.UA.DA' := '1'} in der GVL setzen\n",
      "\n",
      "// 3) Fertigmeldung vom OPC-UA-Client\n",
      "//rtFinished(CLK := OPCUA.DiagnoseFinished);\n",
      "rtAck(CLK := OPCUA.DiagnoseFinished);\n",
      "rtD3(CLK := OPCUA.Alt_found);\n",
      "IF rtAck.Q OR rtD3.Q THEN\n",
      "    Diagnose_beendet := TRUE;\n",
      "    GVL.Weiter := TRUE;\n",
      "    Busy := FALSE;\n",
      "    OPCUA.TriggerD2 := FALSE;\n",
      "\tOPCUA.bool2 := FALSE;\n",
      "    GVL.Fehler := FALSE;\n",
      "    Diagnose_gefordert := FALSE;\n",
      "\tGVL.DiagnoseRequested := FALSE;\n",
      "END_IF\n",
      "IF rtD3.Q THEN\n",
      "\tAlt_gefunden := TRUE;\n",
      "END_IF\n",
      "\n",
      "POU FB_InitFahrt_A6_A2 (FunctionBlock)\n",
      "  VAR_INPUT:\n",
      "    - A6: BOOL := FALSE\n",
      "    - A2: BOOL := FALSE\n",
      "  VAR_OUTPUT:\n",
      "    - Init_erreicht: BOOL := FALSE\n",
      "  VAR_IN_OUT:\n",
      "\n",
      "  ST-Implementation (Preview):\n",
      "IF A6 THEN\n",
      "\ttInit(IN := A6, PT := T#3S);\n",
      "ELSIF A2 THEN\n",
      "\ttInit(IN := A2, PT := T#5S);\n",
      "END_IF\n",
      "\n",
      "IF tInit.Q THEN\n",
      "\tInit_erreicht := TRUE;\n",
      "ELSE\n",
      "\tInit_erreicht := FALSE;\n",
      "END_IF\n"
     ]
    }
   ],
   "source": [
    "# TwinCAT: POUs/DUTs/GVLs/VISUs sammeln + ST-IO-Variablen extrahieren (Jupyter-ready)\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import re, json, xml.etree.ElementTree as ET\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def read_text(p: Path) -> str:\n",
    "    return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "def strip_ns(xml_text: str) -> str:\n",
    "    # Default-Namespaces entfernen -> XPath wird einfacher\n",
    "    return re.sub(r'\\sxmlns=\"[^\"]+\"', '', xml_text, count=1)\n",
    "\n",
    "def strip_st_comments(s: str) -> str:\n",
    "    # ST-Kommentare entfernen: (* ... *) und // ...\n",
    "    s = re.sub(r'\\(\\*.*?\\*\\)', '', s, flags=re.S)\n",
    "    s = re.sub(r'//.*', '', s)\n",
    "    return s\n",
    "\n",
    "def detect_impl_lang(impl_node):\n",
    "    \"\"\"Finde ST/FBD/LD/SFC/IL auch wenn ein NWL-Container dazwischen sitzt.\"\"\"\n",
    "    if impl_node is None:\n",
    "        return None, \"\"\n",
    "    for tag in (\"ST\", \"FBD\", \"LD\", \"SFC\", \"IL\"):\n",
    "        n = impl_node.find(f\".//{tag}\")\n",
    "        if n is not None:\n",
    "            return tag, (n.text or \"\").strip()\n",
    "    # Fallback: erster Child-Tagname (z. B. 'NWL')\n",
    "    if list(impl_node):\n",
    "        c = list(impl_node)[0]\n",
    "        return c.tag, (c.text or \"\").strip()\n",
    "    return None, \"\"\n",
    "\n",
    "# ---------- IEC/ST Deklarationsparser ----------\n",
    "_var_stmt_re = re.compile(\n",
    "    r'^\\s*([A-Za-z_]\\w*)'               # Name\n",
    "    r'(?:\\s+AT\\s+([^:]+))?'             # optional AT-Adresse\n",
    "    r'\\s*:\\s*'                          \n",
    "    r'([^:=;]+?)'                       # Typ (inkl. ARRAY[..] OF ...)\n",
    "    r'(?:\\s*:=\\s*([^;]+?))?'            # optional Initialwert\n",
    "    r'\\s*;\\s*$', re.M | re.S)\n",
    "\n",
    "def _extract_var_block(text: str, scope_keyword: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extrahiert Variablen aus einem Block VAR_<SCOPE> ... END_VAR.\n",
    "    scope_keyword: 'INPUT' | 'OUTPUT' | 'IN_OUT' | 'GLOBAL' | 'TEMP' | etc.\n",
    "    \"\"\"\n",
    "    txt = strip_st_comments(text)\n",
    "    # Nicht-gierige Suche inkl. evtl. Zusätzen wie CONSTANT/RETAIN nach VAR_<SCOPE>\n",
    "    m = re.search(rf'VAR_{scope_keyword}\\b.*?\\n(.*?)END_VAR', txt, flags=re.S | re.I)\n",
    "    if not m:\n",
    "        return []\n",
    "    block = m.group(1)\n",
    "    vars_ = []\n",
    "    # Auf Semikolons getrimmt parsen\n",
    "    for m2 in _var_stmt_re.finditer(block):\n",
    "        name, at_addr, typ, init = [g.strip() if g else None for g in m2.groups()]\n",
    "        vars_.append({\n",
    "            \"name\": name,\n",
    "            \"address\": at_addr,\n",
    "            \"type\": re.sub(r'\\s+', ' ', typ).strip(),\n",
    "            \"init\": init.strip() if init else None\n",
    "        })\n",
    "    return vars_\n",
    "\n",
    "def extract_io_from_declaration(declaration: str) -> dict:\n",
    "    \"\"\"Liest IO-Variablen aus der ST-Deklaration.\"\"\"\n",
    "    return {\n",
    "        \"inputs\": _extract_var_block(declaration, \"INPUT\"),\n",
    "        \"outputs\": _extract_var_block(declaration, \"OUTPUT\"),\n",
    "        \"inouts\": _extract_var_block(declaration, \"IN_OUT\"),\n",
    "        # Optional: lokale Blöcke, falls gewünscht\n",
    "        \"temps\": _extract_var_block(declaration, \"TEMP\"),\n",
    "    }\n",
    "\n",
    "# ---------- Parser für TwinCAT-XML ----------\n",
    "def parse_tc_pou_anylang(pou_path: Path):\n",
    "    txt = read_text(pou_path)\n",
    "    root = ET.fromstring(strip_ns(txt))\n",
    "\n",
    "    pou = root.find(\".//POU\")\n",
    "    name = pou.get(\"Name\") if pou is not None else pou_path.stem\n",
    "\n",
    "    # Typ (Program / FunctionBlock / Function)\n",
    "    ptype = (pou.get(\"POUType\") if pou is not None else \"\") or \"\"\n",
    "    decl_node = root.find(\".//Declaration\")\n",
    "    declaration = (decl_node.text or \"\").strip() if decl_node is not None else \"\"\n",
    "    if not ptype and declaration:\n",
    "        m = re.match(r\"\\s*(PROGRAM|FUNCTION_BLOCK|FUNCTION)\\b\", declaration, re.I)\n",
    "        ptype = (m.group(1).title().replace(\"_\", \"\") if m else \"\")\n",
    "\n",
    "    impl_node = root.find(\".//Implementation\")\n",
    "    lang_tag, impl_text = detect_impl_lang(impl_node)\n",
    "\n",
    "    io = extract_io_from_declaration(declaration) if declaration else {\"inputs\":[], \"outputs\":[], \"inouts\":[], \"temps\":[]}\n",
    "\n",
    "    return {\n",
    "        \"kind\": \"POU\",\n",
    "        \"name\": name,\n",
    "        \"pou_type\": ptype,                  # Program | FunctionBlock | Function\n",
    "        \"implementation_lang\": lang_tag,    # ST | FBD | LD | SFC | IL | NWL | None\n",
    "        \"declaration\": declaration,\n",
    "        \"implementation\": impl_text,        # bei FBD/LD meist leer (grafisch)\n",
    "        \"io\": io,\n",
    "        \"file\": str(pou_path)\n",
    "    }\n",
    "\n",
    "def parse_tc_dut(dut_path: Path):\n",
    "    txt = read_text(dut_path)\n",
    "    root = ET.fromstring(strip_ns(txt))\n",
    "    dut = root.find(\".//DUT\")\n",
    "    name = dut.get(\"Name\") if dut is not None else dut_path.stem\n",
    "    # Typ (STRUCT/ENUM/ALIAS/UNION) steckt i. d. R. in der Declaration\n",
    "    decl_node = root.find(\".//Declaration\")\n",
    "    declaration = (decl_node.text or \"\").strip() if decl_node is not None else \"\"\n",
    "    # heuristischer dut_kind\n",
    "    dut_kind = \"\"\n",
    "    m = re.match(r\"\\s*(TYPE\\s+)?(STRUCT|ENUM|UNION|ALIAS)\\b\", declaration, re.I)\n",
    "    if m:\n",
    "        dut_kind = m.group(2).upper()\n",
    "    return {\n",
    "        \"kind\": \"DUT\",\n",
    "        \"name\": name,\n",
    "        \"dut_kind\": dut_kind,\n",
    "        \"declaration\": declaration,\n",
    "        \"file\": str(dut_path)\n",
    "    }\n",
    "\n",
    "def parse_tc_gvl(gvl_path: Path):\n",
    "    txt = read_text(gvl_path)\n",
    "    root = ET.fromstring(strip_ns(txt))\n",
    "    gvl = root.find(\".//GVL\")\n",
    "    name = gvl.get(\"Name\") if gvl is not None else gvl_path.stem\n",
    "    decl_node = root.find(\".//Declaration\")\n",
    "    declaration = (decl_node.text or \"\").strip() if decl_node is not None else \"\"\n",
    "    # Variablen in GVL stehen üblicherweise in VAR_GLOBAL ... END_VAR\n",
    "    globals_ = _extract_var_block(declaration, \"GLOBAL\")\n",
    "    return {\n",
    "        \"kind\": \"GVL\",\n",
    "        \"name\": name,\n",
    "        \"declaration\": declaration,\n",
    "        \"globals\": globals_,\n",
    "        \"file\": str(gvl_path)\n",
    "    }\n",
    "\n",
    "def parse_tc_vis(vis_path: Path):\n",
    "    \"\"\"\n",
    "    VISU-Metadaten aus .TcVis (Seitenname). Struktur ist XML; wir lesen den Wurzelknoten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        txt = read_text(vis_path)\n",
    "        root = ET.fromstring(strip_ns(txt))\n",
    "        vis = root.find(\".//Visualization\")\n",
    "        name = (vis.get(\"Name\") if vis is not None else None) or vis_path.stem\n",
    "    except Exception:\n",
    "        name = vis_path.stem\n",
    "    return {\n",
    "        \"kind\": \"VISU\",\n",
    "        \"name\": name,\n",
    "        \"file\": str(vis_path)\n",
    "    }\n",
    "\n",
    "# ---------- .plcproj Utilities ----------\n",
    "def list_artifacts_in_plcproj(plcproj: Path):\n",
    "    \"\"\"\n",
    "    Sucht referenzierte .TcPOU/.TcDUT/.TcGVL/.TcVis und zusätzlich inline-Objekte im .plcproj.\n",
    "    \"\"\"\n",
    "    txt = strip_ns(read_text(plcproj))\n",
    "    root = ET.fromstring(txt)\n",
    "    out = []\n",
    "\n",
    "    # 1) Referenzen in ItemGroups\n",
    "    for item in root.findall(\".//ItemGroup/*\"):\n",
    "        inc = item.get(\"Include\") or \"\"\n",
    "        inc_l = inc.lower()\n",
    "        p = (plcproj.parent / inc).resolve()\n",
    "\n",
    "        try:\n",
    "            if inc_l.endswith(\".tcpou\") and p.exists():\n",
    "                out.append(parse_tc_pou_anylang(p))\n",
    "            elif inc_l.endswith(\".tcdut\") and p.exists():\n",
    "                out.append(parse_tc_dut(p))\n",
    "            elif inc_l.endswith(\".tcgvl\") and p.exists():\n",
    "                out.append(parse_tc_gvl(p))\n",
    "            elif inc_l.endswith(\".tcvis\") and p.exists():\n",
    "                out.append(parse_tc_vis(p))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Fehler beim Parsen {p}: {e}\")\n",
    "\n",
    "    # 2) Inline-POUs/GVLs/DUTs (falls Multiple Project Files nicht aktiv war)\n",
    "    for pou in root.findall(\".//POU\"):\n",
    "        name = pou.get(\"Name\") or \"\"\n",
    "        ptype = pou.get(\"POUType\") or \"\"\n",
    "        decl = pou.find(\".//Declaration\")\n",
    "        impl = pou.find(\".//Implementation\")\n",
    "        lang_tag, impl_text = detect_impl_lang(impl)\n",
    "        declaration = (decl.text or \"\").strip() if decl is not None else \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"POU\",\n",
    "            \"name\": name,\n",
    "            \"pou_type\": ptype,\n",
    "            \"implementation_lang\": lang_tag,\n",
    "            \"declaration\": declaration,\n",
    "            \"implementation\": impl_text,\n",
    "            \"io\": extract_io_from_declaration(declaration) if declaration else {\"inputs\":[], \"outputs\":[], \"inouts\":[], \"temps\":[]},\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "    for gvl in root.findall(\".//GVL\"):\n",
    "        name = gvl.get(\"Name\") or \"\"\n",
    "        decl = gvl.find(\".//Declaration\")\n",
    "        declaration = (decl.text or \"\").strip() if decl is not None else \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"GVL\",\n",
    "            \"name\": name,\n",
    "            \"declaration\": declaration,\n",
    "            \"globals\": _extract_var_block(declaration, \"GLOBAL\"),\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "    for dut in root.findall(\".//DUT\"):\n",
    "        name = dut.get(\"Name\") or \"\"\n",
    "        decl = dut.find(\".//Declaration\")\n",
    "        declaration = (decl.text or \"\").strip() if decl is not None else \"\"\n",
    "        m = re.match(r\"\\s*(TYPE\\s+)?(STRUCT|ENUM|UNION|ALIAS)\\b\", declaration, re.I)\n",
    "        dut_kind = m.group(2).upper() if m else \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"DUT\",\n",
    "            \"name\": name,\n",
    "            \"dut_kind\": dut_kind,\n",
    "            \"declaration\": declaration,\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "    # VISUs sind selten inline; falls vorhanden:\n",
    "    for vis in root.findall(\".//Visualization\"):\n",
    "        name = vis.get(\"Name\") or \"\"\n",
    "        out.append({\n",
    "            \"kind\": \"VISU\",\n",
    "            \"name\": name,\n",
    "            \"file\": str(plcproj) + \" (inline)\"\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "def find_tsprojs_in_sln(sln_path: Path):\n",
    "    txt = read_text(sln_path)\n",
    "    tsprojs = []\n",
    "    for m in re.finditer(r'Project\\(\".*?\"\\)\\s=\\s*\".*?\",\\s*\"(.*?)\"', txt):\n",
    "        rel = m.group(1)\n",
    "        if rel.lower().endswith(\".tsproj\"):\n",
    "            tsprojs.append((sln_path.parent / rel).resolve())\n",
    "    return tsprojs\n",
    "\n",
    "def find_plcprojs_near(tsproj: Path):\n",
    "    return list(tsproj.parent.rglob(\"*.plcproj\"))\n",
    "\n",
    "# ---------- Pfad zu DEINER SLN ----------\n",
    "sln_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents.sln\")\n",
    "\n",
    "# ---------- Sammeln ----------\n",
    "tsprojs = find_tsprojs_in_sln(sln_path)\n",
    "plcprojs = []\n",
    "for ts in tsprojs:\n",
    "    plcprojs.extend(find_plcprojs_near(ts))\n",
    "plcprojs = sorted(set(plcprojs))\n",
    "\n",
    "all_objs = []\n",
    "for pp in plcprojs:\n",
    "    try:\n",
    "        all_objs.extend(list_artifacts_in_plcproj(pp))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Fehler beim Parsen {pp}: {e}\")\n",
    "\n",
    "# ---------- Auswertung ----------\n",
    "kinds = Counter([o.get(\"kind\") for o in all_objs])\n",
    "print(\"Objekt-Typen:\")\n",
    "for k, v in kinds.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Beispiele je Typ\n",
    "by_kind = defaultdict(list)\n",
    "for o in all_objs:\n",
    "    by_kind[o.get(\"kind\")].append(o)\n",
    "\n",
    "print(\"\\nBeispiele je Typ:\")\n",
    "for kind, items in by_kind.items():\n",
    "    print(f\"\\n== {kind} ==\")\n",
    "    for o in items[:5]:  # max 5 Beispiele\n",
    "        if kind == \"POU\":\n",
    "            io = o.get(\"io\", {})\n",
    "            io_sum = f\"in={len(io.get('inputs',[]))}, out={len(io.get('outputs',[]))}, inout={len(io.get('inouts',[]))}\"\n",
    "            print(f\"- {o['name']}  [{o.get('pou_type','?')}/{o.get('implementation_lang') or '—'}]  IO({io_sum}) -> {o['file']}\")\n",
    "        elif kind == \"DUT\":\n",
    "            print(f\"- {o['name']}  [{o.get('dut_kind') or '—'}] -> {o['file']}\")\n",
    "        else:\n",
    "            print(f\"- {o['name']} -> {o['file']}\")\n",
    "\n",
    "# Nur POUs mit ST-Implementation zeigen + deren IO-Variablen\n",
    "st_pous = [o for o in all_objs if o.get(\"kind\")==\"POU\" and (o.get(\"implementation_lang\") or \"\").upper()==\"ST\"]\n",
    "print(f\"\\nSummary: PLCProjs={len(plcprojs)}, Objects={len(all_objs)}, ST-POUs={len(st_pous)}\")\n",
    "\n",
    "# Optional: Dateien schreiben (JSONs neben der SLN)\n",
    "out_base = sln_path.with_suffix(\"\")\n",
    "Path(str(out_base) + \"_objects.json\").write_text(json.dumps(all_objs, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "Path(str(out_base) + \"_pous_st.json\").write_text(json.dumps(st_pous, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"\\nExport:\")\n",
    "print(\" -\", str(out_base) + \"_objects.json\")\n",
    "print(\" -\", str(out_base) + \"_pous_st.json\")\n",
    "\n",
    "# Beispielhafte Ausgabe der IO-Listen und ST-Implementierung (gekürzt) für die ersten 3 ST-POUs\n",
    "print(\"\\n--- ST-POU IO-Details (erste 3) ---\")\n",
    "for o in st_pous[:3]:\n",
    "    print(f\"\\nPOU {o['name']} ({o.get('pou_type','?')})\")\n",
    "    io = o[\"io\"]\n",
    "    for label, lst in [(\"VAR_INPUT\", io[\"inputs\"]), (\"VAR_OUTPUT\", io[\"outputs\"]), (\"VAR_IN_OUT\", io[\"inouts\"])]:\n",
    "        print(f\"  {label}:\")\n",
    "        for v in lst:\n",
    "            addr = f\" @ {v['address']}\" if v['address'] else \"\"\n",
    "            init = f\" := {v['init']}\" if v['init'] else \"\"\n",
    "            print(f\"    - {v['name']}: {v['type']}{addr}{init}\")\n",
    "    # ST-Code (falls vorhanden) leicht gekürzt\n",
    "    impl = (o.get(\"implementation\") or \"\").strip()\n",
    "    if impl:\n",
    "        preview = impl if len(impl) < 800 else impl[:800] + \"\\n... [gekürzt] ...\"\n",
    "        print(\"\\n  ST-Implementation (Preview):\\n\" + preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efbfdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene PLC-Projekte: ['TIPC^Proj1^Proj1 Project']\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "\n",
    "# 1) JSON einlesen\n",
    "json_path = pathlib.Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents_objects.json\")\n",
    "with json_path.open(encoding=\"utf-8\") as f:\n",
    "    objects = json.load(f)\n",
    "\n",
    "plc_names = set()\n",
    "\n",
    "# 2) Für jedes Artefakt den Elternordner durchsuchen, bis .plcproj gefunden wird\n",
    "for obj in objects:\n",
    "    fpath = pathlib.Path(obj[\"file\"])\n",
    "    # inline-Einträge haben \" (inline)\" am Ende, deshalb originalen Pfad extrahieren\n",
    "    try:\n",
    "        fpath = pathlib.Path(fpath.as_posix().split(\" (inline)\")[0])\n",
    "    except Exception:\n",
    "        pass\n",
    "    for parent in fpath.parents:\n",
    "        for plcproj in parent.glob(\"*.plcproj\"):\n",
    "            plc_names.add(plcproj.stem)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "# 3) Aus PLC-Namen Lookup-Pfade bauen\n",
    "lookup_paths = [f\"TIPC^{name}^{name} Project\" for name in sorted(plc_names)]\n",
    "print(\"Gefundene PLC-Projekte:\", lookup_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc5925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLC-Namen aus Dateien (nur Info): ['Proj1']\n",
      "Projects in Solution:\n",
      "  Index 1: Name=TestProjektTwinCATEvents, FullName=C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents.tsproj\n",
      "Verwende TwinCAT-Projekt: TestProjektTwinCATEvents\n",
      "PLC-Root gefunden: SPS Pfad: TIPC\n",
      "  Kind: Proj1 | Pfad: TIPC^Proj1\n",
      "Versuche Export via NestedProject von 'Proj1' ...\n",
      "XML-Export erstellt: C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\export.xml\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib, datetime, pythoncom\n",
    "import win32com.client as com\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Konfiguration ---\n",
    "sln_path   = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents.sln\"\n",
    "export_xml = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\export.xml\"\n",
    "json_path  = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents_objects.json\"\n",
    "\n",
    "# --- PLC-Namen (nur Info / Fallback bei Pfadkonstruktion) ---\n",
    "with open(json_path, encoding=\"utf-8\") as f:\n",
    "    objects = json.load(f)\n",
    "plc_names = set()\n",
    "for obj in objects:\n",
    "    fpath = Path(obj[\"file\"].split(\" (inline)\")[0])\n",
    "    for parent in fpath.parents:\n",
    "        for plcproj in parent.glob(\"*.plcproj\"):\n",
    "            plc_names.add(plcproj.stem)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "print(\"PLC-Namen aus Dateien (nur Info):\", sorted(plc_names))\n",
    "\n",
    "# --- TwinCAT Solution öffnen ---\n",
    "Path(export_xml).parent.mkdir(parents=True, exist_ok=True)\n",
    "dte = com.Dispatch(\"TcXaeShell.DTE.17.0\")  # ggf. Version anpassen\n",
    "dte.SuppressUI = False\n",
    "dte.MainWindow.Visible = True\n",
    "solution = dte.Solution\n",
    "solution.Open(sln_path)\n",
    "\n",
    "print(\"Projects in Solution:\")\n",
    "for i in range(1, solution.Projects.Count + 1):\n",
    "    p = solution.Projects.Item(i)\n",
    "    print(f\"  Index {i}: Name={p.Name}, FullName={p.FullName}\")\n",
    "\n",
    "# .tsproj ermitteln\n",
    "tc_project = None\n",
    "for i in range(1, solution.Projects.Count + 1):\n",
    "    p = solution.Projects.Item(i)\n",
    "    if p.FullName.lower().endswith(\".tsproj\"):\n",
    "        tc_project = p\n",
    "        break\n",
    "if tc_project is None:\n",
    "    raise RuntimeError(\"Kein TwinCAT-Systemprojekt (.tsproj) in der Solution gefunden\")\n",
    "print(\"Verwende TwinCAT-Projekt:\", tc_project.Name)\n",
    "\n",
    "sys_mgr = tc_project.Object  # ITcSysManager\n",
    "\n",
    "# --- PLC-Root & Kinder ermitteln ---\n",
    "root_plc = sys_mgr.LookupTreeItem(\"TIPC\")\n",
    "print(\"PLC-Root gefunden:\", root_plc.Name, \"Pfad:\", root_plc.PathName)\n",
    "\n",
    "children = []\n",
    "try:\n",
    "    # Bevorzugt Enumerator (COM _NewEnum)\n",
    "    for child in root_plc:\n",
    "        print(\"  Kind:\", child.Name, \"| Pfad:\", child.PathName)\n",
    "        children.append(child)\n",
    "except Exception as e:\n",
    "    # Fallback 1-basiert\n",
    "    print(\"Enumerator nicht verfügbar -> Child(i). Grund:\", e)\n",
    "    cnt = int(root_plc.ChildCount)\n",
    "    for i in range(1, cnt + 1):\n",
    "        child = root_plc.Child(i)\n",
    "        print(\"  Kind:\", child.Name, \"| Pfad:\", child.PathName)\n",
    "        children.append(child)\n",
    "\n",
    "if not children:\n",
    "    raise RuntimeError(\"Unter 'TIPC' wurde kein PLC-Projekt gefunden.\")\n",
    "\n",
    "# --- Export-Funktion ---\n",
    "def try_export_from_node(node, out_path: Path, selection: str = \"\"):\n",
    "    \"\"\"Versucht, PlcOpenExport auf einem Knoten mit ITcPlcIECProject aufzurufen.\"\"\"\n",
    "    # Datei freimachen oder alternativen Namen wählen\n",
    "    target = out_path\n",
    "    if target.exists():\n",
    "        try:\n",
    "            target.unlink()\n",
    "        except Exception:\n",
    "            ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            target = target.with_name(f\"{target.stem}_{ts}{target.suffix}\")\n",
    "            print(\"Konnte bestehende Datei nicht löschen -> nutze:\", target)\n",
    "\n",
    "    node.PlcOpenExport(str(target), selection)\n",
    "    print(\"XML-Export erstellt:\", target)\n",
    "    return target\n",
    "\n",
    "exported = False\n",
    "last_err = None\n",
    "\n",
    "# 1) Primär: NestedProject benutzen (robust gegen Bezeichner/Übersetzung)\n",
    "for child in children:\n",
    "    print(f\"Versuche Export via NestedProject von '{child.Name}' ...\")\n",
    "    try:\n",
    "        nested = child.NestedProject  # ITcPlcIECProject\n",
    "        try_export_from_node(nested, Path(export_xml), selection=\"\")  # leer = gesamtes NestedProject\n",
    "        exported = True\n",
    "        break\n",
    "    except pythoncom.com_error as e:\n",
    "        print(\"  NestedProject/Export nicht möglich bei\", child.Name, \"->\", e)\n",
    "        last_err = e\n",
    "\n",
    "# 2) Sekundär: Explizite Pfade testen — sowohl '... Project' (EN) als auch '... Projekt' (DE)\n",
    "if not exported:\n",
    "    candidates = []\n",
    "    for child in children:\n",
    "        base = child.PathName           # z. B. TIPC^SPS_Demonstrator\n",
    "        name = child.Name               # z. B. SPS_Demonstrator\n",
    "        # Reihenfolge: erst 'Project', dann 'Projekt', dann nackter Name (manche Bäume haben kein Suffix)\n",
    "        candidates += [\n",
    "            f\"{base}^{name} Project\",\n",
    "            f\"{base}^{name} Projekt\",\n",
    "            f\"{base}^{name}\",\n",
    "        ]\n",
    "    # auch aus JSON bekannte Namen stützen\n",
    "    for nm in sorted(plc_names):\n",
    "        candidates += [f\"TIPC^{nm}^{nm} Project\", f\"TIPC^{nm}^{nm} Projekt\", f\"TIPC^{nm}\"]\n",
    "\n",
    "    # Deduplizieren, Reihenfolge beibehalten\n",
    "    seen = set(); uniq = []\n",
    "    for c in candidates:\n",
    "        if c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "\n",
    "    print(\"Probiere Pfad-Kandidaten:\")\n",
    "    for c in uniq:\n",
    "        try:\n",
    "            node = sys_mgr.LookupTreeItem(c)\n",
    "            print(\"  [OK] gefunden:\", c)\n",
    "            try:\n",
    "                try_export_from_node(node, Path(export_xml), selection=\"\")\n",
    "                exported = True\n",
    "                break\n",
    "            except pythoncom.com_error as e:\n",
    "                print(\"    -> Knoten gefunden, aber Export schlug fehl:\", e)\n",
    "                last_err = e\n",
    "        except pythoncom.com_error as e:\n",
    "            print(\"  [--] nicht gefunden:\", c, \"| Grund:\", e)\n",
    "            last_err = e\n",
    "\n",
    "if not exported:\n",
    "    raise RuntimeError(f\"Kein exportierbarer PLC-Knoten gefunden. Letzter Fehler: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f929e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "NS = {'ns': 'http://www.plcopen.org/xml/tc6_0200'}\n",
    "\n",
    "def parse_io_vars(pou):\n",
    "    \"\"\"Liefert Listen der deklarierten Inputs und Outputs aus der Interface-Sektion eines POU.\"\"\"\n",
    "    inputs, outputs = [], []\n",
    "    interface = pou.find('ns:interface', NS)\n",
    "    if interface is not None:\n",
    "        input_vars = interface.find('ns:inputVars', NS)\n",
    "        if input_vars is not None:\n",
    "            for var in input_vars.findall('ns:variable', NS):\n",
    "                name = var.attrib.get('name')\n",
    "                if name:\n",
    "                    inputs.append(name)\n",
    "        output_vars = interface.find('ns:outputVars', NS)\n",
    "        if output_vars is not None:\n",
    "            for var in output_vars.findall('ns:variable', NS):\n",
    "                name = var.attrib.get('name')\n",
    "                if name:\n",
    "                    outputs.append(name)\n",
    "    return inputs, outputs\n",
    "\n",
    "def build_node_mapping(fbd):\n",
    "    \"\"\"Erzeugt ein Dictionary localId -> externer Ausdruck für inVariable/outVariable-Knoten.\"\"\"\n",
    "    node_expr = {}\n",
    "    for inv in fbd.findall('ns:inVariable', NS):\n",
    "        lid = inv.get('localId')\n",
    "        expr = inv.find('ns:expression', NS)\n",
    "        if lid and expr is not None and expr.text:\n",
    "            node_expr[lid] = expr.text.strip()\n",
    "    for outv in fbd.findall('ns:outVariable', NS):\n",
    "        lid = outv.get('localId')\n",
    "        expr = outv.find('ns:expression', NS)\n",
    "        if lid and expr is not None and expr.text:\n",
    "            node_expr[lid] = expr.text.strip()\n",
    "    return node_expr\n",
    "\n",
    "def extract_call_blocks(fbd, pou_names_set, node_map):\n",
    "    \"\"\"Sammelt die Aufrufe von Unterprogrammen (block.typeName in pou_names_set) und deren I/O-Mapping.\"\"\"\n",
    "    calls = []\n",
    "    for block in fbd.findall('ns:block', NS):\n",
    "        type_name = block.get('typeName')\n",
    "        if type_name and type_name in pou_names_set:\n",
    "            call_info = {\n",
    "                'SubNetwork_Name': type_name,\n",
    "                'instanceName': block.get('instanceName'),\n",
    "                'inputs': [],\n",
    "                'outputs': [],\n",
    "            }\n",
    "            # Eingänge der Subfunktion auslesen\n",
    "            for var in block.findall('ns:inputVariables/ns:variable', NS):\n",
    "                formal = var.get('formalParameter')\n",
    "                ext = None\n",
    "                cpin = var.find('ns:connectionPointIn', NS)\n",
    "                if cpin is not None:\n",
    "                    conn = cpin.find('ns:connection', NS)\n",
    "                    if conn is not None:\n",
    "                        ref = conn.get('refLocalId')\n",
    "                        if ref:\n",
    "                            ext = node_map.get(ref, f'localId:{ref}')\n",
    "                call_info['inputs'].append({'internal': formal, 'external': ext})\n",
    "            # Ausgänge der Subfunktion auslesen\n",
    "            for var in block.findall('ns:outputVariables/ns:variable', NS):\n",
    "                formal = var.get('formalParameter')\n",
    "                ext = None\n",
    "                cpout = var.find('ns:connectionPointOut', NS)\n",
    "                if cpout is not None:\n",
    "                    expr = cpout.find('ns:expression', NS)\n",
    "                    if expr is not None and expr.text:\n",
    "                        ext = expr.text.strip()\n",
    "                    else:\n",
    "                        conn = cpout.find('ns:connection', NS)\n",
    "                        if conn is not None:\n",
    "                            ref = conn.get('refLocalId')\n",
    "                            if ref:\n",
    "                                ext = node_map.get(ref, f'localId:{ref}')\n",
    "                call_info['outputs'].append({'internal': formal, 'external': ext})\n",
    "            calls.append(call_info)\n",
    "    return calls\n",
    "\n",
    "def map_pou_io_to_external(pou, node_map):\n",
    "    \"\"\"\n",
    "    Ordnet deklarierten Inputs/Outputs eines POU den externen Variablennamen zu,\n",
    "    sofern sie in den in/out-Variablen des FBD-Blocks erscheinen.\n",
    "    \"\"\"\n",
    "    inputs, outputs = parse_io_vars(pou)\n",
    "    mapped_inputs = []\n",
    "    mapped_outputs = []\n",
    "    # Reverse-Mapping: Eine externe Zuordnung wird nur vorgenommen, wenn der Ausdruck einen Punkt enthält (also ein Präfix hat) und der Suffix mit dem internen Namen übereinstimmt. Dadurch wird verhindert, dass Variablen auf sich selbst gemappt werden.\n",
    "    pou_name = pou.attrib.get('name')\n",
    "    for inp in inputs:\n",
    "        ext = None\n",
    "        for expr in node_map.values():\n",
    "            if expr and '.' in expr:\n",
    "                prefix, suffix = expr.split('.', 1)[0], expr.split('.')[-1]\n",
    "                if suffix == inp and prefix != pou_name:\n",
    "                    ext = expr\n",
    "                    break\n",
    "        mapped_inputs.append({'internal': inp, 'external': ext})\n",
    "    for out in outputs:\n",
    "        ext = None\n",
    "        for expr in node_map.values():\n",
    "            if expr and '.' in expr:\n",
    "                prefix, suffix = expr.split('.', 1)[0], expr.split('.')[-1]\n",
    "                if suffix == out and prefix != pou_name:\n",
    "                    ext = expr\n",
    "                    break\n",
    "        mapped_outputs.append({'internal': out, 'external': ext})\n",
    "    return mapped_inputs, mapped_outputs\n",
    "\n",
    "def analyze_plcopen(xml_path):\n",
    "    \"\"\"Analysiert die PLCopen-XML und erzeugt eine Liste aus Programminformationen und Subnetz-Aufrufen.\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    pou_names = {p.attrib.get('name') for p in root.findall('.//ns:pou', NS)}\n",
    "    result = []\n",
    "    for pou in root.findall('.//ns:pou', NS):\n",
    "        name = pou.attrib.get('name')\n",
    "        fbd = pou.find('.//ns:FBD', NS)\n",
    "        node_map = build_node_mapping(fbd) if fbd is not None else {}\n",
    "        inputs, outputs = parse_io_vars(pou)\n",
    "        mapped_inputs, mapped_outputs = ([], [])\n",
    "        if fbd is not None:\n",
    "            mapped_inputs, mapped_outputs = map_pou_io_to_external(pou, node_map)\n",
    "        else:\n",
    "            mapped_inputs = [{'internal': n, 'external': None} for n in inputs]\n",
    "            mapped_outputs = [{'internal': n, 'external': None} for n in outputs]\n",
    "        subcalls = extract_call_blocks(fbd, pou_names, node_map) if fbd is not None else []\n",
    "        result.append({\n",
    "            'Programm_Name': name,\n",
    "            'inputs': mapped_inputs,\n",
    "            'outputs': mapped_outputs,\n",
    "            'subcalls': subcalls\n",
    "        })\n",
    "    return result\n",
    "\n",
    "# Beispielaufruf:\n",
    "xml_file = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\export.xml\")\n",
    "mapping = analyze_plcopen(xml_file)\n",
    "with open(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\program_io_with_mapping.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mapping, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95cbc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POUs gefunden: ['FB_Automatikbetrieb_F1', 'FB_Betriebsarten', 'FB_Diagnose_D2', 'FB_InitFahrt_A6_A2', 'FB_ProduktionMitStoerung_D3', 'MAIN', 'FB_Methode1Job', 'FB_Notaus_D1']\n",
      "JSON um Typen, temps und Programmkode erweitert.\n"
     ]
    }
   ],
   "source": [
    "# Zusätzliche Informationen aus export.xml ergänzen\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# 1) JSON erneut laden\n",
    "json_file = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\program_io_with_mapping.json\")\n",
    "mapping = json.loads(json_file.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "# 2) export.xml parsen\n",
    "xml_file = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\export.xml\")\n",
    "tree = ET.parse(xml_file)\n",
    "root = tree.getroot()\n",
    "NS = {\"ns\": \"http://www.plcopen.org/xml/tc6_0200\",\n",
    "      \"html\": \"http://www.w3.org/1999/xhtml\"}\n",
    "\n",
    "def get_var_type(var):\n",
    "    \"\"\"\n",
    "    Holt den Datentyp einer ns:variable aus export.xml.\n",
    "    - Basisdatentypen: BOOL, INT, TIME ...\n",
    "    - Abgeleitete Typen: RS, R_TRIG, TON, FB_... usw.\n",
    "    \"\"\"\n",
    "    tnode = var.find(\"ns:type\", NS)\n",
    "    if tnode is None:\n",
    "        return None\n",
    "\n",
    "    # 1) abgeleiteter Typ?\n",
    "    derived = tnode.find(\"ns:derived\", NS)\n",
    "    if derived is not None:\n",
    "        return derived.attrib.get(\"name\")\n",
    "\n",
    "    # 2) Basisdatentyp: erstes Kindelement auswerten\n",
    "    for child in tnode:\n",
    "        tag = child.tag\n",
    "        local = tag.split(\"}\", 1)[1] if \"}\" in tag else tag\n",
    "        return local\n",
    "\n",
    "    return None\n",
    "\n",
    "# 3) interne Variablen, Programmkode und Typen je POU sammeln\n",
    "pou_info = {}\n",
    "pou_var_types = {}\n",
    "\n",
    "for pou in root.findall(\".//ns:pou\", NS):\n",
    "    name = pou.attrib.get(\"name\")\n",
    "    interface = pou.find(\"ns:interface\", NS)\n",
    "\n",
    "    locals_list = []\n",
    "    type_map = {}\n",
    "\n",
    "    if interface is not None:\n",
    "        # alle relevanten Sektionen durchgehen\n",
    "        for sect_tag in [\"inputVars\", \"outputVars\", \"inOutVars\", \"localVars\", \"tempVars\"]:\n",
    "            sect = interface.find(f\"ns:{sect_tag}\", NS)\n",
    "            if sect is None:\n",
    "                continue\n",
    "\n",
    "            for var in sect.findall(\"ns:variable\", NS):\n",
    "                vname = var.attrib.get(\"name\")\n",
    "                if not vname:\n",
    "                    continue\n",
    "\n",
    "                vtype = get_var_type(var)\n",
    "                type_map[vname] = vtype\n",
    "\n",
    "                # lokale/temp Variablen später als \"temps\" führen\n",
    "                if sect_tag in (\"localVars\", \"tempVars\"):\n",
    "                    locals_list.append(vname)\n",
    "\n",
    "    # Programmkode aus dem ST-Body holen (wie bisher bei dir)\n",
    "    body = pou.find(\"ns:body\", NS)\n",
    "    code_str = \"\"\n",
    "    if body is not None:\n",
    "        st = body.find(\"ns:ST\", NS)\n",
    "        if st is not None and st.text:\n",
    "            code_str = st.text.strip()\n",
    "        else:\n",
    "            html_st = body.find(\".//html:xhtml\", NS)\n",
    "            if html_st is not None and html_st.text:\n",
    "                code_str = html_st.text.strip()\n",
    "\n",
    "    pou_info[name] = {\"locals\": locals_list, \"code\": code_str}\n",
    "    pou_var_types[name] = type_map\n",
    "\n",
    "print(\"POUs gefunden:\", list(pou_info.keys()))\n",
    "\n",
    "# 4) Mapping-Einträge erweitern\n",
    "for entry in mapping:\n",
    "    name = entry[\"Programm_Name\"]\n",
    "    info = pou_info.get(name, {})\n",
    "    types = pou_var_types.get(name, {})\n",
    "\n",
    "    # 4.1 interne Variablen (locals/tempVars) als temps mit Typ speichern\n",
    "    locals_list = info.get(\"locals\", [])\n",
    "    entry[\"temps\"] = [\n",
    "        {\"name\": lv, \"type\": types.get(lv)}\n",
    "        for lv in locals_list\n",
    "    ]\n",
    "\n",
    "    # 4.2 Programmkode als eigener Key\n",
    "    entry[\"program_code\"] = info.get(\"code\", \"\")\n",
    "\n",
    "    # 4.3 Typen an Inputs/Outputs anhängen\n",
    "    for inp in entry.get(\"inputs\", []):\n",
    "        vname = inp.get(\"internal\")\n",
    "        if vname in types:\n",
    "            inp[\"internal_type\"] = types[vname]\n",
    "\n",
    "    for out in entry.get(\"outputs\", []):\n",
    "        vname = out.get(\"internal\")\n",
    "        if vname in types:\n",
    "            out[\"internal_type\"] = types[vname]\n",
    "\n",
    "# 5) Erweiterte JSON speichern\n",
    "json_file.write_text(json.dumps(mapping, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"JSON um Typen, temps und Programmkode erweitert.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e3bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse abgeschlossen. Ergebnisse in C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\variable_traces.json\n"
     ]
    }
   ],
   "source": [
    "import json, xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Hilfsfunktionen ===\n",
    "def base_name(expr: str) -> str:\n",
    "    return expr.split(\".\")[-1] if expr else \"\"\n",
    "\n",
    "# === Daten laden ===\n",
    "json_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\program_io_with_mapping.json\")\n",
    "xml_path  = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\export.xml\")\n",
    "\n",
    "pou_map_data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "pou_map = {entry[\"Programm_Name\"]: entry for entry in pou_map_data}\n",
    "\n",
    "# Hardwarevariablen (xDI/udiDI, xDO/udiDO) aus der export.XML auslesen:contentReference[oaicite:0]{index=0}\n",
    "NS = {\"ns\":\"http://www.plcopen.org/xml/tc6_0200\",\"html\":\"http://www.w3.org/1999/xhtml\"}\n",
    "root = ET.parse(xml_path).getroot()\n",
    "var_doc = {}    # Variable -> physische Adresse\n",
    "hw_inputs = set()\n",
    "hw_outputs = set()\n",
    "for var in root.findall(\".//ns:variable\", NS):\n",
    "    name = var.attrib.get(\"name\")\n",
    "    doc = var.find(\".//html:xhtml\", NS)\n",
    "    if doc is not None and doc.text:\n",
    "        doc_text = doc.text.strip()\n",
    "        var_doc[name] = doc_text\n",
    "        if doc_text.startswith((\"xDI\",\"udiDI\")):\n",
    "            hw_inputs.add(name)\n",
    "        elif doc_text.startswith((\"xDO\",\"udiDO\")):\n",
    "            hw_outputs.add(name)\n",
    "\n",
    "# === Variablen‑Graph erzeugen ===\n",
    "# Knoten: Variablen-Basisname; Kanten: (Program, neues Basisname)\n",
    "var_graph = defaultdict(list)\n",
    "for entry in pou_map_data:\n",
    "    pname = entry[\"Programm_Name\"]\n",
    "    # externe Eingangs- und Ausgangsvariablen sammeln\n",
    "    in_bases  = [base_name(inp[\"external\"]) for inp in entry[\"inputs\"] if inp.get(\"external\")]\n",
    "    out_bases = [base_name(out[\"external\"]) for out in entry[\"outputs\"] if out.get(\"external\")]\n",
    "    for b_in in in_bases:\n",
    "        for b_out in out_bases:\n",
    "            var_graph[b_in].append((pname, b_out))\n",
    "\n",
    "# === Rekursives Tracing von Variablen zu Hardware ===\n",
    "def find_paths(start_base, visited_bases=None, depth=0):\n",
    "    \"\"\"Gibt für eine Variable (Basisname) alle Pfade (Programmkette und Variable) bis zur HW zurück.\"\"\"\n",
    "    if visited_bases is None:\n",
    "        visited_bases = set()\n",
    "    if start_base in visited_bases:\n",
    "        return []\n",
    "    visited_bases.add(start_base)\n",
    "\n",
    "    # direkter HW‑Treffer: keine weiteren Programme\n",
    "    if start_base in hw_outputs:\n",
    "        return [[]]\n",
    "\n",
    "    paths = []\n",
    "    for prog, new_base in var_graph.get(start_base, []):\n",
    "        for sub_path in find_paths(new_base, visited_bases.copy(), depth+1):\n",
    "            paths.append([(prog, new_base)] + sub_path)\n",
    "    return paths\n",
    "\n",
    "# === Programmausgabe: Pro Programm alle Outputs und Pfade ===\n",
    "trace = {}\n",
    "for pname, entry in pou_map.items():\n",
    "    prog_outputs = []\n",
    "    for out in entry[\"outputs\"]:\n",
    "        internal = out[\"internal\"]\n",
    "        ext      = out.get(\"external\")\n",
    "        if not ext:\n",
    "            continue\n",
    "        b = base_name(ext)\n",
    "        if b in hw_outputs:\n",
    "            prog_outputs.append({\n",
    "                \"internal\": internal,\n",
    "                \"external\": ext,\n",
    "                \"hardware\": True,\n",
    "                \"paths\": [[(pname, b), {\"hardware\": var_doc.get(b)}]]\n",
    "            })\n",
    "        else:\n",
    "            chains = []\n",
    "            for path in find_paths(b):\n",
    "                chain = [{\"program\": pname, \"variable\": b}]\n",
    "                for step_prog, step_base in path:\n",
    "                    chain.append({\"program\": step_prog, \"variable\": step_base})\n",
    "                if path:\n",
    "                    last_base = path[-1][1]\n",
    "                    chain.append({\"hardware\": var_doc.get(last_base)})\n",
    "                chains.append(chain)\n",
    "            prog_outputs.append({\n",
    "                \"internal\": internal,\n",
    "                \"external\": ext,\n",
    "                \"hardware\": False,\n",
    "                \"paths\": chains\n",
    "            })\n",
    "    trace[pname] = prog_outputs\n",
    "\n",
    "# Ergebnis als JSON speichern oder weiterverarbeiten\n",
    "out_file = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\variable_traces.json\")\n",
    "out_file.write_text(json.dumps(trace, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(f\"Analyse abgeschlossen. Ergebnisse in {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b1b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene POUs und Sprachen:\n",
      "  - FB_Automatikbetrieb_F1: ST\n",
      "  - FB_Betriebsarten: FBD\n",
      "  - FB_Diagnose_D2: ST\n",
      "  - FB_InitFahrt_A6_A2: ST\n",
      "  - FB_ProduktionMitStoerung_D3: ST\n",
      "  - MAIN: ST\n",
      "  - FB_Methode1Job: ST\n",
      "  - FB_Notaus_D1: ST\n",
      "\n",
      "=== Verarbeite POU: FB_Automatikbetrieb_F1 (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "=== Verarbeite POU: FB_Betriebsarten (lang=FBD) ===\n",
      "  -> FBD-POU, PyLC1–4 werden ausgeführt.\n",
      "Python-Code nach generated_code_1.py geschrieben.\n",
      "Umbenannte Datei nach generated_code_2.py geschrieben.\n",
      "Generated code has been written to  generated_code_3.py .\n",
      "Generated code has been written to generated_code_3.py.\n",
      "\n",
      "=== Verarbeite POU: FB_Diagnose_D2 (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "=== Verarbeite POU: FB_InitFahrt_A6_A2 (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "=== Verarbeite POU: FB_ProduktionMitStoerung_D3 (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "=== Verarbeite POU: MAIN (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "=== Verarbeite POU: FB_Methode1Job (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "=== Verarbeite POU: FB_Notaus_D1 (lang=ST) ===\n",
      "  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\n",
      "\n",
      "Fertig: program_code wurde für alle passenden Programme gesetzt (ST oder FBD).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\MA_Python_Agent\\PyLC_Anpassung\")\n",
    "\n",
    "from PyLC1_Converter import parse_pou_blocks\n",
    "from PyLC2_Generator import generate_python_code\n",
    "from PyLC3_Rename import rename_variables\n",
    "from PyLC4_Cleanup import cleanup_code\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Konfiguration\n",
    "# -------------------------------------------------\n",
    "xml_path = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\export.xml\"\n",
    "json_path = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\program_io_with_mapping.json\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# XML-Helfer: Default-Namespace entfernen, damit XPath einfacher ist\n",
    "# -------------------------------------------------\n",
    "def strip_ns(xml_text: str) -> str:\n",
    "    return re.sub(r'\\sxmlns=\"[^\"]+\"', '', xml_text, count=1)\n",
    "\n",
    "def load_export_root(xml_path: str) -> ET.Element:\n",
    "    xml_raw = Path(xml_path).read_text(encoding=\"utf-8\")\n",
    "    return ET.fromstring(strip_ns(xml_raw))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Sprache einer POU bestimmen (FBD vs. ST)\n",
    "# -------------------------------------------------\n",
    "def detect_pou_lang(pou: ET.Element) -> str | None:\n",
    "    \"\"\"\n",
    "    Schaut nur auf das <body>-Element:\n",
    "    - <FBD>  -> 'FBD'\n",
    "    - <ST>   -> 'ST'\n",
    "    \"\"\"\n",
    "    body = pou.find(\"body\")\n",
    "    if body is None:\n",
    "        return None\n",
    "    if body.find(\"FBD\") is not None:\n",
    "        return \"FBD\"\n",
    "    if body.find(\"ST\") is not None:\n",
    "        return \"ST\"\n",
    "    return None\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ST-Programmcode (inkl. Methoden) aus einer POU holen\n",
    "# -------------------------------------------------\n",
    "def collect_st_from_pou(pou_elem: ET.Element) -> str:\n",
    "    \"\"\"\n",
    "    Sammelt ST-Code:\n",
    "    - Top-Level-Body (falls <body><ST><html:xhtml>...</html:xhtml></ST></body>)\n",
    "    - Methoden in addData/data name=\".../method\"\n",
    "    Gibt einen zusammenhängenden ST-Text zurück.\n",
    "    \"\"\"\n",
    "    parts: list[str] = []\n",
    "    name = pou_elem.get(\"name\", \"?\")\n",
    "\n",
    "    # 1) Top-Level-Body\n",
    "    body = pou_elem.find(\"body\")\n",
    "    if body is not None:\n",
    "        st = body.find(\".//ST\")\n",
    "        if st is not None:\n",
    "            txt = (st.text or \"\").strip() if st.text else \"\"\n",
    "            if not txt:\n",
    "                # ST-Text steckt oft im <html:xhtml> Unterelement\n",
    "                xhtml = None\n",
    "                for child in st.iter():\n",
    "                    if child.tag.endswith(\"xhtml\"):\n",
    "                        xhtml = child\n",
    "                        break\n",
    "                if xhtml is not None:\n",
    "                    txt = \"\".join(xhtml.itertext()).strip()\n",
    "            if txt:\n",
    "                parts.append(f\"// POU {name} body\\n{txt}\")\n",
    "\n",
    "    # 2) Methoden aus Vendor-Block (plcopenxml/method)\n",
    "    for data in pou_elem.findall(\".//data[@name='http://www.3s-software.com/plcopenxml/method']\"):\n",
    "        for method in data.findall(\".//Method\"):\n",
    "            m_name = method.get(\"name\", \"?\")\n",
    "            st = method.find(\".//ST\")\n",
    "            if st is None:\n",
    "                continue\n",
    "            txt = (st.text or \"\").strip() if st.text else \"\"\n",
    "            if not txt:\n",
    "                xhtml = None\n",
    "                for child in st.iter():\n",
    "                    if child.tag.endswith(\"xhtml\"):\n",
    "                        xhtml = child\n",
    "                        break\n",
    "                if xhtml is not None:\n",
    "                    txt = \"\".join(xhtml.itertext()).strip()\n",
    "            if txt:\n",
    "                parts.append(f\"// METHOD {m_name} of {name}\\n{txt}\")\n",
    "\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# XML laden und POU-Index aufbauen\n",
    "# -------------------------------------------------\n",
    "root = load_export_root(xml_path)\n",
    "pous = root.findall(\".//pou\")\n",
    "\n",
    "pou_lang: dict[str, str | None] = {p.get(\"name\"): detect_pou_lang(p) for p in pous}\n",
    "pou_by_name: dict[str, ET.Element] = {p.get(\"name\"): p for p in pous}\n",
    "\n",
    "print(\"Gefundene POUs und Sprachen:\")\n",
    "for n, lang in pou_lang.items():\n",
    "    print(f\"  - {n}: {lang}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# program_io_with_mapping.json laden\n",
    "# -------------------------------------------------\n",
    "mapping = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Hilfsfunktion: passende JSON-Einträge zu einem POU-Namen finden\n",
    "def entries_for_program(name: str):\n",
    "    return [e for e in mapping if e.get(\"Programm_Name\") == name]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Hauptschleife: für jede POU je nach Sprache verarbeiten\n",
    "# -------------------------------------------------\n",
    "for pou_name, lang in pou_lang.items():\n",
    "    print(f\"\\n=== Verarbeite POU: {pou_name} (lang={lang}) ===\")\n",
    "\n",
    "    if lang == \"ST\":\n",
    "        # ST-Fall: ST-Programmcode direkt aus export.xml holen\n",
    "        pou_elem = pou_by_name[pou_name]\n",
    "        st_code = collect_st_from_pou(pou_elem)\n",
    "        if not st_code:\n",
    "            print(\"  -> Achtung: Keine ST-Implementierung gefunden, überspringe.\")\n",
    "            continue\n",
    "\n",
    "        print(\"  -> ST-POU, PyLC wird NICHT aufgerufen. ST-Code wird direkt in JSON geschrieben.\")\n",
    "        for entry in entries_for_program(pou_name):\n",
    "            entry[\"program_code\"] = st_code\n",
    "\n",
    "        continue  # wichtig: keine PyLC-Pipeline mehr für dieses POU\n",
    "\n",
    "    if lang != \"FBD\":\n",
    "        print(\"  -> Weder FBD noch ST erkannt, PyLC wird übersprungen.\")\n",
    "        continue\n",
    "\n",
    "    # FBD-Fall: PyLC1–4 verwenden\n",
    "    print(\"  -> FBD-POU, PyLC1–4 werden ausgeführt.\")\n",
    "\n",
    "    # 1. Intermediate-Code erzeugen\n",
    "    parse_pou_blocks(\n",
    "        xml_path=xml_path,\n",
    "        output_path=\"generated_code_0.py\",\n",
    "        target_pou_name=pou_name,\n",
    "    )\n",
    "\n",
    "    # 2. Python-Code generieren\n",
    "    generate_python_code(\n",
    "        blocks_module_path=\"generated_code_0.py\",\n",
    "        output_path=\"generated_code_1.py\",\n",
    "    )\n",
    "\n",
    "    # 3. Variablen umbenennen\n",
    "    rename_variables(\n",
    "        input_code_path=\"generated_code_1.py\",\n",
    "        blocks_module_path=\"generated_code_0.py\",\n",
    "        output_path=\"generated_code_2.py\",\n",
    "    )\n",
    "\n",
    "    # 4. Code bereinigen\n",
    "    cleanup_code(\n",
    "        input_code_path=\"generated_code_2.py\",\n",
    "        output_path=\"generated_code_3.py\",\n",
    "    )\n",
    "\n",
    "    # 5. finalen Python-Code laden\n",
    "    with open(\"generated_code_3.py\", \"r\", encoding=\"utf-8\") as f:\n",
    "        python_code = f.read()\n",
    "\n",
    "    # 5a. Platzhalter zurücksetzen\n",
    "    python_code_for_json = python_code.replace(\"__DOT__\", \".\")\n",
    "\n",
    "    # 6. Python-Code in JSON schreiben\n",
    "    for entry in entries_for_program(pou_name):\n",
    "        entry[\"program_code\"] = python_code_for_json\n",
    "\n",
    "# -------------------------------------------------\n",
    "# JSON zurückschreiben\n",
    "# -------------------------------------------------\n",
    "json_path.write_text(json.dumps(mapping, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"\\nFertig: program_code wurde für alle passenden Programme gesetzt (ST oder FBD).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb5711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class GlobalVar:\n",
    "    name: str\n",
    "    type: str\n",
    "    init: Optional[str] = None\n",
    "    address: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class GVL:\n",
    "    name: str\n",
    "    globals: List[GlobalVar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4128544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GVLs aus C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\TestProjektTwinCATEvents_objects.json in Datenklassen geladen.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import asdict\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "# Projektverzeichnis anpassen, falls bei dir anders\n",
    "project_dir = Path(r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\")\n",
    "\n",
    "objects_file = project_dir / \"TestProjektTwinCATEvents_objects.json\"\n",
    "gvl_json_file = project_dir / \"gvl_globals.json\"\n",
    "\n",
    "# 1) Objects-JSON laden\n",
    "objects_data = json.loads(objects_file.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# 2) GVL-Datenklassenliste aufbauen\n",
    "gvl_list: List[GVL] = []\n",
    "\n",
    "for obj in objects_data:\n",
    "    # Wir interessieren uns nur für GVL-Objekte\n",
    "    if obj.get(\"kind\") != \"GVL\":\n",
    "        continue\n",
    "\n",
    "    gvl_name = obj.get(\"name\")\n",
    "    if not gvl_name:\n",
    "        continue\n",
    "\n",
    "    globals_raw = obj.get(\"globals\", [])  # Liste von dicts mit name/type/init/address\n",
    "\n",
    "    globals_dc: List[GlobalVar] = []\n",
    "    for gv in globals_raw:\n",
    "        globals_dc.append(\n",
    "            GlobalVar(\n",
    "                name=gv[\"name\"],\n",
    "                type=gv.get(\"type\", \"\"),\n",
    "                init=gv.get(\"init\"),\n",
    "                address=gv.get(\"address\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    gvl_list.append(GVL(name=gvl_name, globals=globals_dc))\n",
    "\n",
    "print(f\"{len(gvl_list)} GVLs aus {objects_file} in Datenklassen geladen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340e9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gvl_globals nach C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\TestProjektTwinCATEvents\\gvl_globals.json geschrieben.\n"
     ]
    }
   ],
   "source": [
    "# 3) Datenklassen -> JSON dumpen\n",
    "gvl_json_file.write_text(\n",
    "    json.dumps([asdict(g) for g in gvl_list], indent=2, ensure_ascii=False),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "print(f\"gvl_globals nach {gvl_json_file} geschrieben.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
