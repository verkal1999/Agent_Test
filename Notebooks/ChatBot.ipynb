{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef57a05",
   "metadata": {},
   "source": [
    "# PLC KG ChatBot (Single Notebook)\n",
    "\n",
    "Dieses Notebook baut einen **einzelnen** ChatBot auf deinem PLC Knowledge Graph (TTL/RDF) auf.\n",
    "\n",
    "Design-Ziele:\n",
    "- **Deterministisch wo möglich** (Tools für Call-Graph, Variable-Info, Trace, Similarity)\n",
    "- **LLM nur als Planner + Text2SPARQL-Fallback**\n",
    "- **Guardrails**: nur SELECT, LIMIT erzwingen, Code-Fences strippen\n",
    "- **Plan → Execute → Answer** Ablauf (debugbar)\n",
    "\n",
    "Referenzen / Best Practices:\n",
    "- Plan-and-Execute Agent Pattern (LangGraph)\n",
    "- SPARQL QA Chains & SPARQL Extraction Helper (LangChain)\n",
    "- Tool-Guardrails & Role-Isolation gegen Prompt-Injection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc85cf",
   "metadata": {},
   "source": [
    "## 0) Installation (optional)\n",
    "Wenn du lokal etwas vermisst, installiere hier die Dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebff1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in d:\\ma_python_agent\\.venv311\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: pandas in d:\\ma_python_agent\\.venv311\\lib\\site-packages (2.3.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-3.0.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core in d:\\ma_python_agent\\.venv311\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-openai in d:\\ma_python_agent\\.venv311\\lib\\site-packages (1.1.7)\n",
      "Requirement already satisfied: langchain-community in d:\\ma_python_agent\\.venv311\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pydantic in d:\\ma_python_agent\\.venv311\\lib\\site-packages (2.12.5)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from rdflib) (3.2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (0.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: colorama in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading pandas-3.0.0-cp312-cp312-win_amd64.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 15.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.6/9.7 MB 18.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 18.4 MB/s  0:00:00\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 914.9/914.9 kB 13.9 MB/s  0:00:00\n",
      "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 20.6 MB/s  0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, pandas, ipywidgets\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [jupyterlab_widgets]\n",
      "  Attempting uninstall: pandas\n",
      "   ---------- ----------------------------- 1/4 [jupyterlab_widgets]\n",
      "    Found existing installation: pandas 2.3.3\n",
      "   ---------- ----------------------------- 1/4 [jupyterlab_widgets]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "    Uninstalling pandas-2.3.3:\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "      Successfully uninstalled pandas-2.3.3\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ------------------------------ --------- 3/4 [ipywidgets]\n",
      "   ---------------------------------------- 4/4 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 pandas-3.0.0 widgetsnbextension-4.0.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\~andas'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Optional: einmalig ausführen (lokal)\n",
    "%pip install -U rdflib pandas ipywidgets langchain-core langchain-openai langchain-community pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0763f7",
   "metadata": {},
   "source": [
    "## 1) Konfiguration\n",
    "Passe die Pfade und Modelle an. Der Code versucht automatisch, eine TTL im selben Ordner oder unter /mnt/data zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "854b9f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTL_PATH = D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\Test2_filled.ttl\n",
      "INDEX_PATH = D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\ChatBotRoutinen\\Test2_filled_routine_index.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# === Pfad zur TTL-Datei ===\n",
    "# 1) Lokal: setze hier deinen absoluten Pfad.\n",
    "TTL_PATH = r\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\Test2_filled.ttl\"\n",
    "filename = \"Test2_filled.ttl\"\n",
    "\n",
    "# 2) Autodetect (z.B. Sandbox)\n",
    "\n",
    "print(\"TTL_PATH =\", TTL_PATH)\n",
    "\n",
    "# === Index-Datei (Similarity / Routine Index) ===\n",
    "index_name = filename.replace(\".ttl\", \"_routine_index.json\")\n",
    "INDEX_DIR = Path(r\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\ChatBotRoutinen\")\n",
    "INDEX_PATH = str(INDEX_DIR / index_name)\n",
    "print(\"INDEX_PATH =\", INDEX_PATH)\n",
    "\n",
    "# === LLM Backend ===\n",
    "# \"openai\" (via langchain_openai). Du kannst später \"gemini\" ergänzen.\n",
    "LLM_BACKEND = \"openai\"\n",
    "\n",
    "# OpenAI (LangChain) Settings\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_TEMPERATURE = 0\n",
    "\n",
    "# Limits\n",
    "MAX_SPARQL_ROWS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03f8c9",
   "metadata": {},
   "source": [
    "## 2) Graph laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d945fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph geladen\n",
      "Triples: 21335\n",
      "Namespaces (Auszug): [('brick', rdflib.term.URIRef('https://brickschema.org/schema/Brick#')), ('csvw', rdflib.term.URIRef('http://www.w3.org/ns/csvw#')), ('dc', rdflib.term.URIRef('http://purl.org/dc/elements/1.1/')), ('dcat', rdflib.term.URIRef('http://www.w3.org/ns/dcat#')), ('dcmitype', rdflib.term.URIRef('http://purl.org/dc/dcmitype/')), ('dcterms', rdflib.term.URIRef('http://purl.org/dc/terms/')), ('dcam', rdflib.term.URIRef('http://purl.org/dc/dcam/')), ('doap', rdflib.term.URIRef('http://usefulinc.com/ns/doap#')), ('foaf', rdflib.term.URIRef('http://xmlns.com/foaf/0.1/')), ('geo', rdflib.term.URIRef('http://www.opengis.net/ont/geosparql#'))]\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "g = Graph()\n",
    "g.parse(TTL_PATH, format=\"turtle\")\n",
    "\n",
    "print(\"✅ Graph geladen\")\n",
    "print(\"Triples:\", len(g))\n",
    "print(\"Namespaces (Auszug):\", list(g.namespaces())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f3576",
   "metadata": {},
   "source": [
    "## 3) Schema Card (kompakte KG-Übersicht)\n",
    "Diese Übersicht geht in Planner und Text2SPARQL Prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e2dc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP CLASSES (rdf:type):\n",
      "  - owl:NamedIndividual: 3640\n",
      "  - ap:class_Variable: 1276\n",
      "  - ap:class_ParameterAssignment: 988\n",
      "  - ap:class_Port: 595\n",
      "  - ap:class_FBInstance: 267\n",
      "  - ap:class_POUCall: 190\n",
      "  - ap:class_SignalSource: 154\n",
      "  - ap:class_PortInstance: 98\n",
      "  - ap:class_IOChannel: 79\n",
      "  - ap:class_FBType: 57\n",
      "  - ap:class_Skill: 48\n",
      "  - ap:class_CustomFBType: 47\n",
      "  - owl:DatatypeProperty: 35\n",
      "  - owl:ObjectProperty: 31\n",
      "  - ap:class_SkillImplementationHypothesis: 31\n",
      "\n",
      "TOP PROPERTIES:\n",
      "  - rdf:type: 7612\n",
      "  - dp:hasVariableName: 1364\n",
      "  - dp:hasVariableType: 1246\n",
      "  - op:hasInternalVariable: 1158\n",
      "  - op:usesVariable: 1158\n",
      "  - op:hasAssignment: 988\n",
      "  - op:assignsFrom: 988\n",
      "  - op:assignsToPort: 930\n",
      "  - op:hasPort: 595\n",
      "  - dp:hasPortDirection: 595\n",
      "  - dp:hasPortName: 595\n",
      "  - dp:hasPortType: 595\n",
      "  - op:implementsPort: 555\n",
      "  - op:isInstanceOfFBType: 267\n",
      "  - op:representsFBInstance: 267\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from rdflib.namespace import RDF\n",
    "\n",
    "def schema_card(graph: Graph, top_n: int = 15) -> str:\n",
    "    pred_counts = Counter()\n",
    "    type_counts = Counter()\n",
    "\n",
    "    for s, p, o in graph:\n",
    "        try:\n",
    "            pred_counts[graph.qname(p)] += 1\n",
    "        except Exception:\n",
    "            pred_counts[str(p)] += 1\n",
    "\n",
    "        if p == RDF.type:\n",
    "            try:\n",
    "                type_counts[graph.qname(o)] += 1\n",
    "            except Exception:\n",
    "                type_counts[str(o)] += 1\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"TOP CLASSES (rdf:type):\")\n",
    "    for k, v in type_counts.most_common(top_n):\n",
    "        lines.append(f\"  - {k}: {v}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"TOP PROPERTIES:\")\n",
    "    for k, v in pred_counts.most_common(top_n):\n",
    "        lines.append(f\"  - {k}: {v}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "SCHEMA_CARD = schema_card(g, top_n=15)\n",
    "print(SCHEMA_CARD[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468543f7",
   "metadata": {},
   "source": [
    "## 4) SPARQL Helper (Guardrails)\n",
    "- nur SELECT\n",
    "- blockt UPDATE/Service\n",
    "- erzwingt LIMIT\n",
    "- Ergebnisse als Liste von Dicts\n",
    "\n",
    "Wenn ein LLM SPARQL in Codeblöcke packt, extrahieren wir es robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "395fda1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "DEFAULT_PREFIXES = \"\"\"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX ag:  <http://www.semanticweb.org/AgentProgramParams/>\n",
    "PREFIX dp:  <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
    "PREFIX op:  <http://www.semanticweb.org/AgentProgramParams/op_>\n",
    "\"\"\"\n",
    "\n",
    "def _normalize_ws(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def enforce_select_only(query: str, max_limit: int = 200) -> str:\n",
    "    q = query.strip()\n",
    "    q_u = _normalize_ws(q).upper()\n",
    "\n",
    "    if not (q_u.startswith(\"PREFIX\") or q_u.startswith(\"SELECT\")):\n",
    "        raise ValueError(\"Only SELECT queries are allowed (optionally with PREFIX).\")\n",
    "\n",
    "    forbidden = [\n",
    "        \"INSERT\",\"DELETE\",\"LOAD\",\"CLEAR\",\"CREATE\",\"DROP\",\"MOVE\",\"COPY\",\"ADD\",\n",
    "        \"SERVICE\",\"WITH\",\"USING\",\"GRAPH\"\n",
    "    ]\n",
    "    for kw in forbidden:\n",
    "        if re.search(rf\"\\b{kw}\\b\", q_u):\n",
    "            raise ValueError(f\"Forbidden SPARQL keyword detected: {kw}\")\n",
    "\n",
    "    m = re.search(r\"\\bLIMIT\\s+(\\d+)\\b\", q_u)\n",
    "    if m:\n",
    "        lim = int(m.group(1))\n",
    "        if lim > max_limit:\n",
    "            q = re.sub(r\"(?i)\\bLIMIT\\s+\\d+\\b\", f\"LIMIT {max_limit}\", q)\n",
    "    else:\n",
    "        q = q.rstrip() + f\"\\nLIMIT {max_limit}\\n\"\n",
    "    return q\n",
    "\n",
    "def strip_code_fences(text: str) -> str:\n",
    "    t = text.strip()\n",
    "    t = re.sub(r\"^```[a-zA-Z]*\\s*\", \"\", t)\n",
    "    t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    return t.strip()\n",
    "\n",
    "try:\n",
    "    from langchain_community.chains.graph_qa.neptune_sparql import extract_sparql as lc_extract_sparql\n",
    "except Exception:\n",
    "    lc_extract_sparql = None\n",
    "\n",
    "def extract_sparql_from_llm(text: str) -> str:\n",
    "    if lc_extract_sparql is not None:\n",
    "        try:\n",
    "            return lc_extract_sparql(text).strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    t = strip_code_fences(text)\n",
    "    m = re.search(r\"(SELECT\\s+.*)\", t, flags=re.IGNORECASE | re.DOTALL)\n",
    "    return (m.group(1).strip() if m else t)\n",
    "\n",
    "def sparql_select_raw(query: str, max_rows: int = 200) -> List[Dict[str, Any]]:\n",
    "    q = query.strip()\n",
    "    if \"PREFIX\" not in q.upper():\n",
    "        q = DEFAULT_PREFIXES + \"\\n\" + q\n",
    "    q = enforce_select_only(q, max_limit=max_rows)\n",
    "\n",
    "    res = g.query(q)\n",
    "    vars_ = [str(v) for v in res.vars]\n",
    "\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for row in res:\n",
    "        item = {}\n",
    "        for i, v in enumerate(vars_):\n",
    "            val = row[i]\n",
    "            item[v] = None if val is None else str(val)\n",
    "        out.append(item)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7943b2",
   "metadata": {},
   "source": [
    "## 5) Deterministische Tools (ohne LLM)\n",
    "Diese Tools beantworten typische Fragen, ohne dass das LLM freie SPARQL generieren muss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fec1deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Set, Tuple\n",
    "from rdflib import URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF\n",
    "\n",
    "AG = Namespace(\"http://www.semanticweb.org/AgentProgramParams/\")\n",
    "DP = Namespace(\"http://www.semanticweb.org/AgentProgramParams/dp_\")\n",
    "OP = Namespace(\"http://www.semanticweb.org/AgentProgramParams/op_\")\n",
    "\n",
    "@dataclass\n",
    "class SensorSnapshot:\n",
    "    program_name: str\n",
    "    sensor_values: Dict[str, Any]\n",
    "\n",
    "@dataclass\n",
    "class RoutineSignature:\n",
    "    pou_name: str\n",
    "    reachable_pous: List[str]\n",
    "    called_pou_names: List[str]\n",
    "    used_variable_names: List[str]\n",
    "    hardware_addresses: List[str]\n",
    "    port_names: List[str]\n",
    "\n",
    "    def as_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"pou_name\": self.pou_name,\n",
    "            \"reachable_pous\": self.reachable_pous,\n",
    "            \"called_pou_names\": self.called_pou_names,\n",
    "            \"used_variable_names\": self.used_variable_names,\n",
    "            \"hardware_addresses\": self.hardware_addresses,\n",
    "            \"port_names\": self.port_names,\n",
    "        }\n",
    "\n",
    "class KGStore:\n",
    "    def __init__(self, graph: Graph):\n",
    "        self.g = graph\n",
    "        self._pou_by_name: Dict[str, URIRef] = {}\n",
    "        self._build_cache()\n",
    "\n",
    "    def _build_cache(self) -> None:\n",
    "        for pou, _, name in self.g.triples((None, DP.hasPOUName, None)):\n",
    "            if isinstance(name, Literal):\n",
    "                self._pou_by_name[str(name)] = pou\n",
    "\n",
    "    def pou_uri_by_name(self, pou_name: str) -> Optional[URIRef]:\n",
    "        return self._pou_by_name.get(pou_name)\n",
    "\n",
    "    def pou_name(self, pou_uri: URIRef) -> str:\n",
    "        v = self.g.value(pou_uri, DP.hasPOUName)\n",
    "        return str(v) if v else str(pou_uri)\n",
    "\n",
    "    def get_reachable_pous(self, root_pou_uri: URIRef) -> Set[URIRef]:\n",
    "        visited: Set[URIRef] = set()\n",
    "        queue: List[URIRef] = [root_pou_uri]\n",
    "        while queue:\n",
    "            cur = queue.pop(0)\n",
    "            if cur in visited:\n",
    "                continue\n",
    "            visited.add(cur)\n",
    "            for call in self.g.objects(cur, OP.containsPOUCall):\n",
    "                for called in self.g.objects(call, OP.callsPOU):\n",
    "                    if isinstance(called, URIRef) and called not in visited:\n",
    "                        queue.append(called)\n",
    "        return visited\n",
    "\n",
    "    def get_called_pous(self, pou_uri: URIRef) -> Set[URIRef]:\n",
    "        called: Set[URIRef] = set()\n",
    "        for call in self.g.objects(pou_uri, OP.containsPOUCall):\n",
    "            for target in self.g.objects(call, OP.callsPOU):\n",
    "                if isinstance(target, URIRef):\n",
    "                    called.add(target)\n",
    "        return called\n",
    "\n",
    "    def get_used_variables(self, pou_uri: URIRef) -> Set[URIRef]:\n",
    "        vars_: Set[URIRef] = set()\n",
    "        for v in self.g.objects(pou_uri, OP.usesVariable):\n",
    "            if isinstance(v, URIRef):\n",
    "                vars_.add(v)\n",
    "        for v in self.g.objects(pou_uri, OP.hasInternalVariable):\n",
    "            if isinstance(v, URIRef):\n",
    "                vars_.add(v)\n",
    "        return vars_\n",
    "\n",
    "    def get_variable_names(self, var_uri: URIRef) -> Set[str]:\n",
    "        names: Set[str] = set()\n",
    "        for _, _, name in self.g.triples((var_uri, DP.hasVariableName, None)):\n",
    "            if isinstance(name, Literal):\n",
    "                names.add(str(name))\n",
    "        return names\n",
    "\n",
    "    def get_hardware_address(self, var_uri: URIRef) -> Optional[str]:\n",
    "        v = self.g.value(var_uri, DP.hasHardwareAddress)\n",
    "        return str(v) if v else None\n",
    "\n",
    "    def get_ports_of_pou(self, pou_uri: URIRef) -> Set[URIRef]:\n",
    "        ports: Set[URIRef] = set()\n",
    "        for p in self.g.objects(pou_uri, OP.hasPort):\n",
    "            if isinstance(p, URIRef):\n",
    "                ports.add(p)\n",
    "        return ports\n",
    "\n",
    "    def get_port_name(self, port_uri: URIRef) -> str:\n",
    "        v = self.g.value(port_uri, DP.hasPortName)\n",
    "        return str(v) if v else \"\"\n",
    "\n",
    "kg = KGStore(g)\n",
    "\n",
    "def tool_list_programs() -> List[Dict[str, Any]]:\n",
    "    q = \"\"\"\n",
    "    SELECT ?programName WHERE {\n",
    "      ?program rdf:type ag:class_Program ;\n",
    "               dp:hasProgramName ?programName .\n",
    "    } ORDER BY ?programName\n",
    "    \"\"\"\n",
    "    return sparql_select_raw(q, max_rows=MAX_SPARQL_ROWS)\n",
    "\n",
    "def tool_get_program_overview(program_name: str) -> List[Dict[str, Any]]:\n",
    "    q = f\"\"\"\n",
    "    SELECT ?report WHERE {{\n",
    "      ?program rdf:type ag:class_Program ;\n",
    "               dp:hasProgramName \\\"{program_name}\\\" .\n",
    "      OPTIONAL {{ ?program dp:hasConsistencyReport ?report }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return sparql_select_raw(q, max_rows=MAX_SPARQL_ROWS)\n",
    "\n",
    "def tool_get_called_pous(program_name: str) -> List[Dict[str, Any]]:\n",
    "    q = f\"\"\"\n",
    "    SELECT DISTINCT ?calleeName WHERE {{\n",
    "      ?program rdf:type ag:class_Program ;\n",
    "               dp:hasProgramName \\\"{program_name}\\\" ;\n",
    "               op:containsPOUCall ?call .\n",
    "      ?call op:callsPOU ?callee .\n",
    "      OPTIONAL {{ ?callee dp:hasPOUName ?calleeName }}\n",
    "    }} ORDER BY ?calleeName\n",
    "    \"\"\"\n",
    "    return sparql_select_raw(q, max_rows=MAX_SPARQL_ROWS)\n",
    "\n",
    "def tool_get_pou_code(pou_name: str) -> List[Dict[str, Any]]:\n",
    "    q = f\"\"\"\n",
    "    SELECT ?lang ?code ?report WHERE {{\n",
    "      ?pou dp:hasPOUName \\\"{pou_name}\\\" .\n",
    "      OPTIONAL {{ ?pou dp:hasPOULanguage ?lang }}\n",
    "      OPTIONAL {{ ?pou dp:hasPOUCode ?code }}\n",
    "      OPTIONAL {{ ?pou dp:hasConsistencyReport ?report }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return sparql_select_raw(q, max_rows=MAX_SPARQL_ROWS)\n",
    "\n",
    "def tool_search_variables(name_contains: str) -> List[Dict[str, Any]]:\n",
    "    needle = name_contains.replace('\"', '\\\\\"')\n",
    "    q = f\"\"\"\n",
    "    SELECT DISTINCT ?name ?type ?addr WHERE {{\n",
    "      ?var rdf:type ag:class_Variable ;\n",
    "           dp:hasVariableName ?name ;\n",
    "           dp:hasVariableType ?type .\n",
    "      FILTER(CONTAINS(LCASE(STR(?name)), LCASE(\\\"{needle}\\\")))\n",
    "      OPTIONAL {{ ?var dp:hasHardwareAddress ?addr }}\n",
    "    }} ORDER BY ?name\n",
    "    \"\"\"\n",
    "    return sparql_select_raw(q, max_rows=MAX_SPARQL_ROWS)\n",
    "\n",
    "def tool_get_variable_trace(name_contains: str) -> List[Dict[str, Any]]:\n",
    "    needle = name_contains.replace('\"', '\\\\\"')\n",
    "    q = f\"\"\"\n",
    "    SELECT DISTINCT ?varName ?exprText ?calleeName WHERE {{\n",
    "      ?var rdf:type ag:class_Variable ;\n",
    "           dp:hasVariableName ?varName .\n",
    "      FILTER(CONTAINS(LCASE(STR(?varName)), LCASE(\\\"{needle}\\\")))\n",
    "\n",
    "      OPTIONAL {{\n",
    "        ?expr rdf:type ag:class_Expression ;\n",
    "              dp:hasExpressionText ?exprText ;\n",
    "              op:isExpressionCreatedBy ?var .\n",
    "        OPTIONAL {{\n",
    "          ?assign rdf:type ag:class_ParameterAssignment ;\n",
    "                  op:assignsFrom ?expr .\n",
    "          OPTIONAL {{\n",
    "            ?pouCall rdf:type ag:class_POUCall ;\n",
    "                     op:hasAssignment ?assign ;\n",
    "                     op:callsPOU ?callee .\n",
    "            OPTIONAL {{ ?callee dp:hasPOUName ?calleeName }}\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return sparql_select_raw(q, max_rows=MAX_SPARQL_ROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43009112",
   "metadata": {},
   "source": [
    "## 6) Routine-Signaturen + Similarity Index\n",
    "Speichert Signaturen in einer JSON-Datei neben der TTL, damit Similarity Checks schnell sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c37ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RoutineIndex neu gebaut & gespeichert: D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\ChatBotRoutinen\\Test2_filled_routine_index.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def jaccard(a: Set[str], b: Set[str]) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "class SignatureExtractor:\n",
    "    def __init__(self, kg: KGStore):\n",
    "        self.kg = kg\n",
    "\n",
    "    def extract_signature(self, pou_name: str) -> RoutineSignature:\n",
    "        pou_uri = self.kg.pou_uri_by_name(pou_name)\n",
    "        if pou_uri is None:\n",
    "            raise ValueError(f\"POU '{pou_name}' not found in KG.\")\n",
    "\n",
    "        reachable = self.kg.get_reachable_pous(pou_uri)\n",
    "\n",
    "        reachable_names: Set[str] = set()\n",
    "        called_names: Set[str] = set()\n",
    "        used_var_names: Set[str] = set()\n",
    "        hw_addrs: Set[str] = set()\n",
    "        port_names: Set[str] = set()\n",
    "\n",
    "        for rp in reachable:\n",
    "            reachable_names.add(self.kg.pou_name(rp))\n",
    "            for callee in self.kg.get_called_pous(rp):\n",
    "                called_names.add(self.kg.pou_name(callee))\n",
    "            for var in self.kg.get_used_variables(rp):\n",
    "                used_var_names |= self.kg.get_variable_names(var)\n",
    "                ha = self.kg.get_hardware_address(var)\n",
    "                if ha:\n",
    "                    hw_addrs.add(ha)\n",
    "            for port in self.kg.get_ports_of_pou(rp):\n",
    "                pn = self.kg.get_port_name(port)\n",
    "                if pn:\n",
    "                    port_names.add(pn)\n",
    "\n",
    "        return RoutineSignature(\n",
    "            pou_name=pou_name,\n",
    "            reachable_pous=sorted(reachable_names),\n",
    "            called_pou_names=sorted(called_names),\n",
    "            used_variable_names=sorted(used_var_names),\n",
    "            hardware_addresses=sorted(hw_addrs),\n",
    "            port_names=sorted(port_names),\n",
    "        )\n",
    "\n",
    "class RoutineIndex:\n",
    "    def __init__(self, signatures: List[RoutineSignature]):\n",
    "        self.signatures = signatures\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        Path(path).write_text(\n",
    "            json.dumps([s.as_dict() for s in self.signatures], indent=2, ensure_ascii=False),\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path: str) -> \"RoutineIndex\":\n",
    "        data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "        sigs = [RoutineSignature(**d) for d in data]\n",
    "        return RoutineIndex(sigs)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_kg(kg: KGStore, only_pous: Optional[List[str]] = None) -> \"RoutineIndex\":\n",
    "        extractor = SignatureExtractor(kg)\n",
    "        if only_pous is None:\n",
    "            only_pous = sorted(kg._pou_by_name.keys())\n",
    "\n",
    "        sigs: List[RoutineSignature] = []\n",
    "        for name in only_pous:\n",
    "            try:\n",
    "                sigs.append(extractor.extract_signature(name))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return RoutineIndex(sigs)\n",
    "\n",
    "    def find_similar(self, target: RoutineSignature, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        tgt_hw = set(target.hardware_addresses)\n",
    "        tgt_vars = set(target.used_variable_names)\n",
    "        tgt_called = set(target.called_pou_names)\n",
    "\n",
    "        scored: List[Tuple[float, RoutineSignature]] = []\n",
    "        for cand in self.signatures:\n",
    "            cand_hw = set(cand.hardware_addresses)\n",
    "            cand_vars = set(cand.used_variable_names)\n",
    "            cand_called = set(cand.called_pou_names)\n",
    "\n",
    "            sim_hw = jaccard(tgt_hw, cand_hw) if (tgt_hw or cand_hw) else 0.0\n",
    "            sim_vars = jaccard(tgt_vars, cand_vars)\n",
    "            sim_called = jaccard(tgt_called, cand_called)\n",
    "\n",
    "            score = 0.55 * sim_hw + 0.25 * sim_vars + 0.20 * sim_called\n",
    "            scored.append((score, cand))\n",
    "\n",
    "        scored.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [{\"score\": round(s, 4), \"pou_name\": r.pou_name} for s, r in scored[:top_k]]\n",
    "\n",
    "def classify_checkable_sensors(snapshot: SensorSnapshot, sig: RoutineSignature) -> Dict[str, str]:\n",
    "    checkable_set = set(sig.used_variable_names) | set(sig.hardware_addresses)\n",
    "    return {k: (\"checkable\" if k in checkable_set else \"not_checkable\") for k in snapshot.sensor_values.keys()}\n",
    "\n",
    "# Build / Load index\n",
    "from pathlib import Path\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "\n",
    "p = Path(INDEX_PATH)\n",
    "\n",
    "def try_load_index(path: Path):\n",
    "    try:\n",
    "        if not path.exists() or path.stat().st_size == 0:\n",
    "            return None\n",
    "        # BOM-sicher + Whitespace entfernen\n",
    "        raw = path.read_text(encoding=\"utf-8-sig\").strip()\n",
    "        if not raw:\n",
    "            return None\n",
    "        data = json.loads(raw)\n",
    "        sigs = [RoutineSignature(**d) for d in data]\n",
    "        return RoutineIndex(sigs)\n",
    "    except (JSONDecodeError, UnicodeError):\n",
    "        return None\n",
    "\n",
    "routine_index = try_load_index(p)\n",
    "if routine_index is None:\n",
    "    routine_index = RoutineIndex.build_from_kg(kg)\n",
    "    routine_index.save(str(p))\n",
    "    print(\"✅ RoutineIndex neu gebaut & gespeichert:\", p)\n",
    "else:\n",
    "    print(\"✅ RoutineIndex geladen:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f740a5c",
   "metadata": {},
   "source": [
    "## 7) LLM Setup\n",
    "Planner + Text2SPARQL + Answerer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "057dbd98",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _invoke\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLLM_BACKEND nicht unterstützt. Setze LLM_BACKEND=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m'\u001b[39m\u001b[33m oder erweitere den Wrapper.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m llm_invoke = \u001b[43mget_llm_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ LLM Wrapper bereit:\u001b[39m\u001b[33m\"\u001b[39m, LLM_BACKEND, OPENAI_MODEL)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_llm_invoke\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBitte installiere langchain-openai + langchain-core.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpip install -U langchain-openai langchain-core\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPENAI_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPENAI_TEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(system: \u001b[38;5;28mstr\u001b[39m, user: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     17\u001b[39m     msgs = [SystemMessage(content=system), HumanMessage(content=user)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_core\\load\\serializable.py:117\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:996\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    986\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(\n\u001b[32m    987\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    988\u001b[39m         )\n\u001b[32m    989\u001b[39m     async_specific = {\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client\n\u001b[32m    991\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_async_httpx_client(\n\u001b[32m   (...)\u001b[39m\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    995\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[38;5;28mself\u001b[39m.root_async_client.chat.completions\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\openai\\_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def get_llm_invoke() -> Callable[[str, str], str]:\n",
    "    if LLM_BACKEND == \"openai\":\n",
    "        try:\n",
    "            from langchain_openai import ChatOpenAI\n",
    "            from langchain_core.messages import SystemMessage, HumanMessage\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Bitte installiere langchain-openai + langchain-core.\\n\"\n",
    "                \"pip install -U langchain-openai langchain-core\"\n",
    "            ) from e\n",
    "\n",
    "        llm = ChatOpenAI(model=OPENAI_MODEL, temperature=OPENAI_TEMPERATURE, max_tokens=1200)\n",
    "\n",
    "        def _invoke(system: str, user: str) -> str:\n",
    "            msgs = [SystemMessage(content=system), HumanMessage(content=user)]\n",
    "            return llm.invoke(msgs).content\n",
    "\n",
    "        return _invoke\n",
    "\n",
    "    raise ValueError(\"LLM_BACKEND nicht unterstützt. Setze LLM_BACKEND='openai' oder erweitere den Wrapper.\")\n",
    "\n",
    "llm_invoke = get_llm_invoke()\n",
    "print(\"✅ LLM Wrapper bereit:\", LLM_BACKEND, OPENAI_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad45e0a",
   "metadata": {},
   "source": [
    "## 8) Text2SPARQL (Fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT2SPARQL_SYSTEM = f\"\"\"\n",
    "Du erzeugst ausschließlich eine SPARQL SELECT Query für einen RDF Knowledge Graph eines SPS Programms.\n",
    "Regeln:\n",
    "- Gib NUR SPARQL zurück (keine Erklärung, kein Markdown).\n",
    "- Nur SELECT (kein INSERT/DELETE/UPDATE, kein SERVICE).\n",
    "- Nutze die Prefixes: rdf, ag, dp, op.\n",
    "Schema Card:\n",
    "{SCHEMA_CARD}\n",
    "\"\"\"\n",
    "\n",
    "def text2sparql(question: str) -> str:\n",
    "    raw = llm_invoke(TEXT2SPARQL_SYSTEM, question)\n",
    "    return extract_sparql_from_llm(raw).strip()\n",
    "\n",
    "def tool_text2sparql_select(question: str, max_rows: int = 50) -> Dict[str, Any]:\n",
    "    q = text2sparql(question)\n",
    "    rows = sparql_select_raw(q, max_rows=max_rows)\n",
    "    return {\"sparql\": q, \"rows\": rows}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721832c",
   "metadata": {},
   "source": [
    "## 9) Tools + Planner + Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_exception_prep(program_name: str, snapshot: Dict[str, Any], top_k: int = 5) -> Dict[str, Any]:\n",
    "    extractor = SignatureExtractor(kg)\n",
    "    sig = extractor.extract_signature(program_name)\n",
    "    snap = SensorSnapshot(program_name=program_name, sensor_values=snapshot)\n",
    "    check_map = classify_checkable_sensors(snap, sig)\n",
    "    similar = routine_index.find_similar(sig, top_k=top_k)\n",
    "    return {\n",
    "        \"signature\": sig.as_dict(),\n",
    "        \"checkable\": check_map,\n",
    "        \"similar\": similar,\n",
    "    }\n",
    "\n",
    "TOOLS = {\n",
    "    \"list_programs\": lambda: tool_list_programs(),\n",
    "    \"program_overview\": lambda program_name: tool_get_program_overview(program_name),\n",
    "    \"called_pous\": lambda program_name: tool_get_called_pous(program_name),\n",
    "    \"pou_code\": lambda pou_name: tool_get_pou_code(pou_name),\n",
    "    \"search_variables\": lambda name_contains: tool_search_variables(name_contains),\n",
    "    \"variable_trace\": lambda name_contains: tool_get_variable_trace(name_contains),\n",
    "    \"text2sparql_select\": lambda question, max_rows=50: tool_text2sparql_select(question, max_rows=max_rows),\n",
    "    \"exception_prep\": lambda program_name, snapshot, top_k=5: tool_exception_prep(program_name, snapshot, top_k=top_k),\n",
    "}\n",
    "\n",
    "TOOL_DESCRIPTIONS = \"\"\"\n",
    "Erlaubte Tools:\n",
    "- list_programs()\n",
    "- program_overview(program_name)\n",
    "- called_pous(program_name)\n",
    "- pou_code(pou_name)\n",
    "- search_variables(name_contains)\n",
    "- variable_trace(name_contains)\n",
    "- text2sparql_select(question, max_rows)\n",
    "- exception_prep(program_name, snapshot, top_k)\n",
    "\n",
    "Regeln:\n",
    "- Wenn eine Frage mit den Tools beantwortbar ist, nutze Tools, nicht freie SPARQL.\n",
    "- text2sparql_select ist Fallback.\n",
    "- Maximal 3 Schritte.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbe521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PLANNER_SYSTEM = f\"\"\"\n",
    "Du bist ein Planner für einen PLC Knowledge-Graph ChatBot.\n",
    "Du planst Tool-Aufrufe als JSON.\n",
    "{TOOL_DESCRIPTIONS}\n",
    "\n",
    "Ausgabeformat (NUR JSON, kein Markdown!):\n",
    "{{\n",
    "  \"steps\": [\n",
    "    {{\"tool\": \"list_programs\", \"args\": {{}}}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Heuristiken:\n",
    "- Wenn User Sensorwerte/Statuswerte nennt oder 'Exception'/'Fehlerbild' -> exception_prep\n",
    "- Wenn User nach 'welche POUs', 'aufrufen', 'Call-Graph' -> called_pous\n",
    "- Wenn User nach 'Code' -> pou_code\n",
    "- Wenn User nach 'Variable', 'Adresse', 'I/O' -> search_variables oder variable_trace\n",
    "- Sonst text2sparql_select\n",
    "Max 3 Steps.\n",
    "\"\"\"\n",
    "\n",
    "def safe_json_loads(s: str) -> Dict[str, Any]:\n",
    "    t = strip_code_fences(s)\n",
    "    m = re.search(r\"(\\{.*\\})\", t, flags=re.DOTALL)\n",
    "    t = m.group(1) if m else t\n",
    "    return json.loads(t)\n",
    "\n",
    "def make_plan(user_message: str, max_retries: int = 2) -> Dict[str, Any]:\n",
    "    user = user_message.strip()\n",
    "    last_err = None\n",
    "\n",
    "    for _ in range(max_retries + 1):\n",
    "        out = llm_invoke(PLANNER_SYSTEM, user)\n",
    "        try:\n",
    "            plan = safe_json_loads(out)\n",
    "            if \"steps\" not in plan:\n",
    "                raise ValueError(\"Missing 'steps'\")\n",
    "            return plan\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            repair_system = \"Du reparierst JSON. Gib NUR gültiges JSON zurück.\"\n",
    "            repair_user = f\"Repariere zu gültigem JSON:\\n{out}\"\n",
    "            out = llm_invoke(repair_system, repair_user)\n",
    "\n",
    "    raise RuntimeError(f\"Planner failed to return valid JSON: {last_err}\")\n",
    "\n",
    "def execute_plan(plan: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    results: Dict[str, Any] = {}\n",
    "    for i, step in enumerate(plan.get(\"steps\", []), start=1):\n",
    "        tool = step.get(\"tool\")\n",
    "        args = step.get(\"args\", {}) or {}\n",
    "        fn = TOOLS.get(tool)\n",
    "        if fn is None:\n",
    "            results[f\"step_{i}_{tool}\"] = {\"error\": \"unknown tool\", \"tool\": tool, \"args\": args}\n",
    "            continue\n",
    "        try:\n",
    "            results[f\"step_{i}_{tool}\"] = fn(**args)\n",
    "        except Exception as e:\n",
    "            results[f\"step_{i}_{tool}\"] = {\"error\": str(e), \"tool\": tool, \"args\": args}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc31ae",
   "metadata": {},
   "source": [
    "## 10) Answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21783b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_SYSTEM = \"\"\"\n",
    "Du bist ein SPS-Assistent. Antworte auf Deutsch.\n",
    "WICHTIG:\n",
    "- Nutze ausschließlich die Fakten aus den Tool-Ergebnissen.\n",
    "- Wenn Daten fehlen oder leer sind: sag klar, dass der KG dazu nichts liefert.\n",
    "- Wenn SPARQL Ergebnisse da sind: fasse sie strukturiert zusammen (max 10 Punkte).\n",
    "- Keine erfundenen Klassen/Properties.\n",
    "\"\"\"\n",
    "\n",
    "def make_answer(user_message: str, plan: Dict[str, Any], tool_results: Dict[str, Any]) -> str:\n",
    "    payload = {\n",
    "        \"question\": user_message,\n",
    "        \"plan\": plan,\n",
    "        \"tool_results\": tool_results,\n",
    "    }\n",
    "    user = \"Hier sind Plan und Tool-Ergebnisse als JSON:\\n\" + json.dumps(payload, ensure_ascii=False, indent=2)[:12000]\n",
    "    return llm_invoke(ANSWER_SYSTEM, user)\n",
    "\n",
    "def chat_once(user_message: str, debug: bool = True) -> Dict[str, Any]:\n",
    "    plan = make_plan(user_message)\n",
    "    results = execute_plan(plan)\n",
    "    answer = make_answer(user_message, plan, results)\n",
    "    out = {\"answer\": answer}\n",
    "    if debug:\n",
    "        out[\"plan\"] = plan\n",
    "        out[\"tool_results\"] = results\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90278312",
   "metadata": {},
   "source": [
    "## 11) Chat UI (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "debug_toggle = widgets.Checkbox(value=True, description=\"Debug (Plan + Tool Results anzeigen)\")\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder=\"Frage stellen... (z.B. 'Welche POUs ruft HRL_SkillSet auf?')\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"90px\")\n",
    ")\n",
    "send_btn = widgets.Button(description=\"Send\", button_style=\"primary\")\n",
    "out = widgets.Output()\n",
    "\n",
    "display(debug_toggle, input_box, send_btn, out)\n",
    "\n",
    "def on_send(_):\n",
    "    out.clear_output()\n",
    "    user_msg = input_box.value.strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "\n",
    "    with out:\n",
    "        print(\"User:\", user_msg)\n",
    "        resp = chat_once(user_msg, debug=debug_toggle.value)\n",
    "        display(Markdown(\"### Antwort\"))\n",
    "        print(resp[\"answer\"])\n",
    "\n",
    "        if debug_toggle.value:\n",
    "            display(Markdown(\"### Plan\"))\n",
    "            print(json.dumps(resp[\"plan\"], ensure_ascii=False, indent=2))\n",
    "            display(Markdown(\"### Tool Results (gekürzt)\"))\n",
    "            print(json.dumps(resp[\"tool_results\"], ensure_ascii=False, indent=2)[:8000])\n",
    "\n",
    "send_btn.on_click(on_send)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055455b",
   "metadata": {},
   "source": [
    "## 12) Quick Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    \"Welche Programme gibt es?\",\n",
    "    \"Welche POUs ruft HRL_SkillSet auf?\",\n",
    "    \"Zeig mir den Code von JobMethode_Schablone\",\n",
    "    \"Suche Variablen, die 'NotAus' enthalten\",\n",
    "    \"Trace für DI04_EncoderStart02\",\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    print(\"\\n---\\n\", q)\n",
    "    try:\n",
    "        resp = chat_once(q, debug=False)\n",
    "        print(resp[\"answer\"][:700])\n",
    "    except Exception as e:\n",
    "        print(\"Fehler:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
