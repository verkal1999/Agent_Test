{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062a0392",
   "metadata": {},
   "source": [
    "# MSRGuard ChatBot Workbench (Notebook UI)\n",
    "\n",
    "Dieses Notebook stellt ein **interaktives UI (ipywidgets)** bereit, um deinen PLC-Knowledge-Graph-ChatBot separat zu testen und weiterzuentwickeln.\n",
    "\n",
    "Was du damit machen kannst:\n",
    "\n",
    "- KG laden (TTL) und **Tool-Registry** initialisieren\n",
    "- Einzelne Tools **auswählen und mit JSON-Args ausführen** (inkl. Output)\n",
    "- **Neue Tools/Methoden** als Code einfügen und direkt **registrieren** (ohne Neustart)\n",
    "- Optional: einen **Chat-Loop** nutzen (Planner → Tools → Antwort), wenn `OPENAI_API_KEY` gesetzt ist\n",
    "- Optional: **Incident Session** (EvD2 Bootstrap) aus `excH_chatbot.py` wie im Desktop-UI, aber im Notebook\n",
    "\n",
    "> Hinweis: Das UI ist bewusst „Werkbank“-artig gehalten: Du kannst es leicht erweitern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: ipywidgets installieren (falls nötig)\n",
    "# In vielen Jupyter-Setups ist ipywidgets bereits vorhanden.\n",
    "# Falls Import fehlschlägt: pip install ipywidgets\n",
    "\n",
    "import sys, os, json, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output, Markdown\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"ipywidgets ist nicht verfügbar. Bitte installiere es via: pip install ipywidgets und starte den Kernel neu.\"\n",
    "    ) from e\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "DEFAULT_OPENAI_KEY_FILE = r\"C:\\Users\\Alexander Verkhov\\Desktop\\OpenAI API Key.txt\"\n",
    "\n",
    "def set_openai_key_from_file(path: str = DEFAULT_OPENAI_KEY_FILE) -> str:\n",
    "    \"\"\"\n",
    "    Liest den OpenAI API Key aus einer Datei und setzt os.environ[\"OPENAI_API_KEY\"].\n",
    "    Unterstützt typische Formate wie:\n",
    "      - sk-...\n",
    "      - sk-proj-...\n",
    "      - OPENAI_API_KEY=sk-...\n",
    "    \"\"\"\n",
    "    p = Path(path).expanduser().resolve()\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Key-Datei nicht gefunden: {p}\")\n",
    "\n",
    "    raw = p.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "\n",
    "    # Key extrahieren (robust gegen \"OPENAI_API_KEY=...\" und Whitespace)\n",
    "    m = re.search(r\"(sk-(?:proj-)?[A-Za-z0-9_\\-]{20,})\", raw)\n",
    "    if not m:\n",
    "        raise ValueError(\n",
    "            \"Kein OpenAI API Key im File gefunden. Erwartet z.B. 'sk-...' oder 'OPENAI_API_KEY=sk-...'.\"\n",
    "        )\n",
    "\n",
    "    key = m.group(1).strip()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = key\n",
    "    return key\n",
    "\n",
    "# Einmalig setzen (für den aktuellen Kernel)\n",
    "key = set_openai_key_from_file(DEFAULT_OPENAI_KEY_FILE)\n",
    "print(\"OPENAI_API_KEY gesetzt:\", bool(os.environ.get(\"OPENAI_API_KEY\")))\n",
    "print(\"Key Preview:\", key[:7] + \"...\" + key[-4:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4126024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: D:\\MA_Python_Agent\\Notebooks\n",
      "python_root: D:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\n",
      "sys.path[0]: D:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\n",
      "expect chatbot_core: True D:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\\msrguard\\chatbot_core.py\n"
     ]
    }
   ],
   "source": [
    "# Helper: Python-Root finden und sys.path setzen\n",
    "# Ziel: Finde das msrguard Paket in einem Layout wie:\n",
    "#   <parent>/MSRGuard_Anpassung/python/msrguard/chatbot_core.py\n",
    "# oder\n",
    "#   <parent>/python/msrguard/chatbot_core.py\n",
    "#\n",
    "# Wir gehen NUR in das Parent-Verzeichnis von cwd und durchsuchen dessen direkte Unterordner.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "def ensure_python_root_on_sys_path() -> Path:\n",
    "    here = Path.cwd().resolve()\n",
    "    parent = here.parent  # NUR eine Ebene hoch\n",
    "\n",
    "    # Kandidaten: parent selbst + alle direkten Unterordner\n",
    "    candidates = [parent] + [p for p in parent.iterdir() if p.is_dir()]\n",
    "\n",
    "    # 1) <cand>/python/msrguard/chatbot_core.py\n",
    "    for c in candidates:\n",
    "        probe = c / \"python\" / \"msrguard\" / \"chatbot_core.py\"\n",
    "        if probe.exists():\n",
    "            root = c / \"python\"\n",
    "            if str(root) not in sys.path:\n",
    "                sys.path.insert(0, str(root))\n",
    "            return root\n",
    "\n",
    "    # 2) <cand>/msrguard/chatbot_core.py (seltenes Layout)\n",
    "    for c in candidates:\n",
    "        probe = c / \"msrguard\" / \"chatbot_core.py\"\n",
    "        if probe.exists():\n",
    "            root = c\n",
    "            if str(root) not in sys.path:\n",
    "                sys.path.insert(0, str(root))\n",
    "            return root\n",
    "\n",
    "    # 3) Fallback: parent\n",
    "    root = parent\n",
    "    if str(root) not in sys.path:\n",
    "        sys.path.insert(0, str(root))\n",
    "    return root\n",
    "\n",
    "def load_module_from_path(path: Path, module_name: str):\n",
    "    \"\"\"Importiert ein .py File als Modul (Fallback wenn Paket-Import nicht klappt).\"\"\"\n",
    "    path = Path(path).expanduser().resolve()\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Modul nicht gefunden: {path}\")\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(path))\n",
    "    if spec is None or spec.loader is None:\n",
    "        raise RuntimeError(f\"Kann spec nicht erstellen für: {path}\")\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)  # type: ignore\n",
    "    return mod\n",
    "\n",
    "python_root = ensure_python_root_on_sys_path()\n",
    "print(\"cwd:\", Path.cwd().resolve())\n",
    "print(\"python_root:\", python_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "print(\"expect chatbot_core:\", (python_root / \"msrguard\" / \"chatbot_core.py\").exists(), python_root / \"msrguard\" / \"chatbot_core.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c728c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported msrguard.chatbot_core from: D:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\\msrguard\\chatbot_core.py\n",
      "Imported msrguard.excH_chatbot from: D:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\\msrguard\\excH_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "# Imports: msrguard.* bevorzugen, sonst Fallback über python_root/msrguard/*.py\n",
    "\n",
    "# --- chatbot_core ---\n",
    "try:\n",
    "    from msrguard.chatbot_core import (\n",
    "        ChatBot, ToolRegistry, BaseAgentTool,\n",
    "        KGStore, RoutineIndex,\n",
    "        ListProgramsTool, EvD2DiagnosisTool, CalledPousTool, PouCallersTool, PouCodeTool,\n",
    "        SearchVariablesTool, VariableTraceTool, GeneralSearchTool, GraphInvestigateTool,\n",
    "        StringTripleSearchTool, ExceptionAnalysisTool, Text2SparqlTool,\n",
    "        build_vector_index, SemanticSearchTool,\n",
    "        get_llm_invoke, schema_card,\n",
    "    )\n",
    "    import msrguard.chatbot_core as chatbot_core\n",
    "    print(\"Imported msrguard.chatbot_core from:\", chatbot_core.__file__)\n",
    "except Exception:\n",
    "    chatbot_core = load_module_from_path(python_root / \"msrguard\" / \"chatbot_core.py\", \"chatbot_core\")\n",
    "    print(\"Fallback import chatbot_core from:\", python_root / \"msrguard\" / \"chatbot_core.py\")\n",
    "\n",
    "    ChatBot = chatbot_core.ChatBot\n",
    "    ToolRegistry = chatbot_core.ToolRegistry\n",
    "    BaseAgentTool = chatbot_core.BaseAgentTool\n",
    "    KGStore = chatbot_core.KGStore\n",
    "    RoutineIndex = chatbot_core.RoutineIndex\n",
    "    ListProgramsTool = chatbot_core.ListProgramsTool\n",
    "    EvD2DiagnosisTool = chatbot_core.EvD2DiagnosisTool\n",
    "    CalledPousTool = chatbot_core.CalledPousTool\n",
    "    PouCallersTool = chatbot_core.PouCallersTool\n",
    "    PouCodeTool = chatbot_core.PouCodeTool\n",
    "    SearchVariablesTool = chatbot_core.SearchVariablesTool\n",
    "    VariableTraceTool = chatbot_core.VariableTraceTool\n",
    "    GeneralSearchTool = chatbot_core.GeneralSearchTool\n",
    "    GraphInvestigateTool = chatbot_core.GraphInvestigateTool\n",
    "    StringTripleSearchTool = chatbot_core.StringTripleSearchTool\n",
    "    ExceptionAnalysisTool = chatbot_core.ExceptionAnalysisTool\n",
    "    Text2SparqlTool = chatbot_core.Text2SparqlTool\n",
    "    build_vector_index = chatbot_core.build_vector_index\n",
    "    SemanticSearchTool = chatbot_core.SemanticSearchTool\n",
    "    get_llm_invoke = chatbot_core.get_llm_invoke\n",
    "    schema_card = chatbot_core.schema_card\n",
    "\n",
    "# --- excH_chatbot ---\n",
    "try:\n",
    "    from msrguard.excH_chatbot import IncidentContext, ExcHChatBotSession, run_initial_analysis\n",
    "    import msrguard.excH_chatbot as excH_chatbot\n",
    "    print(\"Imported msrguard.excH_chatbot from:\", excH_chatbot.__file__)\n",
    "except Exception:\n",
    "    excH_chatbot = load_module_from_path(python_root / \"msrguard\" / \"excH_chatbot.py\", \"excH_chatbot\")\n",
    "    print(\"Fallback import excH_chatbot from:\", python_root / \"msrguard\" / \"excH_chatbot.py\")\n",
    "    IncidentContext = excH_chatbot.IncidentContext\n",
    "    ExcHChatBotSession = excH_chatbot.ExcHChatBotSession\n",
    "    run_initial_analysis = excH_chatbot.run_initial_analysis\n",
    "\n",
    "# rdflib nur nötig, wenn du KG lädst\n",
    "try:\n",
    "    from rdflib import Graph\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"rdflib fehlt. Bitte installieren via: pip install rdflib\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a810d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def try_set_openai_key_from_file(path_str: str) -> Optional[str]:\n",
    "    # Wenn Key schon im Environment ist, nichts tun (optional: überschreiben, falls gewünscht)\n",
    "    if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        return None\n",
    "    \n",
    "    if not path_str:\n",
    "        return \"OPENAI_API_KEY fehlt und openai_api_key_file Pfad ist leer.\"\n",
    "\n",
    "    p = Path(path_str).expanduser().resolve()\n",
    "    if not p.exists():\n",
    "        return f\"openai_api_key_file existiert nicht: {p}\"\n",
    "\n",
    "    try:\n",
    "        key = p.read_text(encoding=\"utf-8\").strip()\n",
    "    except Exception as e:\n",
    "        return f\"Fehler beim Lesen der Key-Datei: {e}\"\n",
    "\n",
    "    if not key:\n",
    "        return f\"openai_api_key_file ist leer: {p}\"\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = key\n",
    "    print(f\"API Key erfolgreich geladen aus: {p}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74436d",
   "metadata": {},
   "source": [
    "## UI starten\n",
    "\n",
    "1) Setze den KG-Pfad (TTL)  \n",
    "2) Optional: setze `openai_api_key_file` oder `OPENAI_API_KEY`  \n",
    "3) Klicke **Build**  \n",
    "4) Tools testen, Chat testen, neue Tools hinzufügen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0b723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d364d1ef79340ff89c2040210caddcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='<h3>Config</h3>'), HTML(value='<p><b>KG TTL</b> ist dein Knowledge Gr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "KG TTL nicht gefunden: D:\\MA_Python_Agent\\Notebooks\\\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\TestEvents.ttl\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 331\u001b[39m, in \u001b[36mMSRGuardWorkbench._on_build_clicked\u001b[39m\u001b[34m(self, _btn)\u001b[39m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (tools-only)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_llm_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (llm chatbot)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m._refresh_tool_list()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 248\u001b[39m, in \u001b[36mMSRGuardWorkbench._build_llm_bot\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKey Hinweis:\u001b[39m\u001b[33m\"\u001b[39m, err)\n\u001b[32m    247\u001b[39m kg_ttl_path = \u001b[38;5;28mself\u001b[39m.kg_path.value.strip()\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28mself\u001b[39m.graph = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg_ttl_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    251\u001b[39m     chatbot_core.g = \u001b[38;5;28mself\u001b[39m.graph\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mMSRGuardWorkbench._load_graph\u001b[39m\u001b[34m(self, kg_ttl_path)\u001b[39m\n\u001b[32m    191\u001b[39m ttl = Path(kg_ttl_path).expanduser().resolve()\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ttl.exists():\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKG TTL nicht gefunden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mttl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m g = Graph()\n\u001b[32m    195\u001b[39m g.parse(\u001b[38;5;28mstr\u001b[39m(ttl), \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mturtle\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: KG TTL nicht gefunden: D:\\MA_Python_Agent\\Notebooks\\\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\TestEvents.ttl\""
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "KG TTL nicht gefunden: D:\\KGs\\TestEvents.ttl",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 331\u001b[39m, in \u001b[36mMSRGuardWorkbench._on_build_clicked\u001b[39m\u001b[34m(self, _btn)\u001b[39m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (tools-only)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_llm_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (llm chatbot)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m._refresh_tool_list()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 248\u001b[39m, in \u001b[36mMSRGuardWorkbench._build_llm_bot\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKey Hinweis:\u001b[39m\u001b[33m\"\u001b[39m, err)\n\u001b[32m    247\u001b[39m kg_ttl_path = \u001b[38;5;28mself\u001b[39m.kg_path.value.strip()\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28mself\u001b[39m.graph = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg_ttl_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    251\u001b[39m     chatbot_core.g = \u001b[38;5;28mself\u001b[39m.graph\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mMSRGuardWorkbench._load_graph\u001b[39m\u001b[34m(self, kg_ttl_path)\u001b[39m\n\u001b[32m    191\u001b[39m ttl = Path(kg_ttl_path).expanduser().resolve()\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ttl.exists():\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKG TTL nicht gefunden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mttl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m g = Graph()\n\u001b[32m    195\u001b[39m g.parse(\u001b[38;5;28mstr\u001b[39m(ttl), \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mturtle\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: KG TTL nicht gefunden: D:\\KGs\\TestEvents.ttl"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "KG TTL nicht gefunden: D:\\MA_Python_Agent\\Notebooks\\\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\TestEvents.ttl\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 331\u001b[39m, in \u001b[36mMSRGuardWorkbench._on_build_clicked\u001b[39m\u001b[34m(self, _btn)\u001b[39m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (tools-only)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_llm_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (llm chatbot)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m._refresh_tool_list()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 248\u001b[39m, in \u001b[36mMSRGuardWorkbench._build_llm_bot\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKey Hinweis:\u001b[39m\u001b[33m\"\u001b[39m, err)\n\u001b[32m    247\u001b[39m kg_ttl_path = \u001b[38;5;28mself\u001b[39m.kg_path.value.strip()\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28mself\u001b[39m.graph = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg_ttl_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    251\u001b[39m     chatbot_core.g = \u001b[38;5;28mself\u001b[39m.graph\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mMSRGuardWorkbench._load_graph\u001b[39m\u001b[34m(self, kg_ttl_path)\u001b[39m\n\u001b[32m    191\u001b[39m ttl = Path(kg_ttl_path).expanduser().resolve()\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ttl.exists():\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKG TTL nicht gefunden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mttl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m g = Graph()\n\u001b[32m    195\u001b[39m g.parse(\u001b[38;5;28mstr\u001b[39m(ttl), \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mturtle\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: KG TTL nicht gefunden: D:\\MA_Python_Agent\\Notebooks\\\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\TestEvents.ttl\""
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 331\u001b[39m, in \u001b[36mMSRGuardWorkbench._on_build_clicked\u001b[39m\u001b[34m(self, _btn)\u001b[39m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (tools-only)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_llm_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_status(\u001b[33m\"\u001b[39m\u001b[33mready (llm chatbot)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m._refresh_tool_list()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36mMSRGuardWorkbench._build_llm_bot\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28mself\u001b[39m.routine_index = RoutineIndex.build_from_kg(\u001b[38;5;28mself\u001b[39m.kg_store)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m.routine_index.save(\u001b[38;5;28mstr\u001b[39m(idx_path))\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_invoke = \u001b[43mget_llm_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenai_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenai_temp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mself\u001b[39m.registry = ToolRegistry()\n\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m.registry.register(ListProgramsTool())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\\msrguard\\chatbot_core.py:352\u001b[39m, in \u001b[36mget_llm_invoke\u001b[39m\u001b[34m(model, temperature)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    349\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBitte installiere: pip install -U langchain-openai langchain-core\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    350\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(system: \u001b[38;5;28mstr\u001b[39m, user: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    355\u001b[39m     msgs = [SystemMessage(content=system), HumanMessage(content=user)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_core\\load\\serializable.py:118\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    117\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:996\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    986\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_async_client = httpx.AsyncClient(\n\u001b[32m    987\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    988\u001b[39m         )\n\u001b[32m    989\u001b[39m     async_specific = {\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client\n\u001b[32m    991\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_async_httpx_client(\n\u001b[32m   (...)\u001b[39m\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: async_api_key_value,\n\u001b[32m    995\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_async_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43masync_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1000\u001b[39m     \u001b[38;5;28mself\u001b[39m.async_client = \u001b[38;5;28mself\u001b[39m.root_async_client.chat.completions\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\openai\\_client.py:488\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    486\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Import rdfLib nur wenn nötig (Fallback im Code vorhanden, aber hier für Typsicherheit)\n",
    "try:\n",
    "    from rdflib import Graph\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "class MSRGuardWorkbench:\n",
    "    def __init__(self):\n",
    "        # Runtime objects\n",
    "        self.graph: Optional[Graph] = None\n",
    "        self.kg_store: Optional[Any] = None\n",
    "        self.routine_index: Optional[Any] = None\n",
    "        self.registry: Optional[Any] = None\n",
    "        self.bot: Optional[Any] = None\n",
    "        self.session: Optional[Any] = None\n",
    "        self.schema_card_text: str = \"\"\n",
    "        self.llm_invoke = None\n",
    "\n",
    "        # --- UI Widgets ---\n",
    "        \n",
    "        # Standard-Pfad für KG (falls vorhanden)\n",
    "        default_kg = Path.cwd() / \"Test_cleaned.ttl\"\n",
    "        self.kg_path = widgets.Text(\n",
    "            value=str(default_kg.resolve()) if default_kg.exists() else \"\",\n",
    "            description=\"KG TTL\",\n",
    "            layout=widgets.Layout(width=\"95%\")\n",
    "        )\n",
    "        \n",
    "        self.routine_index_dir = widgets.Text(\n",
    "            value=\"\",\n",
    "            description=\"Index Dir\",\n",
    "            placeholder=\"optional (Default: TTL Ordner)\",\n",
    "            layout=widgets.Layout(width=\"95%\")\n",
    "        )\n",
    "        self.enable_rag = widgets.Checkbox(value=False, description=\"RAG (semantic_search) aktivieren\")\n",
    "        self.openai_model = widgets.Text(value=\"gpt-4o-mini\", description=\"Model\")\n",
    "        self.openai_temp = widgets.FloatSlider(value=0.0, min=0.0, max=1.0, step=0.1, description=\"Temp\")\n",
    "        \n",
    "        # --- HIER IST DIE KORREKTUR ---\n",
    "        # Der Pfad zur Key-Datei ist nun voreingestellt:\n",
    "        self.openai_key_file = widgets.Text(\n",
    "            value=r\"C:\\Users\\Alexander Verkhov\\Desktop\\OpenAI API Key.txt\", \n",
    "            description=\"Key-File\", \n",
    "            layout=widgets.Layout(width=\"95%\")\n",
    "        )\n",
    "\n",
    "        self.build_mode = widgets.Dropdown(\n",
    "            options=[(\"Tools-only (ohne LLM)\", \"tools\"), (\"ChatBot (Planner+LLM)\", \"llm\")],\n",
    "            value=\"tools\",\n",
    "            description=\"Mode\"\n",
    "        )\n",
    "\n",
    "        self.btn_build = widgets.Button(description=\"Build\", button_style=\"success\")\n",
    "        self.btn_build.on_click(self._on_build_clicked)\n",
    "\n",
    "        self.status = widgets.HTML(\"<b>Status:</b> idle\")\n",
    "\n",
    "        # --- Tools tab ---\n",
    "        self.tool_dropdown = widgets.Dropdown(options=[], description=\"Tool\")\n",
    "        self.tool_doc = widgets.Textarea(value=\"\", description=\"Doc\", layout=widgets.Layout(width=\"95%\", height=\"180px\"))\n",
    "        self.tool_args = widgets.Textarea(value=\"{}\", description=\"Args(JSON)\", layout=widgets.Layout(width=\"95%\", height=\"120px\"))\n",
    "        self.btn_run_tool = widgets.Button(description=\"Run Tool\", button_style=\"primary\")\n",
    "        self.btn_run_tool.on_click(self._on_run_tool_clicked)\n",
    "        self.out_tool = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "        self.tool_dropdown.observe(self._on_tool_selected, names=\"value\")\n",
    "\n",
    "        # --- Tool Builder tab ---\n",
    "        self.newtool_name = widgets.Text(value=\"my_new_tool\", description=\"name\")\n",
    "        self.newtool_desc = widgets.Text(value=\"Kurzbeschreibung...\", description=\"description\", layout=widgets.Layout(width=\"95%\"))\n",
    "\n",
    "        self.btn_skeleton = widgets.Button(description=\"Generate Skeleton\", button_style=\"\")\n",
    "        self.btn_skeleton.on_click(self._on_generate_skeleton)\n",
    "\n",
    "        self.btn_register = widgets.Button(description=\"Register Tool\", button_style=\"warning\")\n",
    "        self.btn_register.on_click(self._on_register_tool_clicked)\n",
    "\n",
    "        self.btn_save_tool = widgets.Button(description=\"Save to custom_tools.py\", button_style=\"\")\n",
    "        self.btn_save_tool.on_click(self._on_save_tool_clicked)\n",
    "\n",
    "        self.custom_code = widgets.Textarea(\n",
    "            value=\"\"\"# Schreibe hier deinen Tool-Code.\n",
    "# Wichtig: definiere eine Funktion make_tool(ctx), die eine Tool-Instanz zurückgibt.\n",
    "# ctx enthält: registry, kg_store, routine_index, graph, llm_invoke, schema_card_text, chatbot_core\n",
    "\n",
    "\"\"\",\n",
    "            description=\"code\",\n",
    "            layout=widgets.Layout(width=\"95%\", height=\"320px\")\n",
    "        )\n",
    "        self.out_builder = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "        # --- Chat tab ---\n",
    "        self.chat_debug = widgets.Checkbox(value=True, description=\"Debug (plan + tool_results anzeigen)\")\n",
    "        self.include_bootstrap = widgets.Checkbox(value=False, description=\"include_bootstrap (EvD2)\")\n",
    "\n",
    "        self.chat_input = widgets.Text(value=\"\", description=\"User\", layout=widgets.Layout(width=\"95%\"), placeholder=\"Frage an den ChatBot...\")\n",
    "        self.btn_send = widgets.Button(description=\"Send\", button_style=\"primary\")\n",
    "        self.btn_send.on_click(self._on_send_clicked)\n",
    "\n",
    "        self.btn_clear_chat = widgets.Button(description=\"Clear\", button_style=\"\")\n",
    "        self.btn_clear_chat.on_click(self._on_clear_chat)\n",
    "\n",
    "        self.out_chat = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\", height=\"320px\", overflow_y=\"auto\"))\n",
    "\n",
    "        # --- Incident tab ---\n",
    "        # Optional: Event-Datei aus agent_results laden (z.B. evD2-..._event.json)\n",
    "        self.event_file_path = widgets.Text(\n",
    "            value=\"\",\n",
    "            description=\"Event File\",\n",
    "            placeholder=r\"z.B. D:\\MA_Python_Agent\\MSRGuard_Anpassung\\python\\agent_results\\..._event.json\",\n",
    "            layout=widgets.Layout(width=\"95%\")\n",
    "        )\n",
    "        self.btn_load_event_file = widgets.Button(description=\"Load Event File\", button_style=\"\")\n",
    "        self.btn_load_event_file.on_click(self._on_load_event_file)\n",
    "\n",
    "        self.patch_event_kg = widgets.Checkbox(value=True, description=\"payload.kg_ttl_path mit KG TTL überschreiben\")\n",
    "\n",
    "        self.event_json = widgets.Textarea(\n",
    "            value=\"\"\"{\n",
    "  \"payload\": {\n",
    "    \"triggerEvent\": \"evD2\",\n",
    "    \"triggerD2\": true,\n",
    "    \"lastExecutedSkill\": \"TestSkill3\",\n",
    "    \"kg_ttl_path\": \"\"\n",
    "  }\n",
    "}\n",
    "\"\"\",\n",
    "            description=\"Event JSON\",\n",
    "            layout=widgets.Layout(width=\"95%\", height=\"240px\")\n",
    "        )\n",
    "        self.btn_load_incident = widgets.Button(description=\"Load Incident Session\", button_style=\"info\")\n",
    "        self.btn_load_incident.on_click(self._on_load_incident)\n",
    "\n",
    "        self.btn_initial = widgets.Button(description=\"Run Initial Analysis\", button_style=\"primary\")\n",
    "        self.btn_initial.on_click(self._on_run_initial_analysis)\n",
    "\n",
    "        self.out_incident = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "        # Tabs\n",
    "        self.tab_config = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Config</h3>\"),\n",
    "            widgets.HTML(\"<p><b>KG TTL</b> ist dein Knowledge Graph. <b>Index Dir</b> ist der Ordner für den RoutineIndex Cache (*_routine_index.json). Leer bedeutet: im TTL Ordner.</p>\"),\n",
    "            self.kg_path,\n",
    "            self.routine_index_dir,\n",
    "            widgets.HBox([self.build_mode, self.enable_rag]),\n",
    "            widgets.HBox([self.openai_model, self.openai_temp]),\n",
    "            self.openai_key_file,\n",
    "            widgets.HBox([self.btn_build, self.status]),\n",
    "        ])\n",
    "\n",
    "        self.tab_tools = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Tools</h3>\"),\n",
    "            self.tool_dropdown,\n",
    "            self.tool_doc,\n",
    "            self.tool_args,\n",
    "            widgets.HBox([self.btn_run_tool]),\n",
    "            self.out_tool,\n",
    "        ])\n",
    "\n",
    "        self.tab_builder = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Tool Builder</h3>\"), \n",
    "            widgets.HBox([self.newtool_name, self.btn_skeleton]),\n",
    "            self.newtool_desc,\n",
    "            self.custom_code,\n",
    "            widgets.HBox([self.btn_register, self.btn_save_tool]),\n",
    "            self.out_builder,\n",
    "        ])\n",
    "\n",
    "        self.tab_chat = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Chat</h3>\"),\n",
    "            widgets.HBox([self.chat_debug, self.include_bootstrap, self.btn_clear_chat]),\n",
    "            self.chat_input,\n",
    "            self.btn_send,\n",
    "            self.out_chat,\n",
    "        ])\n",
    "\n",
    "        self.tab_incident = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Incident Session (optional)</h3>\"), \n",
    "            widgets.HTML(\"<p>Erzeugt eine ExcHChatBotSession wie im Desktop-UI (run_initial_analysis nutzt EvD2 Bootstrap).</p>\"),\n",
    "            self.event_file_path,\n",
    "            widgets.HBox([self.btn_load_event_file, self.patch_event_kg]),\n",
    "            self.event_json,\n",
    "            widgets.HBox([self.btn_load_incident, self.btn_initial]),\n",
    "            self.out_incident\n",
    "        ])\n",
    "\n",
    "        self.tabs = widgets.Tab(children=[self.tab_config, self.tab_tools, self.tab_builder, self.tab_chat, self.tab_incident])\n",
    "        for i, title in enumerate([\"Config\", \"Tools\", \"Tool Builder\", \"Chat\", \"Incident\"]):\n",
    "            self.tabs.set_title(i, title)\n",
    "\n",
    "    # ---------- Core build ----------\n",
    "    def _load_graph(self, kg_ttl_path: str) -> Graph:\n",
    "        ttl = Path(kg_ttl_path).expanduser().resolve()\n",
    "        if not ttl.exists():\n",
    "            raise FileNotFoundError(f\"KG TTL nicht gefunden: {ttl}\")\n",
    "        g = Graph()\n",
    "        g.parse(str(ttl), format=\"turtle\")\n",
    "        return g\n",
    "\n",
    "    def _build_tools_only(self):\n",
    "        kg_ttl_path = self.kg_path.value.strip()\n",
    "        self.graph = self._load_graph(kg_ttl_path)\n",
    "\n",
    "        # wichtig: module-global setzen, da chatbot_core.sparql_select_raw auf 'g' zugreift\n",
    "        try:\n",
    "            chatbot_core.g = self.graph\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        self.kg_store = KGStore(self.graph)\n",
    "        self.schema_card_text = schema_card(self.graph, top_n=15)\n",
    "\n",
    "        # Routine index wie im build_bot\n",
    "        idx_dir = Path(self.routine_index_dir.value.strip()).expanduser().resolve() if self.routine_index_dir.value.strip() else Path(kg_ttl_path).expanduser().resolve().parent\n",
    "        idx_dir.mkdir(parents=True, exist_ok=True)\n",
    "        idx_path = idx_dir / (Path(kg_ttl_path).stem + \"_routine_index.json\")\n",
    "\n",
    "        if idx_path.exists() and idx_path.stat().st_size > 0:\n",
    "            self.routine_index = RoutineIndex.load(str(idx_path))\n",
    "        else:\n",
    "            self.routine_index = RoutineIndex.build_from_kg(self.kg_store)\n",
    "            self.routine_index.save(str(idx_path))\n",
    "\n",
    "        self.registry = ToolRegistry()\n",
    "        # Deterministische Tools\n",
    "        self.registry.register(ListProgramsTool())\n",
    "        self.registry.register(EvD2DiagnosisTool())\n",
    "        self.registry.register(CalledPousTool())\n",
    "        self.registry.register(PouCallersTool())\n",
    "        self.registry.register(PouCodeTool())\n",
    "        self.registry.register(SearchVariablesTool())\n",
    "        self.registry.register(VariableTraceTool())\n",
    "        self.registry.register(GeneralSearchTool())\n",
    "        self.registry.register(GraphInvestigateTool())\n",
    "        self.registry.register(StringTripleSearchTool(self.kg_store))\n",
    "        self.registry.register(ExceptionAnalysisTool(self.kg_store, self.routine_index))\n",
    "\n",
    "        self.bot = None\n",
    "        self.llm_invoke = None\n",
    "        self.session = None\n",
    "\n",
    "    def _build_llm_bot(self):\n",
    "        # Key setzen (falls Key-File angegeben)\n",
    "        err = try_set_openai_key_from_file(self.openai_key_file.value.strip())\n",
    "        if err:\n",
    "            # Nur Hinweis, kein Abbruch: User kann OPENAI_API_KEY auch anders setzen\n",
    "            print(\"Key Hinweis:\", err)\n",
    "\n",
    "        kg_ttl_path = self.kg_path.value.strip()\n",
    "        self.graph = self._load_graph(kg_ttl_path)\n",
    "\n",
    "        try:\n",
    "            chatbot_core.g = self.graph\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        self.kg_store = KGStore(self.graph)\n",
    "        self.schema_card_text = schema_card(self.graph, top_n=15)\n",
    "\n",
    "        idx_dir = Path(self.routine_index_dir.value.strip()).expanduser().resolve() if self.routine_index_dir.value.strip() else Path(kg_ttl_path).expanduser().resolve().parent\n",
    "        idx_dir.mkdir(parents=True, exist_ok=True)\n",
    "        idx_path = idx_dir / (Path(kg_ttl_path).stem + \"_routine_index.json\")\n",
    "\n",
    "        if idx_path.exists() and idx_path.stat().st_size > 0:\n",
    "            self.routine_index = RoutineIndex.load(str(idx_path))\n",
    "        else:\n",
    "            self.routine_index = RoutineIndex.build_from_kg(self.kg_store)\n",
    "            self.routine_index.save(str(idx_path))\n",
    "\n",
    "        # Hier würde der Error fliegen, wenn der Key nicht geladen wurde\n",
    "        self.llm_invoke = get_llm_invoke(model=self.openai_model.value.strip() or \"gpt-4o-mini\", temperature=float(self.openai_temp.value))\n",
    "\n",
    "        self.registry = ToolRegistry()\n",
    "        self.registry.register(ListProgramsTool())\n",
    "        self.registry.register(EvD2DiagnosisTool())\n",
    "        self.registry.register(CalledPousTool())\n",
    "        self.registry.register(PouCallersTool())\n",
    "        self.registry.register(PouCodeTool())\n",
    "        self.registry.register(SearchVariablesTool())\n",
    "        self.registry.register(VariableTraceTool())\n",
    "        self.registry.register(GeneralSearchTool())\n",
    "        self.registry.register(GraphInvestigateTool())\n",
    "        self.registry.register(StringTripleSearchTool(self.kg_store))\n",
    "        self.registry.register(ExceptionAnalysisTool(self.kg_store, self.routine_index))\n",
    "        self.registry.register(Text2SparqlTool(self.llm_invoke, self.schema_card_text))\n",
    "\n",
    "        if bool(self.enable_rag.value):\n",
    "            vs = build_vector_index(self.kg_store, self.registry)\n",
    "            if vs is not None:\n",
    "                self.registry.register(SemanticSearchTool(vs))\n",
    "\n",
    "        self.bot = ChatBot(self.registry, self.llm_invoke)\n",
    "        self.session = None\n",
    "\n",
    "    def _refresh_tool_list(self):\n",
    "        if not self.registry:\n",
    "            self.tool_dropdown.options = []\n",
    "            self.tool_doc.value = \"\"\n",
    "            return\n",
    "\n",
    "        names = sorted(list(getattr(self.registry, \"_tools\", {}).keys()))\n",
    "        self.tool_dropdown.options = names\n",
    "        if names:\n",
    "            self.tool_dropdown.value = names[0]\n",
    "            self._update_tool_doc(names[0])\n",
    "\n",
    "    def _update_tool_doc(self, tool_name: str):\n",
    "        if not self.registry:\n",
    "            self.tool_doc.value = \"\"\n",
    "            return\n",
    "        tool = getattr(self.registry, \"_tools\", {}).get(tool_name)\n",
    "        if tool is None:\n",
    "            self.tool_doc.value = \"\"\n",
    "            return\n",
    "        try:\n",
    "            self.tool_doc.value = tool.get_documentation()\n",
    "        except Exception:\n",
    "            self.tool_doc.value = f\"{tool_name}\\n(no documentation)\\n{tool}\"\n",
    "\n",
    "    # ---------- UI callbacks ----------\n",
    "    def _set_status(self, text: str):\n",
    "        self.status.value = f\"<b>Status:</b> {text}\"\n",
    "\n",
    "    def _on_build_clicked(self, _btn):\n",
    "        with self.out_tool:\n",
    "            pass\n",
    "        try:\n",
    "            self._set_status(\"building...\")\n",
    "            mode = self.build_mode.value\n",
    "            if mode == \"tools\":\n",
    "                self._build_tools_only()\n",
    "                self._set_status(\"ready (tools-only)\")\n",
    "            else:\n",
    "                self._build_llm_bot()\n",
    "                self._set_status(\"ready (llm chatbot)\")\n",
    "            self._refresh_tool_list()\n",
    "        except Exception as e:\n",
    "            self._set_status(f\"ERROR: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _on_tool_selected(self, change):\n",
    "        val = change.get(\"new\")\n",
    "        if val:\n",
    "            self._update_tool_doc(val)\n",
    "\n",
    "    def _on_run_tool_clicked(self, _btn):\n",
    "        self.out_tool.clear_output()\n",
    "        with self.out_tool:\n",
    "            if not self.registry:\n",
    "                print(\"Registry ist nicht gebaut. Erst in 'Config' auf Build klicken.\")\n",
    "                return\n",
    "            tool_name = self.tool_dropdown.value\n",
    "            try:\n",
    "                args = json.loads(self.tool_args.value.strip() or \"{}\")\n",
    "                if not isinstance(args, dict):\n",
    "                    args = {}\n",
    "            except Exception as e:\n",
    "                print(\"Args JSON parse error:\", e)\n",
    "                return\n",
    "\n",
    "            res = self.registry.execute(tool_name, args)\n",
    "            print(json.dumps(res, ensure_ascii=False, indent=2) if not isinstance(res, str) else res)\n",
    "\n",
    "    def _on_generate_skeleton(self, _btn):\n",
    "        tool_name = (self.newtool_name.value or \"my_new_tool\").strip()\n",
    "        desc = (self.newtool_desc.value or \"Kurzbeschreibung...\").strip()\n",
    "\n",
    "        skel = f'''# --- Custom Tool Skeleton ---\n",
    "# ctx enthält: registry, kg_store, routine_index, graph, llm_invoke, schema_card_text, chatbot_core\n",
    "# Du MUSST make_tool(ctx) definieren, die eine Tool-Instanz zurückgibt.\n",
    "\n",
    "class {tool_name.title().replace(\"_\", \"\")}Tool(chatbot_core.BaseAgentTool):\n",
    "    name = \"{tool_name}\"\n",
    "    description = \"{desc}\"\n",
    "    usage_guide = \"Wann soll der Planner dieses Tool nutzen?\"\n",
    "\n",
    "    def __init__(self, kg_store=None, routine_index=None, registry=None, llm_invoke=None):\n",
    "        self.kg_store = kg_store\n",
    "        self.routine_index = routine_index\n",
    "        self.registry = registry\n",
    "        self.llm_invoke = llm_invoke\n",
    "\n",
    "    def run(self, **kwargs):\n",
    "        # TODO: Implementiere hier deine Logik.\n",
    "        # Du kannst z.B. über self.registry.execute(\"pou_code\", {{...}}) andere Tools nutzen.\n",
    "        return {{\n",
    "            \"ok\": True,\n",
    "            \"note\": \"Implement me\",\n",
    "            \"kwargs\": kwargs\n",
    "        }}\n",
    "\n",
    "def make_tool(ctx):\n",
    "    return {tool_name.title().replace(\"_\", \"\")}Tool(\n",
    "        kg_store=ctx.get(\"kg_store\"),\n",
    "        routine_index=ctx.get(\"routine_index\"),\n",
    "        registry=ctx.get(\"registry\"),\n",
    "        llm_invoke=ctx.get(\"llm_invoke\"),\n",
    "    )\n",
    "'''\n",
    "        self.custom_code.value = skel\n",
    "\n",
    "    def _on_register_tool_clicked(self, _btn):\n",
    "        self.out_builder.clear_output()\n",
    "        with self.out_builder:\n",
    "            if not self.registry:\n",
    "                print(\"Registry ist nicht gebaut. Erst in 'Config' auf Build klicken.\")\n",
    "                return\n",
    "\n",
    "            code = self.custom_code.value\n",
    "            ctx = {\n",
    "                \"registry\": self.registry,\n",
    "                \"kg_store\": self.kg_store,\n",
    "                \"routine_index\": self.routine_index,\n",
    "                \"graph\": self.graph,\n",
    "                \"llm_invoke\": self.llm_invoke,\n",
    "                \"schema_card_text\": self.schema_card_text,\n",
    "                \"chatbot_core\": chatbot_core,\n",
    "            }\n",
    "\n",
    "            ns: Dict[str, Any] = {}\n",
    "            try:\n",
    "                exec(code, ns, ns)\n",
    "            except Exception as e:\n",
    "                print(\"Code exec error:\", e)\n",
    "                return\n",
    "\n",
    "            if \"make_tool\" not in ns:\n",
    "                print(\"Fehlt: make_tool(ctx). Bitte im Code definieren.\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                tool_obj = ns[\"make_tool\"](ctx)\n",
    "            except Exception as e:\n",
    "                print(\"make_tool(ctx) error:\", e)\n",
    "                return\n",
    "\n",
    "            if not hasattr(tool_obj, \"name\") or not hasattr(tool_obj, \"run\"):\n",
    "                print(\"make_tool(ctx) muss ein Tool-Objekt (BaseAgentTool) zurückgeben.\")\n",
    "                return\n",
    "\n",
    "            self.registry.register(tool_obj)\n",
    "            print(f\"Registered tool: {tool_obj.name}\")\n",
    "            self._refresh_tool_list()\n",
    "\n",
    "    def _on_save_tool_clicked(self, _btn):\n",
    "        self.out_builder.clear_output()\n",
    "        with self.out_builder:\n",
    "            code = self.custom_code.value.strip()\n",
    "            if not code:\n",
    "                print(\"Kein Code zum Speichern.\")\n",
    "                return\n",
    "            outp = Path(\"custom_tools.py\").resolve()\n",
    "            stamp = f\"\\n\\n# ---- saved {datetime.datetime.utcnow().isoformat()}Z ----\\n\"\n",
    "            outp.write_text((outp.read_text(encoding=\"utf-8\") if outp.exists() else \"\") + stamp + code + \"\\n\", encoding=\"utf-8\")\n",
    "            print(f\"Saved to: {outp}\")\n",
    "\n",
    "    def _append_chat(self, role: str, text: str):\n",
    "        with self.out_chat:\n",
    "            display(Markdown(f\"**{role}:**\\n\\n{text}\\n\"))\n",
    "\n",
    "    def _on_clear_chat(self, _btn):\n",
    "        self.out_chat.clear_output()\n",
    "\n",
    "    def _on_send_clicked(self, _btn):\n",
    "        msg = self.chat_input.value.strip()\n",
    "        if not msg:\n",
    "            return\n",
    "        self.chat_input.value = \"\"\n",
    "\n",
    "        self._append_chat(\"User\", msg)\n",
    "\n",
    "        if self.session is not None:\n",
    "            # Incident session\n",
    "            try:\n",
    "                res = self.session.ask(msg, debug=bool(self.chat_debug.value), include_bootstrap=bool(self.include_bootstrap.value))\n",
    "                answer = res.get(\"answer\") if isinstance(res, dict) else str(res)\n",
    "                self._append_chat(\"Assistant\", answer or \"\")\n",
    "                if bool(self.chat_debug.value) and isinstance(res, dict):\n",
    "                    plan = res.get(\"plan\")\n",
    "                    tool_results = res.get(\"tool_results\")\n",
    "                    self._append_chat(\"Debug/Plan\", f\"```json\\n{json.dumps(plan, ensure_ascii=False, indent=2)}\\n```\" if plan is not None else \"(none)\")\n",
    "                    self._append_chat(\"Debug/Tools\", f\"```json\\n{json.dumps(tool_results, ensure_ascii=False, indent=2)[:12000]}\\n```\" if tool_results is not None else \"(none)\")\n",
    "            except Exception as e:\n",
    "                self._append_chat(\"System\", f\"ChatBot Fehler: {e}\")\n",
    "            return\n",
    "\n",
    "        # Standard bot chat\n",
    "        if not self.bot:\n",
    "            self._append_chat(\"System\", \"ChatBot ist nicht initialisiert (LLM-Mode). Baue den Bot in 'Config' im LLM-Mode.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            res = self.bot.chat(msg, debug=bool(self.chat_debug.value))\n",
    "            answer = res.get(\"answer\") if isinstance(res, dict) else str(res)\n",
    "            self._append_chat(\"Assistant\", answer or \"\")\n",
    "            if bool(self.chat_debug.value) and isinstance(res, dict):\n",
    "                plan = res.get(\"plan\")\n",
    "                tool_results = res.get(\"tool_results\")\n",
    "                self._append_chat(\"Debug/Plan\", f\"```json\\n{json.dumps(plan, ensure_ascii=False, indent=2)}\\n```\" if plan is not None else \"(none)\")\n",
    "                self._append_chat(\"Debug/Tools\", f\"```json\\n{json.dumps(tool_results, ensure_ascii=False, indent=2)[:12000]}\\n```\" if tool_results is not None else \"(none)\")\n",
    "        except Exception as e:\n",
    "            self._append_chat(\"System\", f\"ChatBot Fehler: {e}\")\n",
    "\n",
    "    def _on_load_event_file(self, _btn):\n",
    "        \"\"\"Lädt ein *_event.json aus einer Datei in das Event JSON Textfeld.\"\"\"\n",
    "        self.out_incident.clear_output()\n",
    "        with self.out_incident:\n",
    "            p = Path(self.event_file_path.value.strip()).expanduser().resolve()\n",
    "            if not p.exists():\n",
    "                print(\"Event File nicht gefunden:\", p)\n",
    "                return\n",
    "            try:\n",
    "                ev = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "            except Exception as e:\n",
    "                print(\"Event File JSON parse error:\", e)\n",
    "                return\n",
    "\n",
    "            # Optional: kg_ttl_path im Event setzen\n",
    "            if bool(self.patch_event_kg.value):\n",
    "                kgp = self.kg_path.value.strip()\n",
    "                if kgp:\n",
    "                    ev.setdefault(\"payload\", {})\n",
    "                    if isinstance(ev[\"payload\"], dict):\n",
    "                        ev[\"payload\"][\"kg_ttl_path\"] = kgp\n",
    "                        print(\"payload.kg_ttl_path gesetzt auf:\", kgp)\n",
    "\n",
    "            self.event_json.value = json.dumps(ev, ensure_ascii=False, indent=2)\n",
    "            print(\"Event File geladen:\", p)\n",
    "\n",
    "    def _on_load_incident(self, _btn):\n",
    "        self.out_incident.clear_output()\n",
    "        with self.out_incident:\n",
    "            if not self.bot and not self.registry:\n",
    "                print(\"Bitte zuerst in Config den Bot/Registry bauen.\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                ev = json.loads(self.event_json.value)\n",
    "            except Exception as e:\n",
    "                print(\"Event JSON parse error:\", e)\n",
    "                return\n",
    "\n",
    "            # KG Pfad aus event payload kann Config überschreiben\n",
    "            payload = ev.get(\"payload\") if isinstance(ev.get(\"payload\"), dict) else {}\n",
    "            kgp = payload.get(\"kg_ttl_path\") or \"\"\n",
    "            if kgp and kgp.strip():\n",
    "                self.kg_path.value = str(kgp)\n",
    "                print(\"KG TTL aus Event übernommen:\", kgp)\n",
    "                # rebuild bot/registry (same mode)\n",
    "                self._on_build_clicked(None)\n",
    "\n",
    "            # Lazy import (robust): IncidentContext + Session immer verfügbar machen\n",
    "            try:\n",
    "                from msrguard.excH_chatbot import IncidentContext as _IncidentContext, ExcHChatBotSession as _ExcHChatBotSession\n",
    "            except Exception:\n",
    "                _excH = load_module_from_path(python_root / \"msrguard\" / \"excH_chatbot.py\", \"excH_chatbot\")\n",
    "                _IncidentContext = _excH.IncidentContext\n",
    "                _ExcHChatBotSession = _excH.ExcHChatBotSession\n",
    "\n",
    "            ctx = _IncidentContext.from_event(ev) if hasattr(_IncidentContext, \"from_event\") else _IncidentContext.from_input(ev)\n",
    "            # Session braucht bot; falls nur tools-mode, versuche trotzdem eine Minimal-ChatBot-Instanz ohne LLM\n",
    "            if self.bot is None:\n",
    "                # tools-only: pseudo-bot mit registry, aber ohne llm\n",
    "                dummy_llm = lambda _sys, _user: \"\"\n",
    "                self.bot = ChatBot(self.registry, dummy_llm)  # type: ignore\n",
    "\n",
    "            self.session = _ExcHChatBotSession(bot=self.bot, ctx=ctx)\n",
    "            print(\"Incident Session geladen.\")\n",
    "            print(\"ctx:\", ctx)\n",
    "\n",
    "    def _on_run_initial_analysis(self, _btn):\n",
    "        self.out_incident.clear_output()\n",
    "        with self.out_incident:\n",
    "            if self.session is None:\n",
    "                print(\"Keine Incident Session. Erst 'Load Incident Session' klicken.\")\n",
    "                return\n",
    "            try:\n",
    "                try:\n",
    "                    from msrguard.excH_chatbot import run_initial_analysis as _run_initial_analysis\n",
    "                except Exception:\n",
    "                    _excH = load_module_from_path(python_root / \"msrguard\" / \"excH_chatbot.py\", \"excH_chatbot\")\n",
    "                    _run_initial_analysis = _excH.run_initial_analysis\n",
    "\n",
    "                res = _run_initial_analysis(self.session, debug=True)\n",
    "                print(\"Initial analysis done.\")\n",
    "                print(\"Answer:\\n\", res.get(\"answer\") if isinstance(res, dict) else res)\n",
    "                if isinstance(res, dict):\n",
    "                    print(\"\\nPlan:\\n\", json.dumps(res.get(\"plan\"), ensure_ascii=False, indent=2))\n",
    "                    print(\"\\nTool results:\\n\", json.dumps(res.get(\"tool_results\"), ensure_ascii=False, indent=2)[:12000])\n",
    "            except Exception as e:\n",
    "                print(\"run_initial_analysis error:\", e)\n",
    "\n",
    "    def display(self):\n",
    "        display(self.tabs)\n",
    "\n",
    "# UI starten:\n",
    "ui = MSRGuardWorkbench()\n",
    "ui.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
