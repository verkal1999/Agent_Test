{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f3ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config geladen: d:\\MA_Python_Agent\\Notebooks\\Dateien_SkillExtractor\\skill_extractor_config.json\n",
      "Skills-Katalog geladen: d:\\MA_Python_Agent\\Notebooks\\Dateien_SkillExtractor\\skills_catalog.json\n",
      "Skills im Katalog: 48\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 0 — Setup: Pfade + Config/Skill-JSON laden\n",
    "# =========================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "# 1) Passe diese Pfade an (Windows: r\"...\")\n",
    "KG_IN  = r\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\Test2_filled.ttl\"\n",
    "KG_OUT = r\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\Test2_filled.ttl\"\n",
    "\n",
    "# JSON Sidecars (liegen idealerweise im gleichen Ordner wie dieses Notebook)\n",
    "CONFIG_JSON_PATH = BASE_DIR / \"Dateien_SkillExtractor/skill_extractor_config.json\"\n",
    "SKILLS_JSON_PATH = BASE_DIR / \"Dateien_SkillExtractor/skills_catalog.json\"\n",
    "\n",
    "# Schalter: Skills im KG jedes Mal neu schreiben?\n",
    "REWRITE_SKILLS_EACH_RUN = True\n",
    "\n",
    "# Schalter: alte LLM-Hypothesen jedes Mal löschen?\n",
    "CLEAR_OLD_HYPOTHESES_EACH_RUN = True\n",
    "\n",
    "config = json.loads(CONFIG_JSON_PATH.read_text(encoding=\"utf-8\"))\n",
    "skills_catalog = json.loads(SKILLS_JSON_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Config geladen:\", CONFIG_JSON_PATH)\n",
    "print(\"Skills-Katalog geladen:\", SKILLS_JSON_PATH)\n",
    "print(\"Skills im Katalog:\", len(skills_catalog.get(\"skills\", [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f95f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG geladen: D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\Test2_filled.ttl\n",
      "Triples: 21192\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 1 — KG laden + Namespaces\n",
    "# =========================================\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "g = Graph()\n",
    "g.parse(KG_IN, format=\"turtle\")\n",
    "\n",
    "AG = Namespace(\"http://www.semanticweb.org/AgentProgramParams/\")\n",
    "DP = Namespace(\"http://www.semanticweb.org/AgentProgramParams/dp_\")\n",
    "OP = Namespace(\"http://www.semanticweb.org/AgentProgramParams/op_\")\n",
    "\n",
    "g.bind(\"ag\", AG)\n",
    "g.bind(\"dp\", DP)\n",
    "g.bind(\"op\", OP)\n",
    "\n",
    "print(\"KG geladen:\", KG_IN)\n",
    "print(\"Triples:\", len(g))\n",
    "\n",
    "def ag(local: str) -> URIRef:\n",
    "    return URIRef(str(AG) + local)\n",
    "\n",
    "def dp(local: str) -> URIRef:\n",
    "    return URIRef(str(DP) + local)\n",
    "\n",
    "def op(local: str) -> URIRef:\n",
    "    return URIRef(str(OP) + local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7c97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills neu geschrieben: gelöscht=49, geschrieben=48\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 2 — Skills löschen (optional) + aus JSON neu schreiben\n",
    "# =========================================\n",
    "SKILL_CLASS = ag(\"class_Skill\")\n",
    "P_HAS_SKILL_DESCRIPTION = dp(\"dp_hasSkillDescription\")\n",
    "\n",
    "def _is_skill_node(uri: URIRef) -> bool:\n",
    "    u = str(uri)\n",
    "    return u.startswith(str(AG)) and u.split(\"/\")[-1].startswith(\"Skill_\")\n",
    "\n",
    "def delete_all_skills(graph: Graph) -> int:\n",
    "    # 1) Skills per rdf:type\n",
    "    nodes = set(graph.subjects(RDF.type, SKILL_CLASS))\n",
    "    # 2) zusätzlich: alle ag:Skill_* (falls Typ mal fehlt)\n",
    "    nodes |= {s for s in graph.subjects(None, None) if isinstance(s, URIRef) and _is_skill_node(s)}\n",
    "\n",
    "    # OUTGOING + INCOMING löschen, damit keine dangling Kanten bleiben\n",
    "    for s in nodes:\n",
    "        graph.remove((s, None, None))\n",
    "        graph.remove((None, None, s))\n",
    "    return len(nodes)\n",
    "\n",
    "def write_skills_from_json(graph: Graph, skills_json: dict) -> int:\n",
    "    n = 0\n",
    "    for s in skills_json.get(\"skills\", []):\n",
    "        sid = s[\"id\"]\n",
    "        label = s.get(\"label\", \"\")\n",
    "        desc = s.get(\"description\", \"\")\n",
    "\n",
    "        uri = ag(sid)\n",
    "        graph.add((uri, RDF.type, SKILL_CLASS))\n",
    "        if label:\n",
    "            graph.add((uri, RDFS.label, Literal(label)))\n",
    "        if desc:\n",
    "            graph.add((uri, P_HAS_SKILL_DESCRIPTION, Literal(desc)))\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "if REWRITE_SKILLS_EACH_RUN:\n",
    "    deleted = delete_all_skills(g)\n",
    "    written = write_skills_from_json(g, skills_catalog)\n",
    "    print(f\"Skills neu geschrieben: gelöscht={deleted}, geschrieben={written}\")\n",
    "else:\n",
    "    print(\"REWRITE_SKILLS_EACH_RUN=False -> Skills bleiben unverändert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261d1de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POUs geladen: 60\n",
      "POUs nach Filter: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pou_iri</th>\n",
       "      <th>pou_name</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL_CB_AS_HorizontalMoveSensors</td>\n",
       "      <td>// POU HRL_CB_AS_HorizontalMoveSensors body\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveEncoders</td>\n",
       "      <td>// POU HRL_RGB_AS_HorizontalMoveEncoders body\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveSensors</td>\n",
       "      <td>// POU HRL_RGB_AS_HorizontalMoveSensors body\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL_RGB_AS_VerticalMoveEncoders</td>\n",
       "      <td>// POU HRL_RGB_AS_VerticalMoveEncoders body\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>MBS_CB_AS_HorizontalMove</td>\n",
       "      <td>// POU MBS_CB_AS_HorizontalMove body\\nMBS_CB_H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pou_iri  \\\n",
       "0  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "1  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "2  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "3  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "4  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "\n",
       "                            pou_name  \\\n",
       "0    HRL_CB_AS_HorizontalMoveSensors   \n",
       "1  HRL_RGB_AS_HorizontalMoveEncoders   \n",
       "2   HRL_RGB_AS_HorizontalMoveSensors   \n",
       "3    HRL_RGB_AS_VerticalMoveEncoders   \n",
       "4           MBS_CB_AS_HorizontalMove   \n",
       "\n",
       "                                                code  \n",
       "0  // POU HRL_CB_AS_HorizontalMoveSensors body\\nH...  \n",
       "1  // POU HRL_RGB_AS_HorizontalMoveEncoders body\\...  \n",
       "2  // POU HRL_RGB_AS_HorizontalMoveSensors body\\n...  \n",
       "3  // POU HRL_RGB_AS_VerticalMoveEncoders body\\nH...  \n",
       "4  // POU MBS_CB_AS_HorizontalMove body\\nMBS_CB_H...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 3 — POUs + Code aus KG holen (robust)\n",
    "# =========================================\n",
    "import pandas as pd\n",
    "\n",
    "Q_POUS = \"\"\"\n",
    "SELECT DISTINCT ?pou ?pou_name ?code\n",
    "WHERE {\n",
    "  OPTIONAL {\n",
    "    ?pou ?p_name ?pou_name .\n",
    "    FILTER ( regex(str(?p_name), \"POUName$\", \"i\") )\n",
    "  }\n",
    "  OPTIONAL {\n",
    "    ?pou ?p_code ?code .\n",
    "    FILTER ( regex(str(?p_code), \"POUCode$\", \"i\") )\n",
    "  }\n",
    "  FILTER ( bound(?pou_name) || bound(?code) )\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 1) Roh lesen (kann Duplikate erzeugen, wenn Name+Code mehrfach vorkommt)\n",
    "tmp = []\n",
    "for r in g.query(Q_POUS):\n",
    "    tmp.append({\n",
    "        \"pou_iri\": str(r.pou),\n",
    "        \"pou_name\": str(r.pou_name) if r.pou_name else \"\",\n",
    "        \"code\": str(r.code) if r.code else \"\"\n",
    "    })\n",
    "\n",
    "# 2) Stabil: Spalten sind IMMER vorhanden\n",
    "df_raw = pd.DataFrame(tmp, columns=[\"pou_iri\", \"pou_name\", \"code\"])\n",
    "\n",
    "# 3) Duplikate je POU zusammenführen (erstes nicht-leeres Name/Code gewinnen)\n",
    "if len(df_raw):\n",
    "    df_pous = (\n",
    "        df_raw.groupby(\"pou_iri\", as_index=False)\n",
    "              .agg({\n",
    "                  \"pou_name\": lambda s: next((x for x in s if x), \"\"),\n",
    "                  \"code\":     lambda s: next((x for x in s if x), \"\")\n",
    "              })\n",
    "    )\n",
    "else:\n",
    "    df_pous = df_raw\n",
    "\n",
    "print(\"POUs geladen:\", len(df_pous))\n",
    "\n",
    "# ---- Debug-Hinweis, falls immer noch 0 ----\n",
    "if len(df_pous) == 0:\n",
    "    print(\"⚠️ Keine POUs gefunden. Dann heißen die Properties bei dir vermutlich nicht ...POUName/...POUCode.\")\n",
    "    print(\"    Tipp: Suche im KG nach Prädikaten mit 'POU' im Namen (siehe Debug-Zelle unten).\")\n",
    "\n",
    "# 4) Filter aus Config (nur wenn Spalte existiert – tut sie jetzt immer)\n",
    "inc = config.get(\"pou_filters\", {}).get(\"include_contains\", [])\n",
    "exc_pref = config.get(\"pou_filters\", {}).get(\"exclude_prefixes\", [])\n",
    "exc_contains = config.get(\"pou_filters\", {}).get(\"exclude_contains\", [])\n",
    "\n",
    "for token in inc:\n",
    "    df_pous = df_pous[df_pous[\"pou_name\"].str.contains(token, na=False)]\n",
    "for pref in exc_pref:\n",
    "    df_pous = df_pous[~df_pous[\"pou_name\"].str.startswith(pref, na=False)]\n",
    "for token in exc_contains:\n",
    "    df_pous = df_pous[~df_pous[\"pou_name\"].str.contains(token, na=False)]\n",
    "\n",
    "df_pous = df_pous.reset_index(drop=True)\n",
    "print(\"POUs nach Filter:\", len(df_pous))\n",
    "\n",
    "df_pous.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc7eb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pou_name</th>\n",
       "      <th>module</th>\n",
       "      <th>submodule</th>\n",
       "      <th>base_action</th>\n",
       "      <th>qualifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HRL_CB_AS_HorizontalMoveSensors</td>\n",
       "      <td>HRL</td>\n",
       "      <td>CB</td>\n",
       "      <td>HorizontalMove</td>\n",
       "      <td>Sensors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveEncoders</td>\n",
       "      <td>HRL</td>\n",
       "      <td>RGB</td>\n",
       "      <td>HorizontalMove</td>\n",
       "      <td>Encoders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveSensors</td>\n",
       "      <td>HRL</td>\n",
       "      <td>RGB</td>\n",
       "      <td>HorizontalMove</td>\n",
       "      <td>Sensors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HRL_RGB_AS_VerticalMoveEncoders</td>\n",
       "      <td>HRL</td>\n",
       "      <td>RGB</td>\n",
       "      <td>VerticalMove</td>\n",
       "      <td>Encoders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBS_CB_AS_HorizontalMove</td>\n",
       "      <td>MBS</td>\n",
       "      <td>CB</td>\n",
       "      <td>HorizontalMove</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MBS_DmPD_AS_HorizontalMove</td>\n",
       "      <td>MBS</td>\n",
       "      <td>DmPD</td>\n",
       "      <td>HorizontalMove</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MBS_DmPD_AS_RotationMove</td>\n",
       "      <td>MBS</td>\n",
       "      <td>DmPD</td>\n",
       "      <td>RotationMove</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MBS_MR01_AS_HardeningProcess</td>\n",
       "      <td>MBS</td>\n",
       "      <td>MR01</td>\n",
       "      <td>HardeningProcess</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MBS_MR01_AS_HorizontalMoveSensors</td>\n",
       "      <td>MBS</td>\n",
       "      <td>MR01</td>\n",
       "      <td>HorizontalMove</td>\n",
       "      <td>Sensors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MBS_MR01_AS_SecuringProcess</td>\n",
       "      <td>MBS</td>\n",
       "      <td>MR01</td>\n",
       "      <td>SecuringProcess</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pou_name module submodule       base_action  \\\n",
       "0    HRL_CB_AS_HorizontalMoveSensors    HRL        CB    HorizontalMove   \n",
       "1  HRL_RGB_AS_HorizontalMoveEncoders    HRL       RGB    HorizontalMove   \n",
       "2   HRL_RGB_AS_HorizontalMoveSensors    HRL       RGB    HorizontalMove   \n",
       "3    HRL_RGB_AS_VerticalMoveEncoders    HRL       RGB      VerticalMove   \n",
       "4           MBS_CB_AS_HorizontalMove    MBS        CB    HorizontalMove   \n",
       "5         MBS_DmPD_AS_HorizontalMove    MBS      DmPD    HorizontalMove   \n",
       "6           MBS_DmPD_AS_RotationMove    MBS      DmPD      RotationMove   \n",
       "7       MBS_MR01_AS_HardeningProcess    MBS      MR01  HardeningProcess   \n",
       "8  MBS_MR01_AS_HorizontalMoveSensors    MBS      MR01    HorizontalMove   \n",
       "9        MBS_MR01_AS_SecuringProcess    MBS      MR01   SecuringProcess   \n",
       "\n",
       "  qualifier  \n",
       "0   Sensors  \n",
       "1  Encoders  \n",
       "2   Sensors  \n",
       "3  Encoders  \n",
       "4            \n",
       "5            \n",
       "6            \n",
       "7            \n",
       "8   Sensors  \n",
       "9            "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 4 — Benennungsschema aus POU-Namen parsen (module/submodule/base_action/qualifier)\n",
    "# =========================================\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "QUAL_RE = re.compile(r\"^(?P<base>.*?)(?P<qual>Encoders|Sensors|Encoder)?$\")\n",
    "\n",
    "def parse_pou_name(pou_name: str) -> dict:\n",
    "    name = (pou_name or \"\").strip()\n",
    "    parts = name.split(\"_\")\n",
    "\n",
    "    if \"AS\" in parts:\n",
    "        as_idx = parts.index(\"AS\")\n",
    "        module = parts[0] if len(parts) > 0 else \"\"\n",
    "        submodule = \"_\".join(parts[1:as_idx]) if as_idx > 1 else \"\"\n",
    "        action_raw = \"_\".join(parts[as_idx+1:]) if as_idx+1 < len(parts) else \"\"\n",
    "    else:\n",
    "        module = parts[0] if parts else \"\"\n",
    "        submodule = \"\"\n",
    "        action_raw = \"_\".join(parts[1:]) if len(parts) > 1 else \"\"\n",
    "\n",
    "    m = QUAL_RE.match(action_raw)\n",
    "    base_action = m.group(\"base\") if m else action_raw\n",
    "    qualifier = m.group(\"qual\") if (m and m.group(\"qual\")) else \"\"\n",
    "\n",
    "    return {\n",
    "        \"module\": module,\n",
    "        \"submodule\": submodule,\n",
    "        \"action_raw\": action_raw,\n",
    "        \"base_action\": base_action,\n",
    "        \"qualifier\": qualifier,\n",
    "    }\n",
    "\n",
    "feat = df_pous[\"pou_name\"].apply(parse_pou_name).apply(pd.Series)\n",
    "df_pous = pd.concat([df_pous, feat], axis=1)\n",
    "\n",
    "df_pous[[\"pou_name\",\"module\",\"submodule\",\"base_action\",\"qualifier\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d0a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills im KG: 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_iri</th>\n",
       "      <th>label</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL: RBG X verfahren</td>\n",
       "      <td>Verfährt den Regalbediengerät Schlitten entlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL: RBG Y verfahren</td>\n",
       "      <td>Verfährt die Hubachse entlang der Y Achse zur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL: Ausleger verfahren</td>\n",
       "      <td>Fährt den Ausleger des Regalbediengeräts ein o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL: Förderband antreiben</td>\n",
       "      <td>Startet oder stoppt das Förderband der Ein und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>HRL: Sicherheitsprüfung</td>\n",
       "      <td>Prüft sicherheitsrelevante Sensorik oder Zustä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>SG1: Horizontal verfahren</td>\n",
       "      <td>Verfährt den Vakuum Greifer Roboter entlang de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>SG1: Vertikal verfahren</td>\n",
       "      <td>Verfährt den Vakuum Greifer Roboter entlang de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://www.semanticweb.org/AgentProgramParams/...</td>\n",
       "      <td>SG1: Rotieren</td>\n",
       "      <td>Rotiert den Greifer oder die Werkzeugaufnahme ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           skill_iri  \\\n",
       "0  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "1  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "2  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "3  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "4  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "5  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "6  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "7  http://www.semanticweb.org/AgentProgramParams/...   \n",
       "\n",
       "                       label  \\\n",
       "0       HRL: RBG X verfahren   \n",
       "1       HRL: RBG Y verfahren   \n",
       "2    HRL: Ausleger verfahren   \n",
       "3  HRL: Förderband antreiben   \n",
       "4    HRL: Sicherheitsprüfung   \n",
       "5  SG1: Horizontal verfahren   \n",
       "6    SG1: Vertikal verfahren   \n",
       "7              SG1: Rotieren   \n",
       "\n",
       "                                                desc  \n",
       "0  Verfährt den Regalbediengerät Schlitten entlan...  \n",
       "1  Verfährt die Hubachse entlang der Y Achse zur ...  \n",
       "2  Fährt den Ausleger des Regalbediengeräts ein o...  \n",
       "3  Startet oder stoppt das Förderband der Ein und...  \n",
       "4  Prüft sicherheitsrelevante Sensorik oder Zustä...  \n",
       "5  Verfährt den Vakuum Greifer Roboter entlang de...  \n",
       "6  Verfährt den Vakuum Greifer Roboter entlang de...  \n",
       "7  Rotiert den Greifer oder die Werkzeugaufnahme ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 5 — Skills aus KG lesen (robust: dp_ + ag-namespace Variationen)\n",
    "# =========================================\n",
    "import pandas as pd\n",
    "\n",
    "Q_SKILLS = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX ag:  <http://www.semanticweb.org/AgentProgramParams/>\n",
    "PREFIX dp:  <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
    "\n",
    "SELECT ?skill ?label ?desc\n",
    "WHERE {\n",
    "  ?skill rdf:type ag:class_Skill .\n",
    "  OPTIONAL { ?skill rdfs:label ?label . }\n",
    "  OPTIONAL { ?skill dp:dp_hasSkillDescription ?desc . }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "skill_rows = []\n",
    "for r in g.query(Q_SKILLS):\n",
    "    skill_rows.append({\n",
    "        \"skill_iri\": str(r.skill),\n",
    "        \"label\": str(r.label) if r.label else \"\",\n",
    "        \"desc\": str(r.desc) if r.desc else \"\"\n",
    "    })\n",
    "\n",
    "df_skills = pd.DataFrame(skill_rows).drop_duplicates(subset=[\"skill_iri\"]).reset_index(drop=True)\n",
    "print(\"Skills im KG:\", len(df_skills))\n",
    "df_skills.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e97094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glossary / Prefix legend for identifiers:\n",
      "{\n",
      "  \"abbreviations\": {\n",
      "    \"HRL\": \"Hochregallager (storage & retrieval / high-bay warehouse)\",\n",
      "    \"RBG\": \"Regalbediengerät (warehouse gantry/robot)\",\n",
      "    \"MBS\": \"Multi-Bearbeitungsstation (multi processing station)\",\n",
      "    \"VSG\": \"Vakuum-Sauggreifer (vacuum suction gripper / pick-and-place)\",\n",
      "    \"SST\": \"Sortierstrecke / Sortierstation (sorting station/line)\",\n",
      "    \"CS\": \"Conveyor & Stanzmaschine (conveyor + punching station)\",\n",
      "    \"CB\": \"Conveyor Belt (Förderband)\",\n",
      "    \"PD\": \"Pushing Device (Schiebeeinheit/Transfer)\",\n",
      "    \"MR01\": \"Bearbeitungsmodul 01 (im MBS-Kontext)\",\n",
      "    \"MR02\": \"Bearbeitungsmodul 02 (im MBS-Kontext)\",\n",
      "    \"AS\": \"Atomic Skill Marker in POU-Namen (…_AS_…)\"\n",
      "  },\n",
      "  \"skill_verbs\": {\n",
      "    \"HorizontalMove\": \"horizontale Bewegung/Transport\",\n",
      "    \"VerticalMove\": \"vertikale Bewegung\",\n",
      "    \"RotationMove\": \"Rotation/Drehbewegung\",\n",
      "    \"Su\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 6 — Prompt Context aus JSON (Abkürzungen etc.)\n",
    "# =========================================\n",
    "import json\n",
    "\n",
    "ABBREVIATIONS = config.get(\"abbreviations\", {})\n",
    "SKILL_VERBS   = config.get(\"skill_verbs\", {})\n",
    "\n",
    "GLOSSARY_TEXT = (\n",
    "    \"Glossary / Prefix legend for identifiers:\\n\"\n",
    "    + json.dumps({\"abbreviations\": ABBREVIATIONS, \"skill_verbs\": SKILL_VERBS}, ensure_ascii=False, indent=2)\n",
    ")\n",
    "\n",
    "print(GLOSSARY_TEXT[:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d67553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Zelle 7 — Candidate Picking (station-aware + action hints)\n",
    "# =========================================\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "token_re = re.compile(r\"[A-Za-z_][A-Za-z0-9_]*\")\n",
    "\n",
    "def norm_tokens(text: str):\n",
    "    return set(t.lower() for t in token_re.findall(text or \"\"))\n",
    "\n",
    "def station_from_skill_label(label: str) -> str:\n",
    "    if not label or \":\" not in label:\n",
    "        return \"\"\n",
    "    return label.split(\":\")[0].strip()\n",
    "\n",
    "MODULE_TO_SKILL_STATIONS = config.get(\"module_to_skill_stations\", {})\n",
    "ACTION_HINTS = config.get(\"action_hints\", {})\n",
    "\n",
    "def build_skill_text(label: str, desc: str, base_action: str) -> str:\n",
    "    text = f\"{label or ''} {desc or ''}\".lower()\n",
    "    for hint in ACTION_HINTS.get(base_action, []):\n",
    "        text += \" \" + hint\n",
    "    return text\n",
    "\n",
    "def pick_candidates_for_row(row, df_skills: pd.DataFrame, top_n: int = 12):\n",
    "    module = row.get(\"module\", \"\") or \"\"\n",
    "    base_action = row.get(\"base_action\", \"\") or \"\"\n",
    "    code = row.get(\"code\", \"\") or \"\"\n",
    "\n",
    "    allowed_stations = set(MODULE_TO_SKILL_STATIONS.get(module, []))\n",
    "    if allowed_stations:\n",
    "        df0 = df_skills[df_skills[\"label\"].fillna(\"\").apply(station_from_skill_label).isin(allowed_stations)]\n",
    "        df0 = df0 if len(df0) else df_skills\n",
    "    else:\n",
    "        df0 = df_skills\n",
    "\n",
    "    code_toks = norm_tokens(code)\n",
    "\n",
    "    scored = []\n",
    "    for _, s in df0.iterrows():\n",
    "        label = s.get(\"label\",\"\") or \"\"\n",
    "        desc  = s.get(\"desc\",\"\") or \"\"\n",
    "        txt = build_skill_text(label, desc, base_action)\n",
    "        stoks = norm_tokens(txt)\n",
    "        token_score = len(code_toks & stoks) / max(1, len(stoks))\n",
    "        scored.append((token_score, s))\n",
    "\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    picked = [s for sc, s in scored if sc > 0][:top_n]\n",
    "    if not picked:\n",
    "        picked = [s for _, s in scored[:top_n]]\n",
    "    return pd.DataFrame(picked)\n",
    "\n",
    "# Quick test\n",
    "if len(df_pous) and len(df_skills):\n",
    "    cand = pick_candidates_for_row(df_pous.iloc[0].to_dict(), df_skills, top_n=config[\"llm\"][\"candidate_top_n\"])\n",
    "    cand[[\"label\",\"desc\"]].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e04047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Zelle 8 — Groq Setup + LLM Inferenz (nur JSON)\n",
    "# =========================================\n",
    "from groq import Groq\n",
    "import json\n",
    "import time\n",
    "\n",
    "api_key_path = r\"C:\\Users\\Alexander Verkhov\\Desktop\\APIKey_Groq.txt\"\n",
    "with open(api_key_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    groq_api_key = f.read().strip()\n",
    "\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "MODEL_NAME = config[\"llm\"][\"model\"]\n",
    "\n",
    "TASK_DEFINITION = \"\"\"\n",
    "Du bekommst IEC 61131-3 Structured Text Code eines POU/Programms aus einer SPS (fischertechnik I4.0 Demonstrator/Simulator Kontext).\n",
    "Außerdem bekommst du einen Katalog an Skills (Name + Kurzbeschreibung).\n",
    "Deine Aufgabe: schätze, welche Skills durch diesen POU implementiert werden.\n",
    "\n",
    "Wichtig:\n",
    "- Wähle NUR Skills aus der übergebenen Kandidatenliste (allowed_skill_iris).\n",
    "- Nutze das Glossar, um Prefixe in POU-Namen/Variablen zu verstehen (z.B. HRL, MBS, VSG, SST, AS).\n",
    "- Wenn du dir nicht sicher bist oder nichts passt, gib matches als [] zurück.\n",
    "- Gib AUSSCHLIESSLICH ein JSON-Objekt zurück (kein Markdown, kein Fließtext).\n",
    "\n",
    "JSON Schema:\n",
    "{\n",
    "  \"pou_name\": \"...\",\n",
    "  \"matches\": [\n",
    "    {\n",
    "      \"skill_iri\": \"<muss exakt einer aus allowed_skill_iris sein>\",\n",
    "      \"skill_label\": \"<optional>\",\n",
    "      \"confidence\": 0.0,\n",
    "      \"reason_short\": \"...\",\n",
    "      \"evidence\": [\"1-6 kurze Codezeilen wörtlich\"]\n",
    "    }\n",
    "  ],\n",
    "  \"notes\": \"\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "\n",
    "EXPECTED_KEYS_REQUIRED = [\"pou_name\", \"matches\"]   # notes ist optional!\n",
    "\n",
    "def _extract_json(text: str):\n",
    "    if not text:\n",
    "        raise ValueError(\"Empty response\")\n",
    "    text = text.strip()\n",
    "    return json.loads(text)\n",
    "\n",
    "def infer_skill_implementations(pou_row: dict, candidates_df, model: str):\n",
    "    cand_list = []\n",
    "    allowed_skill_iris = []\n",
    "\n",
    "    for _, r in candidates_df.iterrows():\n",
    "        cand_list.append({\n",
    "            \"skill_iri\": r[\"skill_iri\"],\n",
    "            \"label\": r.get(\"label\",\"\"),\n",
    "            \"desc\": r.get(\"desc\",\"\")\n",
    "        })\n",
    "        allowed_skill_iris.append(r[\"skill_iri\"])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{TASK_DEFINITION}\n",
    "\n",
    "{GLOSSARY_TEXT}\n",
    "\n",
    "POU-Name: {pou_row.get(\"pou_name\",\"\")}\n",
    "module/submodule/base_action: {pou_row.get(\"module\",\"\")} / {pou_row.get(\"submodule\",\"\")} / {pou_row.get(\"base_action\",\"\")}\n",
    "\n",
    "allowed_skill_iris:\n",
    "{json.dumps(allowed_skill_iris, ensure_ascii=False)}\n",
    "\n",
    "Skill-Kandidaten (nur diese wählen):\n",
    "{json.dumps(cand_list, ensure_ascii=False, indent=2)}\n",
    "\n",
    "Code:\n",
    "{pou_row.get(\"code\",\"\")}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Du bist ein präziser Industrie-4.0 Skill-Analyst. Antworte nur mit JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        # JSON Mode (Groq)\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    txt = resp.choices[0].message.content\n",
    "    data = _extract_json(txt)\n",
    "\n",
    "    # Minimal sanity checks\n",
    "    missing = [k for k in EXPECTED_KEYS_REQUIRED if k not in data]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing keys in JSON: {missing}\")\n",
    "\n",
    "    if \"notes\" not in data:\n",
    "        data[\"notes\"] = \"\"\n",
    "\n",
    "    # Hard-filter: nur erlaubte Skills durchlassen\n",
    "    allowed = set(allowed_skill_iris)\n",
    "    filtered = []\n",
    "    for m in (data.get(\"matches\") or []):\n",
    "        if m.get(\"skill_iri\") in allowed:\n",
    "            filtered.append(m)\n",
    "    data[\"matches\"] = filtered\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1178e9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alte Hypothesen gelöscht: 26\n",
      "[1/21] HRL_CB_AS_HorizontalMoveSensors -> matches=2\n",
      "[2/21] HRL_RGB_AS_HorizontalMoveEncoders -> matches=3\n",
      "[3/21] HRL_RGB_AS_HorizontalMoveSensors -> matches=2\n",
      "[4/21] HRL_RGB_AS_VerticalMoveEncoders -> matches=2\n",
      "[5/21] MBS_CB_AS_HorizontalMove -> matches=1\n",
      "[6/21] MBS_DmPD_AS_HorizontalMove -> matches=1\n",
      "[7/21] MBS_DmPD_AS_RotationMove -> matches=1\n",
      "[8/21] MBS_MR01_AS_HardeningProcess -> matches=2\n",
      "[9/21] MBS_MR01_AS_HorizontalMoveSensors -> matches=1\n",
      "[10/21] MBS_MR01_AS_SecuringProcess -> matches=4\n",
      "[11/21] MBS_MR02_AS_CuttingProcess -> matches=1\n",
      "[12/21] MBS_VSG_AS_HorizontalMove -> matches=1\n",
      "[13/21] MBS_VSG_AS_SuctionProcess -> matches=2\n",
      "[14/21] MBS_VSG_AS_VerticalMove -> matches=1\n",
      "[15/21] SST_CB_AS_HorizontalMove -> matches=2\n",
      "[16/21] SST_CS_AS_ColorDetection -> matches=1\n",
      "[17/21] SST_PD_AS_HorizontalMove -> matches=3\n",
      "[18/21] VSG_AS_CompressorControl -> matches=2\n",
      "[19/21] VSG_AS_HorizontalMoveEncoder -> matches=1\n",
      "[20/21] VSG_AS_RotationMoveEncoder -> matches=3\n",
      "[21/21] VSG_AS_VerticalMoveEncoder -> matches=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pou</th>\n",
       "      <th>skill</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MBS_VSG_AS_HorizontalMove</td>\n",
       "      <td>MBS: Greifer horizontal verfahren</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MBS_MR02_AS_CuttingProcess</td>\n",
       "      <td>MBS: Schneiden</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MBS_DmPD_AS_HorizontalMove</td>\n",
       "      <td>MBS: Greifer horizontal verfahren</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MBS_MR01_AS_HardeningProcess</td>\n",
       "      <td>MBS: Härten</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MBS_DmPD_AS_RotationMove</td>\n",
       "      <td>MBS: Drehteller rotieren</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VSG_AS_VerticalMoveEncoder</td>\n",
       "      <td>SG1: Vertikal verfahren</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>VSG_AS_HorizontalMoveEncoder</td>\n",
       "      <td>SG1: Horizontal verfahren</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>VSG_AS_RotationMoveEncoder</td>\n",
       "      <td>SG1: Rotieren</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VSG_AS_RotationMoveEncoder</td>\n",
       "      <td>SG2: Rotieren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HRL_CB_AS_HorizontalMoveSensors</td>\n",
       "      <td>HRL: Förderband antreiben</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VSG_AS_CompressorControl</td>\n",
       "      <td>SG1: Ansaugen und Ablagen</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SST_CB_AS_HorizontalMove</td>\n",
       "      <td>SORT: Förderband antreiben</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveEncoders</td>\n",
       "      <td>HRL: RBG X verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MBS_MR01_AS_HorizontalMoveSensors</td>\n",
       "      <td>MBS: Greifer horizontal verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MBS_MR01_AS_SecuringProcess</td>\n",
       "      <td>MBS: Werkstück spannen oder lösen</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MBS_VSG_AS_VerticalMove</td>\n",
       "      <td>MBS: Greifer vertikal verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SST_PD_AS_HorizontalMove</td>\n",
       "      <td>SORT: Schieber bewegen</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MBS_VSG_AS_SuctionProcess</td>\n",
       "      <td>MBS: Greifer vertikal verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MBS_CB_AS_HorizontalMove</td>\n",
       "      <td>MBS: Greifer horizontal verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HRL_RGB_AS_VerticalMoveEncoders</td>\n",
       "      <td>HRL: RBG Y verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveSensors</td>\n",
       "      <td>HRL: RBG X verfahren</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SST_CS_AS_ColorDetection</td>\n",
       "      <td>SORT: Farbe erkennen</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MBS_MR01_AS_HardeningProcess</td>\n",
       "      <td>MBS: Förderband antreiben</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRL_CB_AS_HorizontalMoveSensors</td>\n",
       "      <td>HRL: Sicherheitsprüfung</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MBS_MR01_AS_SecuringProcess</td>\n",
       "      <td>MBS: Werkstück in Ofen ein oder ausfahren</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VSG_AS_RotationMoveEncoder</td>\n",
       "      <td>SG3: Rotieren</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VSG_AS_CompressorControl</td>\n",
       "      <td>SG1: Vertikal verfahren</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MBS_VSG_AS_SuctionProcess</td>\n",
       "      <td>MBS: Greifer horizontal verfahren</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HRL_RGB_AS_HorizontalMoveEncoders</td>\n",
       "      <td>HRL: RBG Y verfahren</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SST_PD_AS_HorizontalMove</td>\n",
       "      <td>SORT: Förderband antreiben</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  pou  \\\n",
       "20          MBS_VSG_AS_HorizontalMove   \n",
       "19         MBS_MR02_AS_CuttingProcess   \n",
       "10         MBS_DmPD_AS_HorizontalMove   \n",
       "12       MBS_MR01_AS_HardeningProcess   \n",
       "11           MBS_DmPD_AS_RotationMove   \n",
       "36         VSG_AS_VerticalMoveEncoder   \n",
       "32       VSG_AS_HorizontalMoveEncoder   \n",
       "33         VSG_AS_RotationMoveEncoder   \n",
       "34         VSG_AS_RotationMoveEncoder   \n",
       "0     HRL_CB_AS_HorizontalMoveSensors   \n",
       "30           VSG_AS_CompressorControl   \n",
       "24           SST_CB_AS_HorizontalMove   \n",
       "2   HRL_RGB_AS_HorizontalMoveEncoders   \n",
       "14  MBS_MR01_AS_HorizontalMoveSensors   \n",
       "15        MBS_MR01_AS_SecuringProcess   \n",
       "23            MBS_VSG_AS_VerticalMove   \n",
       "27           SST_PD_AS_HorizontalMove   \n",
       "21          MBS_VSG_AS_SuctionProcess   \n",
       "9            MBS_CB_AS_HorizontalMove   \n",
       "7     HRL_RGB_AS_VerticalMoveEncoders   \n",
       "5    HRL_RGB_AS_HorizontalMoveSensors   \n",
       "26           SST_CS_AS_ColorDetection   \n",
       "13       MBS_MR01_AS_HardeningProcess   \n",
       "1     HRL_CB_AS_HorizontalMoveSensors   \n",
       "16        MBS_MR01_AS_SecuringProcess   \n",
       "35         VSG_AS_RotationMoveEncoder   \n",
       "31           VSG_AS_CompressorControl   \n",
       "22          MBS_VSG_AS_SuctionProcess   \n",
       "3   HRL_RGB_AS_HorizontalMoveEncoders   \n",
       "28           SST_PD_AS_HorizontalMove   \n",
       "\n",
       "                                        skill  conf  \n",
       "20          MBS: Greifer horizontal verfahren   0.9  \n",
       "19                             MBS: Schneiden   0.9  \n",
       "10          MBS: Greifer horizontal verfahren   0.9  \n",
       "12                                MBS: Härten   0.9  \n",
       "11                   MBS: Drehteller rotieren   0.9  \n",
       "36                    SG1: Vertikal verfahren   0.9  \n",
       "32                  SG1: Horizontal verfahren   0.9  \n",
       "33                              SG1: Rotieren   0.9  \n",
       "34                              SG2: Rotieren   0.8  \n",
       "0                   HRL: Förderband antreiben   0.8  \n",
       "30                  SG1: Ansaugen und Ablagen   0.8  \n",
       "24                 SORT: Förderband antreiben   0.8  \n",
       "2                        HRL: RBG X verfahren   0.8  \n",
       "14          MBS: Greifer horizontal verfahren   0.8  \n",
       "15          MBS: Werkstück spannen oder lösen   0.8  \n",
       "23            MBS: Greifer vertikal verfahren   0.8  \n",
       "27                     SORT: Schieber bewegen   0.8  \n",
       "21            MBS: Greifer vertikal verfahren   0.8  \n",
       "9           MBS: Greifer horizontal verfahren   0.8  \n",
       "7                        HRL: RBG Y verfahren   0.8  \n",
       "5                        HRL: RBG X verfahren   0.8  \n",
       "26                       SORT: Farbe erkennen   0.8  \n",
       "13                  MBS: Förderband antreiben   0.7  \n",
       "1                     HRL: Sicherheitsprüfung   0.7  \n",
       "16  MBS: Werkstück in Ofen ein oder ausfahren   0.7  \n",
       "35                              SG3: Rotieren   0.7  \n",
       "31                    SG1: Vertikal verfahren   0.7  \n",
       "22          MBS: Greifer horizontal verfahren   0.6  \n",
       "3                        HRL: RBG Y verfahren   0.6  \n",
       "28                 SORT: Förderband antreiben   0.6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# Zelle 9 — Ergebnisse in KG schreiben + Loop (mit Cleanup)\n",
    "# =========================================\n",
    "from rdflib import Literal, URIRef\n",
    "from rdflib.namespace import XSD\n",
    "from datetime import datetime, timezone\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "CLASS_HYP = ag(\"class_SkillImplementationHypothesis\")\n",
    "\n",
    "P_ABOUT_POU   = ag(\"op_hasHypothesisAboutPOU\")\n",
    "P_ABOUT_SKILL = ag(\"op_hasHypothesisAboutSkill\")\n",
    "P_CONF        = ag(\"dp_hasConfidence\")\n",
    "P_REASON      = ag(\"dp_hasRationale\")\n",
    "P_EVID        = ag(\"dp_hasEvidenceSnippet\")\n",
    "P_MODEL       = ag(\"dp_inferredByModel\")\n",
    "P_TIME        = ag(\"dp_inferredAt\")\n",
    "\n",
    "P_IMPL        = ag(\"op_implementsSkill\")\n",
    "\n",
    "def hyp_uri(pou_iri: str, skill_iri: str, model: str) -> URIRef:\n",
    "    h = hashlib.sha1(f\"{pou_iri}|{skill_iri}|{model}\".encode(\"utf-8\")).hexdigest()[:12]\n",
    "    return URIRef(str(AG) + f\"SkillImplHyp_{h}\")\n",
    "\n",
    "def cleanup_old_hypotheses(graph: Graph) -> int:\n",
    "    old_claims = set()\n",
    "    old_claims |= set(graph.subjects(RDF.type, CLASS_HYP))\n",
    "    old_claims |= set(graph.subjects(P_ABOUT_POU, None))\n",
    "    old_claims |= set(graph.subjects(P_ABOUT_SKILL, None))\n",
    "    old_claims |= set(graph.subjects(P_MODEL, None))\n",
    "\n",
    "    for c in old_claims:\n",
    "        graph.remove((c, None, None))\n",
    "        graph.remove((None, None, c))\n",
    "\n",
    "    graph.remove((None, P_IMPL, None))\n",
    "    return len(old_claims)\n",
    "\n",
    "def write_mapping_to_kg(pou_iri: str, mapping_json: dict, model: str):\n",
    "    pou_uri = URIRef(pou_iri)\n",
    "    now = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "    for m in (mapping_json.get(\"matches\") or []):\n",
    "        conf = float(m.get(\"confidence\", 0.0))\n",
    "\n",
    "        # Optional: Confidence-Schwelle\n",
    "        if conf < float(config[\"llm\"][\"confidence_threshold\"]):\n",
    "            continue\n",
    "\n",
    "        skill_uri = URIRef(m[\"skill_iri\"])\n",
    "        claim = hyp_uri(pou_iri, m[\"skill_iri\"], model)\n",
    "\n",
    "        g.remove((claim, None, None))\n",
    "\n",
    "        g.add((claim, RDF.type, CLASS_HYP))\n",
    "        g.add((claim, P_ABOUT_POU, pou_uri))\n",
    "        g.add((claim, P_ABOUT_SKILL, skill_uri))\n",
    "        g.add((claim, P_CONF, Literal(conf, datatype=XSD.decimal)))\n",
    "        g.add((claim, P_REASON, Literal(m.get(\"reason_short\", \"\"))))\n",
    "        g.add((claim, P_MODEL, Literal(model)))\n",
    "        g.add((claim, P_TIME, Literal(now, datatype=XSD.dateTime)))\n",
    "\n",
    "        for ev in (m.get(\"evidence\") or [])[:6]:\n",
    "            g.add((claim, P_EVID, Literal(ev)))\n",
    "\n",
    "        g.add((pou_uri, P_IMPL, skill_uri))\n",
    "\n",
    "# Cleanup\n",
    "if CLEAR_OLD_HYPOTHESES_EACH_RUN:\n",
    "    n = cleanup_old_hypotheses(g)\n",
    "    print(\"Alte Hypothesen gelöscht:\", n)\n",
    "\n",
    "# Loop\n",
    "MAX_POUS = int(config[\"llm\"][\"max_pous\"])\n",
    "TOP_N = int(config[\"llm\"][\"candidate_top_n\"])\n",
    "SLEEP_S = float(config[\"llm\"][\"sleep_s\"])\n",
    "\n",
    "rows_out = []\n",
    "for i, row in df_pous.head(MAX_POUS).iterrows():\n",
    "    try:\n",
    "        candidates_df = pick_candidates_for_row(row.to_dict(), df_skills, top_n=TOP_N)\n",
    "        out = infer_skill_implementations(row.to_dict(), candidates_df, model=MODEL_NAME)\n",
    "\n",
    "        write_mapping_to_kg(row[\"pou_iri\"], out, model=MODEL_NAME)\n",
    "\n",
    "        # für DataFrame\n",
    "        for m in out.get(\"matches\", []):\n",
    "            rows_out.append({\n",
    "                \"pou\": row[\"pou_name\"],\n",
    "                \"skill\": m.get(\"skill_label\", \"\"),\n",
    "                \"conf\": float(m.get(\"confidence\", 0.0))\n",
    "            })\n",
    "\n",
    "        print(f\"[{i+1}/{min(MAX_POUS,len(df_pous))}] {row['pou_name']} -> matches={len(out.get('matches',[]))}\")\n",
    "        time.sleep(SLEEP_S)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{i+1}] ERROR bei {row['pou_name']}: {e}\")\n",
    "\n",
    "df_results = pd.DataFrame(rows_out).sort_values(\"conf\", ascending=False)\n",
    "df_results.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Zelle 10 — KG speichern + optional Skills wieder exportieren\n",
    "# =========================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "g.serialize(destination=KG_OUT, format=\"turtle\")\n",
    "print(\"KG gespeichert:\", KG_OUT)\n",
    "print(\"Triples:\", len(g))\n",
    "\n",
    "# Optional: Skills aus KG wieder in skills_catalog.json exportieren (wenn du den KG als Source-of-Truth nutzen willst)\n",
    "EXPORT_SKILLS_FROM_KG = False\n",
    "\n",
    "if EXPORT_SKILLS_FROM_KG:\n",
    "    Q_SKILLS_EXPORT = \"\"\"\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX ag:  <http://www.semanticweb.org/AgentProgramParams/>\n",
    "    PREFIX dp:  <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
    "\n",
    "    SELECT ?skill ?label ?desc\n",
    "    WHERE {\n",
    "      ?skill rdf:type ag:class_Skill .\n",
    "      OPTIONAL { ?skill rdfs:label ?label . }\n",
    "      OPTIONAL { ?skill dp:dp_hasSkillDescription ?desc . }\n",
    "    }\n",
    "    \"\"\"\n",
    "    out_sk = []\n",
    "    for r in g.query(Q_SKILLS_EXPORT):\n",
    "        out_sk.append({\n",
    "            \"id\": str(r.skill).split(\"/\")[-1],\n",
    "            \"label\": str(r.label) if r.label else \"\",\n",
    "            \"description\": str(r.desc) if r.desc else \"\",\n",
    "            \"station_prefix\": (str(r.label).split(\":\")[0].strip() if r.label and \":\" in str(r.label) else \"\"),\n",
    "            \"aliases\": []\n",
    "        })\n",
    "\n",
    "    payload = {\n",
    "        \"schema_version\": \"1.0\",\n",
    "        \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"notes\": \"Export aus KG\",\n",
    "        \"skills\": sorted(out_sk, key=lambda x: x[\"id\"])\n",
    "    }\n",
    "    SKILLS_JSON_PATH.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(\"Skills exportiert nach:\", SKILLS_JSON_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
