{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33e22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, pathlib, xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# <<< Pfade anpassen, falls nötig >>>\n",
    "SLN_PATH   = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\v1.0_Tisch01_Beckhoff_I4.0.sln\"\n",
    "OUT_XML    = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\io_mappings.xml\"\n",
    "OUT_JSON   = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\io_mappings.json\"\n",
    "\n",
    "# util: erstes n Zeichen eines Strings sicher anzeigen\n",
    "def head(text, n=600):\n",
    "    t = (text or \"\")[:n].replace(\"\\r\",\" \").replace(\"\\n\",\" \")\n",
    "    return t + (\"…\" if text and len(text) > n else \"\")\n",
    "\n",
    "# util: TwinCAT Pfad -> Teilstücke\n",
    "def split_tc_path(p):\n",
    "    return [s for s in (p or \"\").split(\"^\") if s]\n",
    "\n",
    "# util: VarA/VarB (\"PlcTask Inputs^MAIN.bX\" bzw. \"Term 1 (EK1100)^...^Channel 1^Input\")\n",
    "def parse_var_side(var_str):\n",
    "    parts = split_tc_path(var_str)\n",
    "    return {\n",
    "        \"raw\": var_str,\n",
    "        \"parts\": parts,\n",
    "        \"is_plc_task\": parts[0].lower().startswith(\"plctask \"),\n",
    "        \"channel\": parts[-1] if parts else \"\"\n",
    "    }\n",
    "\n",
    "# util: Adresse Byte.Bit aus „Channel X^Input“ ziehen wir später aus OwnerB-Pfad über Prozessabbild (Erweiterung möglich)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b915b043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projects in Solution:\n",
      "  Index 1: Name=Beckhoff_I4.0-Demonstrator, FullName=C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\Test1\\Beckhoff_I4.0-Demonstrator.tsproj\n",
      "Verwende TwinCAT-Projekt: Beckhoff_I4.0-Demonstrator\n"
     ]
    }
   ],
   "source": [
    "import win32com.client as com\n",
    "\n",
    "dte = com.Dispatch(\"TcXaeShell.DTE.17.0\")  # ggf. Version anpassen (17=VS 2022)\n",
    "dte.SuppressUI = False\n",
    "dte.MainWindow.Visible = True\n",
    "\n",
    "solution = dte.Solution\n",
    "solution.Open(SLN_PATH)\n",
    "\n",
    "# .tsproj suchen\n",
    "tc_project = None\n",
    "print(\"Projects in Solution:\")\n",
    "for i in range(1, solution.Projects.Count + 1):\n",
    "    p = solution.Projects.Item(i)\n",
    "    print(f\"  Index {i}: Name={p.Name}, FullName={p.FullName}\")\n",
    "    if p.FullName.lower().endswith(\".tsproj\"):\n",
    "        tc_project = p\n",
    "\n",
    "if tc_project is None:\n",
    "    raise RuntimeError(\"Kein TwinCAT-Systemprojekt (.tsproj) in der Solution gefunden\")\n",
    "\n",
    "print(\"Verwende TwinCAT-Projekt:\", tc_project.Name)\n",
    "sys_mgr = tc_project.Object  # SystemManager (Automation Interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e429cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping-XML gespeichert: C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\io_mappings.xml\n",
      "XML-Head: <?xml version=\"1.0\"?><VarLinks><OwnerA Name=\"TIPC^SPS_Demonstrator^SPS_Demonstrator Instance\"><OwnerB Name=\"TIID^Device 1 (EtherCAT)^Term 1 (EK1200)^Term 10 (EL2409)\"><Link VarA=\"PlcTask Outputs^GVL_MBS.MBS_Kompressor\" VarB=\"Channel 2^Output\"/><Link VarA=\"PlcTask Outputs^GVL_MBS.MBS_Leuchte_Ofen\" VarB=\"Channel 1^Output\"/><Link VarA=\"PlcTask Outputs^GVL_MBS.MBS_MV_Ofentuer\" VarB=\"Channel 5^Output\"/><Link VarA=\"PlcTask Outputs^GVL_MBS.MBS_MV_Schieber\" VarB=\"Channel 6^Output\"/><Link VarA=\"PlcTask O…\n",
      "PLC↔I/O-Links gefunden: 79\n",
      "OK: C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\io_mappings.json (79 Einträge)\n"
     ]
    }
   ],
   "source": [
    "# 1) rohes Mapping-XML erzeugen (alle konfigurierten Links, u. a. PLC<->I/O)\n",
    "xml_text = sys_mgr.ProduceMappingInfo()  # ITcSysManager3::ProduceMappingInfo\n",
    "with open(OUT_XML, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(xml_text or \"\")\n",
    "print(\"Mapping-XML gespeichert:\", OUT_XML)\n",
    "print(\"XML-Head:\", head(xml_text, 500))\n",
    "\n",
    "# 2) XML -> strukturierte Liste von VarLinks\n",
    "links = []\n",
    "if xml_text and \"<VarLinks\" in xml_text:\n",
    "    root = ET.fromstring(xml_text)\n",
    "    # Struktur lt. Beckhoff-Doku:\n",
    "    # <VarLinks>\n",
    "    #   <OwnerA Name=\"TIPC^...\"> <OwnerB Name=\"TIID^...\"><Link VarA=\"...\" VarB=\"...\"/></OwnerB> ...\n",
    "    #   <OwnerA Name=\"TIID^...\"> <OwnerB Name=\"TIPC^...\"><Link VarA=\"...\" VarB=\"...\"/></OwnerB> ...\n",
    "    # </VarLinks>\n",
    "    for ownerA in root.findall(\".//OwnerA\"):\n",
    "        ownerA_name = ownerA.attrib.get(\"Name\", \"\")\n",
    "        for ownerB in ownerA.findall(\"./OwnerB\"):\n",
    "            ownerB_name = ownerB.attrib.get(\"Name\", \"\")\n",
    "            for link in ownerB.findall(\"./Link\"):\n",
    "                varA = link.attrib.get(\"VarA\", \"\")\n",
    "                varB = link.attrib.get(\"VarB\", \"\")\n",
    "                rec = {\n",
    "                    \"ownerA\": ownerA_name,\n",
    "                    \"ownerB\": ownerB_name,\n",
    "                    \"varA\": varA,\n",
    "                    \"varB\": varB,\n",
    "                    \"sideA\": parse_var_side(varA),\n",
    "                    \"sideB\": parse_var_side(varB),\n",
    "                }\n",
    "                # Normalisieren: PLC-Seite immer unter 'plc', I/O-Seite unter 'io'\n",
    "                if rec[\"sideA\"][\"is_plc_task\"]:\n",
    "                    rec[\"plc\"] = rec[\"sideA\"]; rec[\"io\"] = rec[\"sideB\"]\n",
    "                elif rec[\"sideB\"][\"is_plc_task\"]:\n",
    "                    rec[\"plc\"] = rec[\"sideB\"]; rec[\"io\"] = rec[\"sideA\"]\n",
    "                else:\n",
    "                    # selten: TcCOM<->I/O oder PLC<->TcCOM – wir lassen roh stehen\n",
    "                    rec[\"plc\"] = None; rec[\"io\"] = None\n",
    "                links.append(rec)\n",
    "\n",
    "print(\"PLC↔I/O-Links gefunden:\", sum(1 for r in links if r[\"plc\"] and r[\"io\"]))\n",
    "\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(links, f, ensure_ascii=False, indent=2)\n",
    "print(\"OK:\", OUT_JSON, f\"({len(links)} Einträge)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07335466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\io_mappings.json  (79 Links, 79 mit Byte/Bit, 0 ohne Channel-XML)\n"
     ]
    }
   ],
   "source": [
    "# Zelle 4 (enriched, überschreibt io_mappings.json mit Adressfeldern)\n",
    "\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "\n",
    "# << gleiche OUT_JSON wie in Zelle 3 >>\n",
    "# OUT_JSON = r\"C:\\Users\\Alexander Verkhov\\OneDrive\\Dokumente\\MPA\\twincat2\\TwinCAT\\io_mappings.json\"\n",
    "\n",
    "def _full_channel_path(ownerB_name: str, varB: str) -> str:\n",
    "    return f\"{ownerB_name}^{varB}\"\n",
    "\n",
    "# --- Parser-Helfer für Channel-XML (ProduceXml) ---\n",
    "\n",
    "_num = r\"[-]?\\d+\"\n",
    "def _get_int(xml: str, tag: str):\n",
    "    m = re.search(fr\"<{tag}[^>]*>\\s*({_num})\\s*</{tag}>\", xml)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def _get_hex_attr(xml: str, tag: str):\n",
    "    m = re.search(fr\"<{tag}[^>]*Hex=\\\"#x([0-9A-Fa-f]+)\\\"\", xml)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def _parse_channel_meta(xml_text: str):\n",
    "    # Standard-Felder, die Beckhoff im Channel-XML bereitstellt (je nach Klemme/Version)\n",
    "    vsize    = _get_int(xml_text, \"VarBitSize\")\n",
    "    vaddr    = _get_int(xml_text, \"VarBitAddr\")    # Bitadresse im Prozessabbild\n",
    "    vinout   = _get_int(xml_text, \"VarInOut\")      # 0 = Input, 1 = Output\n",
    "    ams      = _get_int(xml_text, \"AmsPort\")\n",
    "    igrp     = _get_int(xml_text, \"IndexGroup\")\n",
    "    ioff     = _get_int(xml_text, \"IndexOffset\")\n",
    "    ln       = _get_int(xml_text, \"Length\")\n",
    "    igrp_hex = _get_hex_attr(xml_text, \"IndexGroup\")\n",
    "    ioff_hex = _get_hex_attr(xml_text, \"IndexOffset\")\n",
    "\n",
    "    # Falls einige Geräte statt VarBitAddr getrennte Offsets liefern:\n",
    "    kv = {}\n",
    "    for m in re.finditer(r\"<([A-Za-z0-9_]+)>\\s*([0-9]+)\\s*</\\1>\", xml_text):\n",
    "        tag, val = m.group(1), int(m.group(2))\n",
    "        if \"Offs\" in tag or \"Offset\" in tag or tag in (\"ByteOffset\", \"BitOffset\"):\n",
    "            kv[tag] = val\n",
    "    for m in re.finditer(r'Name=\"([^\"]*?(?:Offs|Offset)[^\"]*)\"\\s*>\\s*([0-9]+)\\s*<', xml_text):\n",
    "        kv[m.group(1)] = int(m.group(2))\n",
    "\n",
    "    # Byte/Bit bevorzugt aus VarBitAddr, sonst aus gefundenen Tags\n",
    "    if isinstance(vaddr, int):\n",
    "        byte_off = vaddr // 8\n",
    "        bit_off  = vaddr % 8\n",
    "    else:\n",
    "        byte_off = (kv.get(\"InputOffsByte\") or kv.get(\"OutputOffsByte\")\n",
    "                    or kv.get(\"ByteOffset\") or kv.get(\"OffsByte\"))\n",
    "        bit_off  = (kv.get(\"InputOffsBit\")  or kv.get(\"OutputOffsBit\")\n",
    "                    or kv.get(\"BitOffset\")  or kv.get(\"OffsBit\"))\n",
    "\n",
    "    return {\n",
    "        \"varBitSize\": vsize,\n",
    "        \"varBitAddr\": vaddr,\n",
    "        \"varInOut\":   vinout,\n",
    "        \"amsPort\":    ams,\n",
    "        \"indexGroup\": igrp,\n",
    "        \"indexOffset\": ioff,\n",
    "        \"length\":     ln,\n",
    "        \"indexGroupHex\": igrp_hex,\n",
    "        \"indexOffsetHex\": ioff_hex,\n",
    "        \"byte_offset\": byte_off,\n",
    "        \"bit_offset\":  bit_off,\n",
    "        \"rawOffsets\":  kv\n",
    "    }\n",
    "\n",
    "def _dir_letter(plc_path_lower: str, var_inout: int, chan_spec: str) -> str:\n",
    "    # Priorität: Channel-Suffix → PLC-Pfad → VarInOut\n",
    "    if chan_spec.endswith(\"^Input\"):  return \"I\"\n",
    "    if chan_spec.endswith(\"^Output\"): return \"Q\"\n",
    "    if \"plctask inputs\"  in plc_path_lower: return \"I\"\n",
    "    if \"plctask outputs\" in plc_path_lower: return \"Q\"\n",
    "    if var_inout == 0: return \"I\"\n",
    "    if var_inout == 1: return \"Q\"\n",
    "    return \"?\"\n",
    "\n",
    "def _plc_var_only(plc_side_var: str) -> str:\n",
    "    parts = plc_side_var.split(\"^\")\n",
    "    return parts[-1] if parts else plc_side_var\n",
    "\n",
    "# --------- Iterate Links aus Zelle 3, lesen Channel-XML und anreichern ----------\n",
    "\n",
    "bundle = []\n",
    "missing = 0\n",
    "\n",
    "for rec in links:\n",
    "    if not rec.get(\"plc\") or not rec.get(\"io\"):\n",
    "        continue\n",
    "\n",
    "    plc_var_path = rec[\"plc\"][\"raw\"]                   # z. B. \"PlcTask Outputs^GVL_MBS.MBS_Leuchte_Ofen\"\n",
    "    plc_var_name = _plc_var_only(plc_var_path)         # z. B. \"GVL_MBS.MBS_Leuchte_Ofen\"\n",
    "    io_owner     = rec[\"ownerB\"] if rec[\"ownerB\"].startswith(\"TIID^\") else rec[\"ownerA\"]\n",
    "    io_chan_spec = rec[\"io\"][\"raw\"]                    # z. B. \"Channel 2^Output\"\n",
    "    full_io_path = _full_channel_path(io_owner, io_chan_spec)\n",
    "\n",
    "    # Standardwerte\n",
    "    meta = {\n",
    "        \"varBitSize\": None, \"varBitAddr\": None, \"varInOut\": None,\n",
    "        \"amsPort\": None, \"indexGroup\": None, \"indexOffset\": None, \"length\": None,\n",
    "        \"indexGroupHex\": None, \"indexOffsetHex\": None,\n",
    "        \"byte_offset\": None, \"bit_offset\": None, \"rawOffsets\": {}\n",
    "    }\n",
    "    raw_xml = \"\"\n",
    "    try:\n",
    "        ch_item = sys_mgr.LookupTreeItem(full_io_path)\n",
    "        try:\n",
    "            ch_xml = ch_item.ProduceXml(0)\n",
    "        except TypeError:\n",
    "            ch_xml = ch_item.ProduceXml()\n",
    "        raw_xml = ch_xml\n",
    "        meta = _parse_channel_meta(ch_xml)\n",
    "    except Exception as e:\n",
    "        missing += 1\n",
    "        raw_xml = f\"ERROR: {e}\"\n",
    "\n",
    "    # %I/%Q Byte.Bit bilden (falls Byte/Bit bekannt)\n",
    "    d_letter = _dir_letter(plc_var_path.lower(), meta.get(\"varInOut\"), io_chan_spec)\n",
    "    if isinstance(meta.get(\"byte_offset\"), int) and isinstance(meta.get(\"bit_offset\"), int):\n",
    "        pi_addr = f\"{d_letter} {meta['byte_offset']}.{meta['bit_offset']}\"\n",
    "    else:\n",
    "        # falls nur VarBitAddr ohne Aufspaltung vorhanden war, erneut rechnen\n",
    "        vaddr = meta.get(\"varBitAddr\")\n",
    "        if isinstance(vaddr, int):\n",
    "            pi_addr = f\"{d_letter} {vaddr//8}.{vaddr%8}\"\n",
    "            meta[\"byte_offset\"] = vaddr//8\n",
    "            meta[\"bit_offset\"]  = vaddr%8\n",
    "        else:\n",
    "            pi_addr = None\n",
    "\n",
    "    bundle.append({\n",
    "        \"plc_path\":     plc_var_path,\n",
    "        \"plc_var\":      plc_var_name,\n",
    "        \"device_path\":  io_owner,\n",
    "        \"channel_label\":io_chan_spec,\n",
    "        \"io_path\":      full_io_path,\n",
    "        \"direction\":    \"Input\" if d_letter==\"I\" else \"Output\" if d_letter==\"Q\" else \"Unknown\",\n",
    "        \"ea_address\":   pi_addr,                  # z. B. \"Q 77.0\" / \"I 39.0\"\n",
    "        \"varBitAddr\":   meta[\"varBitAddr\"],       # Bitadresse im Prozessabbild\n",
    "        \"varBitSize\":   meta[\"varBitSize\"],\n",
    "        \"varInOut\":     meta[\"varInOut\"],         # 0=Input, 1=Output\n",
    "        \"byte_offset\":  meta[\"byte_offset\"],      # bevorzugt aus VarBitAddr berechnet\n",
    "        \"bit_offset\":   meta[\"bit_offset\"],\n",
    "        \"amsPort\":      meta[\"amsPort\"],\n",
    "        \"indexGroup\":   meta[\"indexGroup\"],\n",
    "        \"indexGroupHex\":meta[\"indexGroupHex\"],\n",
    "        \"indexOffset\":  meta[\"indexOffset\"],\n",
    "        \"indexOffsetHex\":meta[\"indexOffsetHex\"],\n",
    "        \"length\":       meta[\"length\"],\n",
    "        \"raw_offsets\":  meta[\"rawOffsets\"],\n",
    "        \"io_raw_xml\":   raw_xml[:4000]            # kürzen, wenn du Platz sparen willst\n",
    "    })\n",
    "\n",
    "# --- Speichern: überschreibt die bestehende io_mappings.json mit den angereicherten Einträgen ---\n",
    "Path(OUT_JSON).write_text(json.dumps(bundle, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(f\"OK: {OUT_JSON}  ({len(bundle)} Links, {sum(1 for x in bundle if x['byte_offset'] is not None)} mit Byte/Bit, {missing} ohne Channel-XML)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd52d2eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PROG_IO_JSON_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Zelle 5: Signal-Graph bauen (aus program_io_with_mapping.json) und bis zur Hardware verfolgen\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m programs = json.loads(Path(\u001b[43mPROG_IO_JSON_PATH\u001b[49m).read_text(encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Knoten: vollqualifizierte Namen \"POU.var\" und globale \"GVL.var\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfq\u001b[39m(pou, var): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpou\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'PROG_IO_JSON_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# Zelle 5: Signal-Graph bauen (aus program_io_with_mapping.json) und bis zur Hardware verfolgen\n",
    "programs = json.loads(Path(PROG_IO_JSON_PATH).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Knoten: vollqualifizierte Namen \"POU.var\" und globale \"GVL.var\"\n",
    "def fq(pou, var): return f\"{pou}.{var}\"\n",
    "\n",
    "# Graph: von 'producer' → 'consumer' (vereinfachtes Modell)\n",
    "edges = []   # (src, dst)\n",
    "vars_all = set()\n",
    "\n",
    "# 5.1 POU-IO registrieren\n",
    "for prog in programs:\n",
    "    pname = prog[\"program\"]\n",
    "    for d in (\"inputs\",\"outputs\",\"inouts\",\"temps\"):\n",
    "        for v in prog[\"io\"].get(d,[]):\n",
    "            vars_all.add(fq(pname, v[\"name\"]))\n",
    "\n",
    "# 5.2 FBD-Subcalls & Verdrahtungen als Kanten abbildern (vereinfachtes Mapping)\n",
    "for prog in programs:\n",
    "    pname = prog[\"program\"]\n",
    "    for call in prog.get(\"subcalls\", []):\n",
    "        # Inputs: external actual → callee.formal\n",
    "        for i in call.get(\"inputs\", []):\n",
    "            if i.get(\"actual\"):\n",
    "                src = i[\"actual\"]                  # externer Ausdruck (z. B. GVL_X.Z)\n",
    "                dst = f\"{call['typeName']}.{i['formal']}\"\n",
    "                edges.append((src, dst))\n",
    "        # Outputs: callee.formal → external actual\n",
    "        for o in call.get(\"outputs\", []):\n",
    "            if o.get(\"actual\"):\n",
    "                src = f\"{call['typeName']}.{o['formal']}\"\n",
    "                dst = o[\"actual\"]\n",
    "                edges.append((src, dst))\n",
    "\n",
    "# 5.3 HW-gebundene Variablen aus io_mappings.json\n",
    "io_map = json.loads(Path(IO_JSON_PATH).read_text(encoding=\"utf-8\"))\n",
    "hw_vars = { m[\"plc_var\"] for m in io_map if m.get(\"byte_offset\") is not None and m.get(\"bit_offset\") is not None }\n",
    "\n",
    "# 5.4 Traces: von jedem Programm-Output in Richtung eines hw_vars\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "adj = defaultdict(list)\n",
    "for s, d in edges:\n",
    "    adj[s].append(d)\n",
    "\n",
    "def bfs_paths(start, targets, max_depth=20):\n",
    "    paths = []\n",
    "    q = deque([([start], 0)])\n",
    "    seen = set([start])\n",
    "    while q:\n",
    "        path, depth = q.popleft()\n",
    "        node = path[-1]\n",
    "        if depth > max_depth: continue\n",
    "        base = node.split(\".\")[-1]  # nur Varname ohne POU\n",
    "        if base in targets:\n",
    "            paths.append(path)\n",
    "            continue\n",
    "        for nxt in adj.get(node, []):\n",
    "            if len(path) > 1_000: break\n",
    "            if (node, nxt) in seen: \n",
    "                continue\n",
    "            seen.add((node, nxt))\n",
    "            q.append((path+[nxt], depth+1))\n",
    "    return paths\n",
    "\n",
    "traces_out = []\n",
    "for prog in programs:\n",
    "    pname = prog[\"program\"]\n",
    "    outs = []\n",
    "    for v in prog[\"io\"].get(\"outputs\", []):\n",
    "        start = fq(pname, v[\"name\"])\n",
    "        paths = bfs_paths(start, hw_vars)\n",
    "        outs.append({\n",
    "            \"var\": v[\"name\"],\n",
    "            \"paths\": [{\"hops\": p, \"len\": len(p)} for p in paths],\n",
    "            \"hardware\": any(paths)\n",
    "        })\n",
    "    traces_out.append({\n",
    "        \"program\": pname,\n",
    "        \"outputs\": outs\n",
    "    })\n",
    "\n",
    "Path(VAR_TRACES_PATH).write_text(json.dumps(traces_out, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"OK:\", VAR_TRACES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db909a43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'URIRef' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Properties/Classes (nutzt vorhandene, sonst neue IRIs)\u001b[39;00m\n\u001b[32m     33\u001b[39m op_isBoundToChannel = AG[\u001b[33m\"\u001b[39m\u001b[33mop_isBoundToChannel\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m class_Variable      = \u001b[43mAG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass_Variable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m class_IoChannel     = AG.get(\u001b[33m\"\u001b[39m\u001b[33mclass_IoChannel\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m dp_qualifiedName = DP.get(\u001b[33m\"\u001b[39m\u001b[33mqualifiedName\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'URIRef' object is not callable"
     ]
    }
   ],
   "source": [
    "# Zelle 6: Wissensgraph (TTL) um echte HW-Bindings anreichern\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "def slug(s: str) -> str:\n",
    "    s = unicodedata.normalize('NFKD', s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = re.sub(r\"[^A-Za-z0-9]+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "def make_pi(direction, b, bit):\n",
    "    if b is None or bit is None: return None\n",
    "    direction = (direction or \"\").lower()\n",
    "    if direction.startswith(\"in\"):  return f\"E{b}.{bit}\"\n",
    "    if direction.startswith(\"out\"): return f\"A{b}.{bit}\"\n",
    "    return f\"PI{b}.{bit}\"\n",
    "\n",
    "g = Graph()\n",
    "g.parse(TTL_PATH, format=\"turtle\")\n",
    "\n",
    "# Prefixe übernehmen/setzen\n",
    "def get_ns(graph: Graph, pref_candidates, default_iri):\n",
    "    for pref, iri in graph.namespaces():\n",
    "        if pref.lower() in [p.lower() for p in pref_candidates]:\n",
    "            return Namespace(str(iri))\n",
    "    graph.bind(pref_candidates[0], default_iri)\n",
    "    return Namespace(default_iri)\n",
    "\n",
    "AG = get_ns(g, [\"AG\",\"ag\"], \"http://example.org/ag#\")\n",
    "DP = get_ns(g, [\"DP\",\"dp\"], \"http://example.org/dp#\")\n",
    "\n",
    "# Properties/Classes (nutzt vorhandene, sonst neue IRIs)\n",
    "op_isBoundToChannel = AG[\"op_isBoundToChannel\"]\n",
    "class_Variable      = AG.get(\"class_Variable\")\n",
    "class_IoChannel     = AG.get(\"class_IoChannel\")\n",
    "\n",
    "dp_qualifiedName = DP.get(\"qualifiedName\")\n",
    "dp_byteOffset    = DP.get(\"byteOffset\")\n",
    "dp_bitOffset     = DP.get(\"bitOffset\")\n",
    "dp_ioPath        = DP.get(\"ioPath\")\n",
    "dp_addressPI     = DP.get(\"addressPI\")\n",
    "dp_isHardware    = DP.get(\"isHardware\")\n",
    "\n",
    "io_map = json.loads(Path(IO_JSON_PATH).read_text(encoding=\"utf-8\"))\n",
    "updates = 0\n",
    "\n",
    "# Helfer: Variable in KG via dp:qualifiedName finden oder neu anlegen\n",
    "def find_or_make_var(qname: str):\n",
    "    for s in g.subjects(dp_qualifiedName, Literal(qname)):\n",
    "        return s\n",
    "    node = URIRef(AG + \"Var_\" + slug(qname))\n",
    "    if class_Variable: g.add((node, RDF.type, class_Variable))\n",
    "    g.add((node, dp_qualifiedName, Literal(qname)))\n",
    "    return node\n",
    "\n",
    "for m in io_map:\n",
    "    qname   = m[\"plc_var\"]               # z. B. GVL_HRL.HRL_MOT_horizontal_zum_Regal\n",
    "    io_path = m[\"io_path\"]               # TIID^EtherCAT^...\n",
    "    byte_off= m.get(\"byte_offset\")\n",
    "    bit_off = m.get(\"bit_offset\")\n",
    "    addr_pi = make_pi(m.get(\"direction\"), byte_off, bit_off)\n",
    "\n",
    "    var_node = find_or_make_var(qname)\n",
    "    io_node  = URIRef(AG + \"IoChan_\" + slug(io_path))\n",
    "    if class_IoChannel:\n",
    "        g.add((io_node, RDF.type, class_IoChannel))\n",
    "\n",
    "    g.add((var_node, op_isBoundToChannel, io_node))\n",
    "    if byte_off is not None:\n",
    "        g.add((io_node, dp_byteOffset, Literal(int(byte_off), datatype=XSD.nonNegativeInteger)))\n",
    "    if bit_off is not None:\n",
    "        g.add((io_node, dp_bitOffset,  Literal(int(bit_off),  datatype=XSD.nonNegativeInteger)))\n",
    "    g.add((io_node, dp_ioPath, Literal(io_path, datatype=XSD.string)))\n",
    "    if addr_pi:\n",
    "        g.add((io_node, dp_addressPI, Literal(addr_pi, datatype=XSD.string)))\n",
    "    g.add((var_node, dp_isHardware, Literal(True, datatype=XSD.boolean)))\n",
    "    updates += 1\n",
    "\n",
    "g.serialize(TTL_PATH, format=\"turtle\")\n",
    "print(\"KG-Updates:\", updates, \"| gespeichert:\", TTL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf83206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 7 (optional): variable_traces.json mit hardware=true aktualisieren\n",
    "if Path(VAR_TRACES_PATH).exists():\n",
    "    traces = json.loads(Path(VAR_TRACES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    bound_qnames = { m[\"plc_var\"] for m in json.loads(Path(IO_JSON_PATH).read_text(encoding=\"utf-8\")) }\n",
    "    changed = 0\n",
    "    for p in traces:\n",
    "        for o in p.get(\"outputs\", []):\n",
    "            if o.get(\"hardware\"): \n",
    "                continue\n",
    "            # wenn ein Hop den Namen einer gebundenen Variable enthält\n",
    "            if any((hop.split(\".\")[-1] in bound_qnames) for path in o.get(\"paths\", []) for hop in path.get(\"hops\", [])):\n",
    "                o[\"hardware\"] = True\n",
    "                changed += 1\n",
    "    Path(VAR_TRACES_PATH).write_text(json.dumps(traces, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    print(\"variable_traces.json aktualisiert (hardware=true in\", changed, \"Outputs).\")\n",
    "else:\n",
    "    print(\"variable_traces.json nicht gefunden – übersprungen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
