{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d146ae",
   "metadata": {},
   "source": [
    "# PLC Knowledge Graph ChatBot (Gemini + RDFLib) ‚Äì Text2SPARQL Template\n",
    "\n",
    "Dieses Notebook ist ein **Template**, um Fragen zu einem PLC-Programm √ºber einen **Wissensgraphen (TTL/RDF)** zu beantworten.\n",
    "\n",
    "**Modus: Text2SPARQL (schnell)**\n",
    "1) LLM erzeugt eine SPARQL SELECT Query  \n",
    "2) RDFLib f√ºhrt sie auf dem lokalen Graph aus  \n",
    "3) Ergebnis wird als **Tabelle (Pandas DataFrame)** angezeigt\n",
    "\n",
    "‚úÖ Anforderungen:\n",
    "- Gemini API Key aus Datei laden\n",
    "- Text2SPARQL ausf√ºhren\n",
    "- Tabellen bleiben Tabellen (kein eingebetteter Flie√ütext)\n",
    "- Ausgabe zeigt **nur** die ausgef√ºhrte SPARQL Query (und optional die Tabelle, wenn vorhanden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da36a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in d:\\ma_python_agent\\.venv311\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: pandas in d:\\ma_python_agent\\.venv311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: langchain-core in d:\\ma_python_agent\\.venv311\\lib\\site-packages (1.2.7)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from rdflib) (3.2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-core) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from langchain-openai) (2.8.1)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2026.1.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Requirement already satisfied: colorama in d:\\ma_python_agent\\.venv311\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "   ---------------------------------------- 0.0/878.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 878.7/878.7 kB 13.1 MB/s  0:00:00\n",
      "Downloading regex-2026.1.15-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Installing collected packages: regex, tiktoken, langchain-openai\n",
      "\n",
      "   ---------------------------------------- 0/3 [regex]\n",
      "   ------------- -------------------------- 1/3 [tiktoken]\n",
      "   -------------------------- ------------- 2/3 [langchain-openai]\n",
      "   -------------------------- ------------- 2/3 [langchain-openai]\n",
      "   -------------------------- ------------- 2/3 [langchain-openai]\n",
      "   ---------------------------------------- 3/3 [langchain-openai]\n",
      "\n",
      "Successfully installed langchain-openai-1.1.7 regex-2026.1.15 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# (1) Install (einmalig)\n",
    "!pip install -U rdflib pandas langchain-core langchain-openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342ff5c",
   "metadata": {},
   "source": [
    "## (2) Konfiguration: Gemini API Key aus Datei laden\n",
    "\n",
    "Du hast den Key in:\n",
    "`C:\\Users\\Alexander Verkhov\\Desktop\\Gemini API Key.txt`\n",
    "\n",
    "Die LangChain Integration liest standardm√§√üig `GOOGLE_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04acaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OPENAI_API_KEY erfolgreich gesetzt.\n"
     ]
    }
   ],
   "source": [
    "# === ZELLE 2: KONFIGURATION ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === Pfad zur TTL-Datei (bleibt gleich) ===\n",
    "TTL_PATH = r\"D:\\MA_Python_Agent\\MSRGuard_Anpassung\\KGs\\Test2_filled.ttl\"\n",
    "\n",
    "# === OpenAI API Key aus Datei laden ===\n",
    "# Pfad zu deiner OpenAI Key Textdatei\n",
    "openai_key_path = r\"C:\\Users\\Alexander Verkhov\\Desktop\\OpenAI API Key.txt\"\n",
    "\n",
    "try:\n",
    "    # Key einlesen und Leerzeichen entfernen\n",
    "    key = Path(openai_key_path).read_text(encoding=\"utf-8\").strip()\n",
    "    \n",
    "    # OpenAI ben√∂tigt die Variable OPENAI_API_KEY\n",
    "    os.environ[\"OPENAI_API_KEY\"] = key\n",
    "    print(\"‚úÖ OPENAI_API_KEY erfolgreich gesetzt.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fehler beim Laden des Keys: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d61cc13",
   "metadata": {},
   "source": [
    "## (3) Wissensgraph laden (TTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92686b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph geladen.\n",
      "Triples: 16410\n",
      "Namespaces (Auszug): [('brick', rdflib.term.URIRef('https://brickschema.org/schema/Brick#')), ('csvw', rdflib.term.URIRef('http://www.w3.org/ns/csvw#')), ('dc', rdflib.term.URIRef('http://purl.org/dc/elements/1.1/')), ('dcat', rdflib.term.URIRef('http://www.w3.org/ns/dcat#')), ('dcmitype', rdflib.term.URIRef('http://purl.org/dc/dcmitype/')), ('dcterms', rdflib.term.URIRef('http://purl.org/dc/terms/')), ('dcam', rdflib.term.URIRef('http://purl.org/dc/dcam/')), ('doap', rdflib.term.URIRef('http://usefulinc.com/ns/doap#'))]\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "g = Graph()\n",
    "g.parse(TTL_PATH, format=\"turtle\")\n",
    "\n",
    "print(\"‚úÖ Graph geladen.\")\n",
    "print(\"Triples:\", len(g))\n",
    "print(\"Namespaces (Auszug):\", list(g.namespaces())[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d6061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extrahiertes Schema (Fast Python Version) ---\n",
      "### KLASSEN:\n",
      "ag:class_FBInstance, ag:class_FBType, ag:class_GlobalVariableList, ag:class_IOChannel, ag:class_PLCProject, ag:class_POUCall, ag:class_ParameterAssignment, ag:class_Port, ag:class_Program, ag:class_SignalSource, ag:class_StandardFBType, ag:class_Variable\n",
      "\n",
      "### BEZIEHUNGEN (Struktur):\n",
      "Format: SubjektKlasse --[Relation]--> ObjektKlasse\n",
      "ag:class_FBInstance --[op:isInstanceOfFBType]--> ag:class_FBType\n",
      "ag:class_FBInstance --[op:isInstanceOfFBType]--> ag:class_StandardFBType\n",
      "ag:class_FBType --[op:containsPOUCall]--> ag:class_POUCall\n",
      "ag:class_FBType --[op:hasInternalVariable]--> ag:class_Variable\n",
      "ag:class_FBType --[op:hasPort]--> ag:class_Port\n",
      "ag:class_FBType --[op:usesVariable]--> ag:class_Variable\n",
      "ag:class_GlobalVariableList --[op:listsGlobalVariable]--> ag:class_Variable\n",
      "ag:class_PLCProject --[op:consistsOfPOU]--> ag:class_FBType\n",
      "ag:class_PLCProject --[op:consistsOfPOU]--> ag:class_Program\n",
      "ag:class_POUCall --[op:callsPOU]--> ag:class_FBType\n",
      "ag:class_POUCall --[op:callsPOU]--> ag:class_StandardFBType\n",
      "ag:class_POUCall --[op:hasAssignment]--> ag:class_ParameterAssignment\n",
      "ag:class_POUCall --[op:hasCallerVariable]--> ag:class_Variable\n",
      "ag:class_ParameterAssignment --[op:assignsFrom]--> ag:class_SignalSource\n",
      "ag:class_ParameterAssignment --[op:assignsFrom]--> ag:class_Variable\n",
      "ag:class_ParameterAssignment --[op:assignsToPort]--> ag:class_Port\n",
      "ag:class_Program --[op:containsPOUCall]--> ag:class_POUCall\n",
      "ag:class_Program --[op:hasInternalVariable]--> ag:class_Variable\n",
      "ag:class_Program --[op:hasPort]--> ag:class_Port\n",
      "ag:class_Program --[op:usesVariable]--> ag:class_Variable\n",
      "ag:class_SignalSource --[op:instantiatesPort]--> ag:class_Port\n",
      "ag:class_SignalSource --[op:isPortOfInstance]--> ag:class_FBInstance\n",
      "ag:class_StandardFBType --[op:hasPort]--> ag:class_Port\n",
      "ag:class_Variable --[op:implementsPort]--> ag:class_Port\n",
      "ag:class_Variable --[op:isBoundToChannel]--> ag:class_IOChannel\n",
      "ag:class_Variable --[op:representsFBInstance]--> ag:class_FBInstance\n",
      "\n",
      "### ATTRIBUTE (Daten):\n",
      "\n",
      "ag:class_FBType:\n",
      "  - dp:hasConsistencyReport\n",
      "  - dp:hasPOUCode\n",
      "  - dp:hasPOULanguage\n",
      "  - dp:hasPOUName\n",
      "\n",
      "ag:class_GlobalVariableList:\n",
      "  - dp:hasGlobalVariableListName\n",
      "\n",
      "ag:class_PLCProject:\n",
      "  - dp:hasPLCProjectName\n",
      "\n",
      "ag:class_Port:\n",
      "  - dp:hasPortDirection\n",
      "  - dp:hasPortName\n",
      "  - dp:hasPortType\n",
      "  - dp:isUnusedPort\n",
      "\n",
      "ag:class_Program:\n",
      "  - dp:hasConsistencyReport\n",
      "  - dp:hasPOUCode\n",
      "  - dp:hasPOULanguage\n",
      "  - dp:hasPOUName\n",
      "  - dp:hasProgramName\n",
      "\n",
      "ag:class_StandardFBType:\n",
      "  - dp:hasPOULanguage\n",
      "  - dp:hasPOUName\n",
      "  - dp:hasPOUType\n",
      "\n",
      "ag:class_Variable:\n",
      "  - dp:hasHardwareAddress\n",
      "  - dp:hasInitialValue\n",
      "  - dp:hasVariableName\n",
      "  - dp:hasVariableScope\n",
      "  - dp:hasVariableType\n",
      "  - dp:ioRawXml\n",
      "  - dp:isUnusedVar\n"
     ]
    }
   ],
   "source": [
    "# === ZELLE 3 KOMPLETT ERSETZEN (Python-Loop statt SPARQL) ===\n",
    "\n",
    "from rdflib import Graph, RDF\n",
    "\n",
    "def shorten_uri(uri, graph):\n",
    "    u = str(uri)\n",
    "    # Manuelle Verk√ºrzung f√ºr sauberen Prompt\n",
    "    u = u.replace(\"http://www.semanticweb.org/AgentProgramParams/dp_\", \"dp:\")\n",
    "    u = u.replace(\"http://www.semanticweb.org/AgentProgramParams/op_\", \"op:\")\n",
    "    u = u.replace(\"http://www.semanticweb.org/AgentProgramParams/class_\", \"ag:class_\") # Explizit class_ Prefix\n",
    "    u = u.replace(\"http://www.semanticweb.org/AgentProgramParams/\", \"ag:\")\n",
    "    \n",
    "    # Fallback\n",
    "    try:\n",
    "        return graph.namespace_manager.normalizeUri(uri)\n",
    "    except:\n",
    "        return u\n",
    "\n",
    "def get_kg_schema_fast(graph):\n",
    "    # 1. Cache aufbauen: Welches Subjekt hat welchen Typ?\n",
    "    # Wir speichern nur Typen, die \"class_\" im Namen haben.\n",
    "    entity_types = {}\n",
    "    \n",
    "    # Iteriere √ºber alle Typ-Zuweisungen (s a type)\n",
    "    for s, _, t in graph.triples((None, RDF.type, None)):\n",
    "        t_str = str(t)\n",
    "        if \"class_\" in t_str:\n",
    "            # Wir nehmen den ersten gefundenen Typ (falls mehrere da sind, reicht einer f√ºrs Schema)\n",
    "            entity_types[s] = shorten_uri(t, graph)\n",
    "\n",
    "    # Liste der Klassen f√ºr den Prompt\n",
    "    unique_classes = sorted(list(set(entity_types.values())))\n",
    "    \n",
    "    # 2. Beziehungen (op_) und Attribute (dp_) scannen\n",
    "    relations = set()\n",
    "    attributes = set()\n",
    "    \n",
    "    # Iteriere √ºber ALLE Tripel im Graph (sehr schnell in Python)\n",
    "    for s, p, o in graph:\n",
    "        p_str = str(p)\n",
    "        \n",
    "        # Fall A: Object Property (op_)\n",
    "        if \"op_\" in p_str and s in entity_types:\n",
    "            # F√ºr Relations brauchen wir auch den Typ des Objekts\n",
    "            if o in entity_types:\n",
    "                s_type = entity_types[s]\n",
    "                o_type = entity_types[o]\n",
    "                p_short = shorten_uri(p, graph)\n",
    "                relations.add(f\"{s_type} --[{p_short}]--> {o_type}\")\n",
    "                \n",
    "        # Fall B: Data Property (dp_)\n",
    "        elif \"dp_\" in p_str and s in entity_types:\n",
    "            s_type = entity_types[s]\n",
    "            p_short = shorten_uri(p, graph)\n",
    "            attributes.add((s_type, p_short))\n",
    "\n",
    "    # --- Ausgabe zusammenbauen ---\n",
    "    schema_parts = []\n",
    "    \n",
    "    schema_parts.append(f\"### KLASSEN:\\n\" + \", \".join(unique_classes))\n",
    "    \n",
    "    schema_parts.append(\"\\n### BEZIEHUNGEN (Struktur):\")\n",
    "    schema_parts.append(\"Format: SubjektKlasse --[Relation]--> ObjektKlasse\")\n",
    "    schema_parts.append(\"\\n\".join(sorted(list(relations))))\n",
    "    \n",
    "    schema_parts.append(\"\\n### ATTRIBUTE (Daten):\")\n",
    "    # Attribute gruppieren\n",
    "    attr_dict = {}\n",
    "    for c, p in attributes:\n",
    "        if c not in attr_dict: attr_dict[c] = []\n",
    "        attr_dict[c].append(p)\n",
    "        \n",
    "    attr_lines = []\n",
    "    for c in sorted(attr_dict.keys()):\n",
    "        attr_lines.append(f\"\\n{c}:\")\n",
    "        for p in sorted(attr_dict[c]):\n",
    "             attr_lines.append(f\"  - {p}\")\n",
    "             \n",
    "    schema_parts.append(\"\\n\".join(attr_lines))\n",
    "\n",
    "    return \"\\n\".join(schema_parts)\n",
    "\n",
    "# Ausf√ºhren\n",
    "kg_schema_context = get_kg_schema_fast(g)\n",
    "\n",
    "print(\"--- Extrahiertes Schema (Fast Python Version) ---\")\n",
    "print(kg_schema_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c4abc",
   "metadata": {},
   "source": [
    "## (4) SPARQL Helper (RDFLib)\n",
    "\n",
    "- Nur **SELECT** erlauben  \n",
    "- `LIMIT` automatisch erg√§nzen  \n",
    "- Ergebnis als JSON-Objekt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f24c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Dict\n",
    "\n",
    "DEFAULT_PREFIXES = \"\"\"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX ag:  <http://www.semanticweb.org/AgentProgramParams/>\n",
    "PREFIX dp:  <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
    "PREFIX op:  <http://www.semanticweb.org/AgentProgramParams/op_>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sparql_select_raw(query: str, max_rows: int = 50) -> Dict[str, Any]:\n",
    "    q = query.strip()\n",
    "\n",
    "    # Prefixes auto-inject, falls nicht vorhanden\n",
    "    if \"PREFIX\" not in q.upper():\n",
    "        q = DEFAULT_PREFIXES + \"\\n\" + q\n",
    "\n",
    "    q_lc = q.lower().lstrip()\n",
    "    if \"select\" not in q_lc:\n",
    "        return {\"ok\": False, \"error\": \"Query must contain SELECT.\", \"query\": q}\n",
    "\n",
    "    # Minimal Safety: keine Updates\n",
    "    if \"insert\" in q_lc or \"delete\" in q_lc or \"update\" in q_lc:\n",
    "        return {\"ok\": False, \"error\": \"Only SELECT queries are allowed.\", \"query\": q}\n",
    "\n",
    "    if \"limit\" not in q_lc:\n",
    "        q += f\"\\nLIMIT {max_rows}\"\n",
    "\n",
    "    try:\n",
    "        res = g.query(q)\n",
    "        rows = [dict(r.asdict()) for r in res]\n",
    "        rows = [{k: (str(v) if v is not None else None) for k, v in row.items()} for row in rows]\n",
    "        return {\"ok\": True, \"row_count\": len(rows), \"rows\": rows, \"query\": q}\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"error\": str(e), \"query\": q}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58d575",
   "metadata": {},
   "source": [
    "## (5) Text2SPARQL (Gemini)\n",
    "\n",
    "Hier erzeugt Gemini **nur** die SPARQL SELECT Query.\n",
    "\n",
    "Wichtig:\n",
    "- Das LLM soll **nichts erkl√§ren**\n",
    "- Es soll **nur** die Query zur√ºckgeben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa48caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ZELLE 5 KOMPLETT ERSETZEN (Mit Hierarchie-Optimierung) ===\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "t2s_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Hier injizieren wir das dynamische Schema\n",
    "TEXT2SPARQL_SYSTEM = f\"\"\"Du bist ein Text2SPARQL Generator f√ºr einen PLC Knowledge Graph (RDF).\n",
    "Deine Aufgabe: Wandle die Frage des Users in eine SPARQL SELECT Query um.\n",
    "\n",
    "### SCHEMA INFO (Verf√ºgbare Klassen & Properties):\n",
    "{kg_schema_context}\n",
    "\n",
    "### WICHTIGES DOMAIN-WISSEN:\n",
    "- \"POU\" (Program Organization Unit) ist der Oberbegriff f√ºr **Programme** (ag:class_Program), **Funktionsbausteine** (ag:class_FBType) und Funktionen.\n",
    "- Wenn nach \"POUs\" gefragt wird, suche nach ALLEM, was unter `ag:class_POU` f√§llt.\n",
    "\n",
    "### REGELN:\n",
    "1. Antworte AUSSCHLIESSLICH mit dem SPARQL-Code.\n",
    "2. Nutze IMMER diese Prefixes:\n",
    "   PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "   PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "   PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "   PREFIX ag: <http://www.semanticweb.org/AgentProgramParams/>\n",
    "   PREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
    "   PREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\n",
    "\n",
    "3. **HIERARCHIEN BEACHTEN**:\n",
    "   Wenn nach einer Oberklasse gefragt wird (z.B. POU), nutze den Pfad `a/rdfs:subClassOf*`, um auch alle Unterklassen (Programme, FBs) zu finden.\n",
    "   \n",
    "   Falsch (findet nur Programme):\n",
    "   `?s a ag:class_Program .`\n",
    "   \n",
    "   Richtig (findet alles, was ein POU ist):\n",
    "   `?s a/rdfs:subClassOf* ag:class_POU .`\n",
    "\n",
    "4. Beispiel-Query (Alle POUs finden):\n",
    "   SELECT ?name ?type WHERE {{\n",
    "     ?s a/rdfs:subClassOf* ag:class_POU .\n",
    "     ?s dp:hasPOUName ?name .\n",
    "     ?s a ?type .\n",
    "   }}\n",
    "\"\"\"\n",
    "\n",
    "def text2sparql(question: str) -> str:\n",
    "    msg = [\n",
    "        (\"system\", TEXT2SPARQL_SYSTEM),\n",
    "        (\"user\", question),\n",
    "    ]\n",
    "    try:\n",
    "        response = t2s_llm.invoke(msg)\n",
    "        content = response.content\n",
    "        \n",
    "        final_text = str(content).strip()\n",
    "        final_text = final_text.replace(\"```sparql\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        return final_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error calling OpenAI: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6336f8",
   "metadata": {},
   "source": [
    "## (6) Ausf√ºhren: Query drucken + Tabelle anzeigen\n",
    "\n",
    "Ausgabe:\n",
    "1) **nur** die SPARQL Query (print)  \n",
    "2) **wenn vorhanden**: Tabelle als DataFrame (keine weitere Erkl√§rung)\n",
    "\n",
    "Wenn keine Zeilen gefunden werden: nur Query wird gedruckt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a829a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Frage: Welche POUs ruft 'HRL_SkillSet' auf?\n",
      "\n",
      "üîç Generierte SPARQL Query:\n",
      "----------------------------------------\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
      "PREFIX ag: <http://www.semanticweb.org/AgentProgramParams/>\n",
      "PREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
      "PREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\n",
      "\n",
      "SELECT ?pouName ?pouType WHERE {\n",
      "  ?pouCall op:hasCallerVariable ?variable .\n",
      "  ?variable dp:hasVariableName \"HRL_SkillSet\" .\n",
      "  ?pouCall op:callsPOU ?pou .\n",
      "  ?pou a/rdfs:subClassOf* ag:class_POU .\n",
      "  ?pou dp:hasPOUName ?pouName .\n",
      "  ?pou a ?pouType .\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "‚ö†Ô∏è Keine Ergebnisse gefunden.\n"
     ]
    }
   ],
   "source": [
    "# === ZELLE 6 / 16 (Ausf√ºhrung) ===\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# === Pandas Optionen f√ºr vollst√§ndige Anzeige ===\n",
    "pd.set_option('display.max_rows', None)      # Alle Zeilen anzeigen\n",
    "pd.set_option('display.max_columns', None)   # Alle Spalten anzeigen\n",
    "pd.set_option('display.max_colwidth', None)  # Inhalt in Zellen nicht abschneiden\n",
    "pd.set_option('display.width', 1000)         # Breite der Ausgabe erh√∂hen\n",
    "\n",
    "def run_text2sparql(question: str, max_rows: int = 50):\n",
    "    print(f\"‚ùì Frage: {question}\\n\")\n",
    "    \n",
    "    # 1. Query generieren\n",
    "    query_raw = text2sparql(question)\n",
    "    \n",
    "    # 2. Bereinigung: Markdown-Code-Bl√∂cke entfernen\n",
    "    # Manche Modelle liefern ```sparql ... ```\n",
    "    query = query_raw.replace(\"```sparql\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    print(\"üîç Generierte SPARQL Query:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(query)\n",
    "    print(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "    # 3. Ausf√ºhren\n",
    "    result = sparql_select_raw(query, max_rows=max_rows)\n",
    "    \n",
    "    if not result.get(\"ok\"):\n",
    "        print(f\"‚ùå Fehler bei der Ausf√ºhrung: {result.get('error')}\")\n",
    "        # Debugging: Zeige was schief lief, falls die Query komisch aussieht\n",
    "        # print(f\"Query war: {query}\")\n",
    "        return None\n",
    "\n",
    "    if result.get(\"row_count\", 0) == 0:\n",
    "        print(\"‚ö†Ô∏è Keine Ergebnisse gefunden.\")\n",
    "        return None\n",
    "\n",
    "    # 4. Ergebnis anzeigen\n",
    "    df = pd.DataFrame(result[\"rows\"])\n",
    "    print(f\"‚úÖ {len(df)} Ergebnisse gefunden:\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "# Test:\n",
    "run_text2sparql(\"Welche POUs ruft 'HRL_SkillSet' auf?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619670fd",
   "metadata": {},
   "source": [
    "Test Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fb7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ZELLE 7 / 16 (LangChain GraphSparqlQAChain) ===\n",
    "\n",
    "# Falls noch nicht installiert:\n",
    "try:\n",
    "    from langchain_community.chains.graph_qa.sparql import GraphSparqlQAChain\n",
    "    from langchain_community.graphs import RdfGraph\n",
    "except ImportError:\n",
    "    !pip install -U langchain langchain-community\n",
    "    from langchain_community.chains.graph_qa.sparql import GraphSparqlQAChain\n",
    "    from langchain_community.graphs import RdfGraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4e241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphSparqlQAChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Welche POUs ruft 'HRL_SkillSet' auf?\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"prompt\": \"Welche POUs ruft 'HRL_SkillSet' auf?\"\n",
      "}\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTask: Identify the intent of a prompt and return the appropriate SPARQL query type.\n",
      "You are an assistant that distinguishes different types of prompts and returns the corresponding SPARQL query types.\n",
      "Consider only the following query types:\n",
      "* SELECT: this query type corresponds to questions\n",
      "* UPDATE: this query type corresponds to all requests for deleting, inserting, or changing triples\n",
      "Note: Be as concise as possible.\n",
      "Do not include any explanations or apologies in your responses.\n",
      "Do not respond to any questions that ask for anything else than for you to identify a SPARQL query type.\n",
      "Do not include any unnecessary whitespaces or any text except the query type, i.e., either return 'SELECT' or 'UPDATE'.\n",
      "\n",
      "The prompt is:\n",
      "Welche POUs ruft 'HRL_SkillSet' auf?\n",
      "Helpful Answer:\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Task: Identify the intent of a prompt and return the appropriate SPARQL query type.\\nYou are an assistant that distinguishes different types of prompts and returns the corresponding SPARQL query types.\\nConsider only the following query types:\\n* SELECT: this query type corresponds to questions\\n* UPDATE: this query type corresponds to all requests for deleting, inserting, or changing triples\\nNote: Be as concise as possible.\\nDo not include any explanations or apologies in your responses.\\nDo not respond to any questions that ask for anything else than for you to identify a SPARQL query type.\\nDo not include any unnecessary whitespaces or any text except the query type, i.e., either return 'SELECT' or 'UPDATE'.\\n\\nThe prompt is:\\nWelche POUs ruft 'HRL_SkillSet' auf?\\nHelpful Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain > llm:ChatOpenAI] [1.40s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"SELECT\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"SELECT\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 1,\n",
      "                \"prompt_tokens\": 171,\n",
      "                \"total_tokens\": 172,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_provider\": \"openai\",\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_8bbc38b4db\",\n",
      "              \"id\": \"chatcmpl-D0LkuQsqNwO5coL0HRWURYM8Sbr9p\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"lc_run--019bdf2f-9e3e-7ae0-9a79-bd8f42d9ed0f-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 171,\n",
      "              \"output_tokens\": 1,\n",
      "              \"total_tokens\": 172,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 1,\n",
      "      \"prompt_tokens\": 171,\n",
      "      \"total_tokens\": 172,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_8bbc38b4db\",\n",
      "    \"id\": \"chatcmpl-D0LkuQsqNwO5coL0HRWURYM8Sbr9p\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain] [1.40s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"SELECT\"\n",
      "}\n",
      "Identified intent:\n",
      "\u001b[32;1m\u001b[1;3mSELECT\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"prompt\": \"Welche POUs ruft 'HRL_SkillSet' auf?\",\n",
      "  \"schema\": \"In the following, each IRI is followed by the local name and optionally its description in parentheses. \\nThe RDF graph supports the following node types:\\n<http://www.w3.org/2002/07/owl#Ontology> (Ontology, None), <http://www.semanticweb.org/AgentProgramParams/class_GlobalVariableList> (class_GlobalVariableList, None), <http://www.semanticweb.org/AgentProgramParams/class_PLCProject> (class_PLCProject, None), <http://www.semanticweb.org/AgentProgramParams/class_FBType> (class_FBType, None), <http://www.semanticweb.org/AgentProgramParams/class_StandardFBType> (class_StandardFBType, None), <http://www.w3.org/2002/07/owl#NamedIndividual> (NamedIndividual, None), <http://www.w3.org/2002/07/owl#Class> (Class, None), <http://www.w3.org/2002/07/owl#DatatypeProperty> (DatatypeProperty, None), <http://www.w3.org/2000/01/rdf-schema#Datatype> (Datatype, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#List> (List, None), <http://www.w3.org/2002/07/owl#ObjectProperty> (ObjectProperty, None), <http://www.semanticweb.org/AgentProgramParams/class_ParameterAssignment> (class_ParameterAssignment, None), <http://www.semanticweb.org/AgentProgramParams/class_FBInstance> (class_FBInstance, None), <http://www.semanticweb.org/AgentProgramParams/class_Variable> (class_Variable, None), <http://www.semanticweb.org/AgentProgramParams/class_IOChannel> (class_IOChannel, None), <http://www.semanticweb.org/AgentProgramParams/class_POUCall> (class_POUCall, None), <http://www.semanticweb.org/AgentProgramParams/class_PortInstance> (class_PortInstance, None), <http://www.semanticweb.org/AgentProgramParams/class_SignalSource> (class_SignalSource, None), <http://www.semanticweb.org/AgentProgramParams/class_Port> (class_Port, None), <http://www.semanticweb.org/AgentProgramParams/class_Program> (class_Program, None)\\nThe RDF graph supports the following relationships:\\n<http://www.w3.org/1999/02/22-rdf-syntax-ns#type> (type, None), <http://www.semanticweb.org/AgentProgramParams/op_hasAssignment> (op_hasAssignment, None), <http://www.semanticweb.org/AgentProgramParams/op_usesVariable> (op_usesVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableName> (dp_hasVariableName, None), <http://www.semanticweb.org/AgentProgramParams/op_hasPort> (op_hasPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortName> (dp_hasPortName, None), <http://www.semanticweb.org/AgentProgramParams/op_hasInternalVariable> (op_hasInternalVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableType> (dp_hasVariableType, None), <http://www.semanticweb.org/AgentProgramParams/op_assignsToPort> (op_assignsToPort, # 1. Wohin geht das Signal? (Zum Port \\\"CLK\\\" definiert im Typ R_TRIG)), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortType> (dp_hasPortType, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasHardwareAddress> (dp_hasHardwareAddress, None), <http://www.semanticweb.org/AgentProgramParams/op_isInstanceOfFBType> (op_isInstanceOfFBType, None), <http://www.semanticweb.org/AgentProgramParams/op_assignsFrom> (op_assignsFrom, # 2. Woher kommt das Signal? Hier ist die Signal-Quelle bei Funktionsaufruf), <http://www.semanticweb.org/AgentProgramParams/op_callsPOU> (op_callsPOU, None), <http://www.semanticweb.org/AgentProgramParams/op_implementsPort> (op_implementsPort, Verbindet eine interne Variable eines FBs mit dem Port, den sie repr√§sentiert), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortDirection> (dp_hasPortDirection, None), <http://www.semanticweb.org/AgentProgramParams/dp_isUnusedVar> (dp_isUnusedVar, None), <http://www.semanticweb.org/AgentProgramParams/op_representsFBInstance> (op_representsFBInstance, None), <http://www.semanticweb.org/AgentProgramParams/op_isBoundToChannel> (op_isBoundToChannel, None), <http://www.semanticweb.org/AgentProgramParams/op_hasCallerVariable> (op_hasCallerVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUCode> (dp_hasPOUCode, None), <http://www.semanticweb.org/AgentProgramParams/op_listsGlobalVariable> (op_listsGlobalVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUName> (dp_hasPOUName, None), <http://www.semanticweb.org/AgentProgramParams/op_containsPOUCall> (op_containsPOUCall, None), <http://www.semanticweb.org/AgentProgramParams/op_instantiatesPort> (op_instantiatesPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasInitialValue> (dp_hasInitialValue, None), <http://www.w3.org/2000/01/rdf-schema#subClassOf> (subClassOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_isUnusedPort> (dp_isUnusedPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOULanguage> (dp_hasPOULanguage, None), <http://www.semanticweb.org/AgentProgramParams/dp_ioRawXml> (dp_ioRawXml, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasConsistencyReport> (dp_hasConsistencyReport, None), <http://www.w3.org/2000/01/rdf-schema#range> (range, None), <http://www.semanticweb.org/AgentProgramParams/op_consistsOfPOU> (op_consistsOfPOU, None), <http://www.w3.org/2000/01/rdf-schema#domain> (domain, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasGlobalVariableListName> (dp_hasGlobalVariableListName, None), <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> (subPropertyOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUType> (dp_hasPOUType, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#rest> (rest, None), <http://www.semanticweb.org/AgentProgramParams/op_isPortOfInstance> (op_isPortOfInstance, None), <http://www.w3.org/2000/01/rdf-schema#comment> (comment, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableScope> (dp_hasVariableScope, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#first> (first, None), <http://www.w3.org/2002/07/owl#oneOf> (oneOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasProgramName> (dp_hasProgramName, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPLCProjectName> (dp_hasPLCProjectName, None)\\n\"\n",
      "}\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTask: Generate a SPARQL SELECT statement for querying a graph database.\n",
      "For instance, to find all email addresses of John Doe, the following query in backticks would be suitable:\n",
      "```\n",
      "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
      "SELECT ?email\n",
      "WHERE {\n",
      "    ?person foaf:name \"John Doe\" .\n",
      "    ?person foaf:mbox ?email .\n",
      "}\n",
      "```\n",
      "Instructions:\n",
      "Use only the node types and properties provided in the schema.\n",
      "Do not use any node types and properties that are not explicitly provided.\n",
      "Include all necessary prefixes.\n",
      "Schema:\n",
      "In the following, each IRI is followed by the local name and optionally its description in parentheses. \n",
      "The RDF graph supports the following node types:\n",
      "<http://www.w3.org/2002/07/owl#Ontology> (Ontology, None), <http://www.semanticweb.org/AgentProgramParams/class_GlobalVariableList> (class_GlobalVariableList, None), <http://www.semanticweb.org/AgentProgramParams/class_PLCProject> (class_PLCProject, None), <http://www.semanticweb.org/AgentProgramParams/class_FBType> (class_FBType, None), <http://www.semanticweb.org/AgentProgramParams/class_StandardFBType> (class_StandardFBType, None), <http://www.w3.org/2002/07/owl#NamedIndividual> (NamedIndividual, None), <http://www.w3.org/2002/07/owl#Class> (Class, None), <http://www.w3.org/2002/07/owl#DatatypeProperty> (DatatypeProperty, None), <http://www.w3.org/2000/01/rdf-schema#Datatype> (Datatype, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#List> (List, None), <http://www.w3.org/2002/07/owl#ObjectProperty> (ObjectProperty, None), <http://www.semanticweb.org/AgentProgramParams/class_ParameterAssignment> (class_ParameterAssignment, None), <http://www.semanticweb.org/AgentProgramParams/class_FBInstance> (class_FBInstance, None), <http://www.semanticweb.org/AgentProgramParams/class_Variable> (class_Variable, None), <http://www.semanticweb.org/AgentProgramParams/class_IOChannel> (class_IOChannel, None), <http://www.semanticweb.org/AgentProgramParams/class_POUCall> (class_POUCall, None), <http://www.semanticweb.org/AgentProgramParams/class_PortInstance> (class_PortInstance, None), <http://www.semanticweb.org/AgentProgramParams/class_SignalSource> (class_SignalSource, None), <http://www.semanticweb.org/AgentProgramParams/class_Port> (class_Port, None), <http://www.semanticweb.org/AgentProgramParams/class_Program> (class_Program, None)\n",
      "The RDF graph supports the following relationships:\n",
      "<http://www.w3.org/1999/02/22-rdf-syntax-ns#type> (type, None), <http://www.semanticweb.org/AgentProgramParams/op_hasAssignment> (op_hasAssignment, None), <http://www.semanticweb.org/AgentProgramParams/op_usesVariable> (op_usesVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableName> (dp_hasVariableName, None), <http://www.semanticweb.org/AgentProgramParams/op_hasPort> (op_hasPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortName> (dp_hasPortName, None), <http://www.semanticweb.org/AgentProgramParams/op_hasInternalVariable> (op_hasInternalVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableType> (dp_hasVariableType, None), <http://www.semanticweb.org/AgentProgramParams/op_assignsToPort> (op_assignsToPort, # 1. Wohin geht das Signal? (Zum Port \"CLK\" definiert im Typ R_TRIG)), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortType> (dp_hasPortType, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasHardwareAddress> (dp_hasHardwareAddress, None), <http://www.semanticweb.org/AgentProgramParams/op_isInstanceOfFBType> (op_isInstanceOfFBType, None), <http://www.semanticweb.org/AgentProgramParams/op_assignsFrom> (op_assignsFrom, # 2. Woher kommt das Signal? Hier ist die Signal-Quelle bei Funktionsaufruf), <http://www.semanticweb.org/AgentProgramParams/op_callsPOU> (op_callsPOU, None), <http://www.semanticweb.org/AgentProgramParams/op_implementsPort> (op_implementsPort, Verbindet eine interne Variable eines FBs mit dem Port, den sie repr√§sentiert), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortDirection> (dp_hasPortDirection, None), <http://www.semanticweb.org/AgentProgramParams/dp_isUnusedVar> (dp_isUnusedVar, None), <http://www.semanticweb.org/AgentProgramParams/op_representsFBInstance> (op_representsFBInstance, None), <http://www.semanticweb.org/AgentProgramParams/op_isBoundToChannel> (op_isBoundToChannel, None), <http://www.semanticweb.org/AgentProgramParams/op_hasCallerVariable> (op_hasCallerVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUCode> (dp_hasPOUCode, None), <http://www.semanticweb.org/AgentProgramParams/op_listsGlobalVariable> (op_listsGlobalVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUName> (dp_hasPOUName, None), <http://www.semanticweb.org/AgentProgramParams/op_containsPOUCall> (op_containsPOUCall, None), <http://www.semanticweb.org/AgentProgramParams/op_instantiatesPort> (op_instantiatesPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasInitialValue> (dp_hasInitialValue, None), <http://www.w3.org/2000/01/rdf-schema#subClassOf> (subClassOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_isUnusedPort> (dp_isUnusedPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOULanguage> (dp_hasPOULanguage, None), <http://www.semanticweb.org/AgentProgramParams/dp_ioRawXml> (dp_ioRawXml, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasConsistencyReport> (dp_hasConsistencyReport, None), <http://www.w3.org/2000/01/rdf-schema#range> (range, None), <http://www.semanticweb.org/AgentProgramParams/op_consistsOfPOU> (op_consistsOfPOU, None), <http://www.w3.org/2000/01/rdf-schema#domain> (domain, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasGlobalVariableListName> (dp_hasGlobalVariableListName, None), <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> (subPropertyOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUType> (dp_hasPOUType, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#rest> (rest, None), <http://www.semanticweb.org/AgentProgramParams/op_isPortOfInstance> (op_isPortOfInstance, None), <http://www.w3.org/2000/01/rdf-schema#comment> (comment, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableScope> (dp_hasVariableScope, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#first> (first, None), <http://www.w3.org/2002/07/owl#oneOf> (oneOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasProgramName> (dp_hasProgramName, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPLCProjectName> (dp_hasPLCProjectName, None)\n",
      "\n",
      "Note: Be as concise as possible.\n",
      "Do not include any explanations or apologies in your responses.\n",
      "Do not respond to any questions that ask for anything else than for you to construct a SPARQL query.\n",
      "Do not include any text except the SPARQL query generated.\n",
      "\n",
      "The question is:\n",
      "Welche POUs ruft 'HRL_SkillSet' auf?\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Task: Generate a SPARQL SELECT statement for querying a graph database.\\nFor instance, to find all email addresses of John Doe, the following query in backticks would be suitable:\\n```\\nPREFIX foaf: <http://xmlns.com/foaf/0.1/>\\nSELECT ?email\\nWHERE {\\n    ?person foaf:name \\\"John Doe\\\" .\\n    ?person foaf:mbox ?email .\\n}\\n```\\nInstructions:\\nUse only the node types and properties provided in the schema.\\nDo not use any node types and properties that are not explicitly provided.\\nInclude all necessary prefixes.\\nSchema:\\nIn the following, each IRI is followed by the local name and optionally its description in parentheses. \\nThe RDF graph supports the following node types:\\n<http://www.w3.org/2002/07/owl#Ontology> (Ontology, None), <http://www.semanticweb.org/AgentProgramParams/class_GlobalVariableList> (class_GlobalVariableList, None), <http://www.semanticweb.org/AgentProgramParams/class_PLCProject> (class_PLCProject, None), <http://www.semanticweb.org/AgentProgramParams/class_FBType> (class_FBType, None), <http://www.semanticweb.org/AgentProgramParams/class_StandardFBType> (class_StandardFBType, None), <http://www.w3.org/2002/07/owl#NamedIndividual> (NamedIndividual, None), <http://www.w3.org/2002/07/owl#Class> (Class, None), <http://www.w3.org/2002/07/owl#DatatypeProperty> (DatatypeProperty, None), <http://www.w3.org/2000/01/rdf-schema#Datatype> (Datatype, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#List> (List, None), <http://www.w3.org/2002/07/owl#ObjectProperty> (ObjectProperty, None), <http://www.semanticweb.org/AgentProgramParams/class_ParameterAssignment> (class_ParameterAssignment, None), <http://www.semanticweb.org/AgentProgramParams/class_FBInstance> (class_FBInstance, None), <http://www.semanticweb.org/AgentProgramParams/class_Variable> (class_Variable, None), <http://www.semanticweb.org/AgentProgramParams/class_IOChannel> (class_IOChannel, None), <http://www.semanticweb.org/AgentProgramParams/class_POUCall> (class_POUCall, None), <http://www.semanticweb.org/AgentProgramParams/class_PortInstance> (class_PortInstance, None), <http://www.semanticweb.org/AgentProgramParams/class_SignalSource> (class_SignalSource, None), <http://www.semanticweb.org/AgentProgramParams/class_Port> (class_Port, None), <http://www.semanticweb.org/AgentProgramParams/class_Program> (class_Program, None)\\nThe RDF graph supports the following relationships:\\n<http://www.w3.org/1999/02/22-rdf-syntax-ns#type> (type, None), <http://www.semanticweb.org/AgentProgramParams/op_hasAssignment> (op_hasAssignment, None), <http://www.semanticweb.org/AgentProgramParams/op_usesVariable> (op_usesVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableName> (dp_hasVariableName, None), <http://www.semanticweb.org/AgentProgramParams/op_hasPort> (op_hasPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortName> (dp_hasPortName, None), <http://www.semanticweb.org/AgentProgramParams/op_hasInternalVariable> (op_hasInternalVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableType> (dp_hasVariableType, None), <http://www.semanticweb.org/AgentProgramParams/op_assignsToPort> (op_assignsToPort, # 1. Wohin geht das Signal? (Zum Port \\\"CLK\\\" definiert im Typ R_TRIG)), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortType> (dp_hasPortType, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasHardwareAddress> (dp_hasHardwareAddress, None), <http://www.semanticweb.org/AgentProgramParams/op_isInstanceOfFBType> (op_isInstanceOfFBType, None), <http://www.semanticweb.org/AgentProgramParams/op_assignsFrom> (op_assignsFrom, # 2. Woher kommt das Signal? Hier ist die Signal-Quelle bei Funktionsaufruf), <http://www.semanticweb.org/AgentProgramParams/op_callsPOU> (op_callsPOU, None), <http://www.semanticweb.org/AgentProgramParams/op_implementsPort> (op_implementsPort, Verbindet eine interne Variable eines FBs mit dem Port, den sie repr√§sentiert), <http://www.semanticweb.org/AgentProgramParams/dp_hasPortDirection> (dp_hasPortDirection, None), <http://www.semanticweb.org/AgentProgramParams/dp_isUnusedVar> (dp_isUnusedVar, None), <http://www.semanticweb.org/AgentProgramParams/op_representsFBInstance> (op_representsFBInstance, None), <http://www.semanticweb.org/AgentProgramParams/op_isBoundToChannel> (op_isBoundToChannel, None), <http://www.semanticweb.org/AgentProgramParams/op_hasCallerVariable> (op_hasCallerVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUCode> (dp_hasPOUCode, None), <http://www.semanticweb.org/AgentProgramParams/op_listsGlobalVariable> (op_listsGlobalVariable, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUName> (dp_hasPOUName, None), <http://www.semanticweb.org/AgentProgramParams/op_containsPOUCall> (op_containsPOUCall, None), <http://www.semanticweb.org/AgentProgramParams/op_instantiatesPort> (op_instantiatesPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasInitialValue> (dp_hasInitialValue, None), <http://www.w3.org/2000/01/rdf-schema#subClassOf> (subClassOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_isUnusedPort> (dp_isUnusedPort, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOULanguage> (dp_hasPOULanguage, None), <http://www.semanticweb.org/AgentProgramParams/dp_ioRawXml> (dp_ioRawXml, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasConsistencyReport> (dp_hasConsistencyReport, None), <http://www.w3.org/2000/01/rdf-schema#range> (range, None), <http://www.semanticweb.org/AgentProgramParams/op_consistsOfPOU> (op_consistsOfPOU, None), <http://www.w3.org/2000/01/rdf-schema#domain> (domain, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasGlobalVariableListName> (dp_hasGlobalVariableListName, None), <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> (subPropertyOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPOUType> (dp_hasPOUType, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#rest> (rest, None), <http://www.semanticweb.org/AgentProgramParams/op_isPortOfInstance> (op_isPortOfInstance, None), <http://www.w3.org/2000/01/rdf-schema#comment> (comment, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasVariableScope> (dp_hasVariableScope, None), <http://www.w3.org/1999/02/22-rdf-syntax-ns#first> (first, None), <http://www.w3.org/2002/07/owl#oneOf> (oneOf, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasProgramName> (dp_hasProgramName, None), <http://www.semanticweb.org/AgentProgramParams/dp_hasPLCProjectName> (dp_hasPLCProjectName, None)\\n\\nNote: Be as concise as possible.\\nDo not include any explanations or apologies in your responses.\\nDo not respond to any questions that ask for anything else than for you to construct a SPARQL query.\\nDo not include any text except the SPARQL query generated.\\n\\nThe question is:\\nWelche POUs ruft 'HRL_SkillSet' auf?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain > llm:ChatOpenAI] [4.10s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\\nPREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\\n\\nSELECT ?pou\\nWHERE {\\n    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\\nPREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\\n\\nSELECT ?pou\\nWHERE {\\n    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 99,\n",
      "                \"prompt_tokens\": 1900,\n",
      "                \"total_tokens\": 1999,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_provider\": \"openai\",\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_29330a9688\",\n",
      "              \"id\": \"chatcmpl-D0LkvmpZcWyTppAoJnFSMYFToyhtm\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"lc_run--019bdf2f-a3bb-74b2-b880-19a7cc32e865-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1900,\n",
      "              \"output_tokens\": 99,\n",
      "              \"total_tokens\": 1999,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 99,\n",
      "      \"prompt_tokens\": 1900,\n",
      "      \"total_tokens\": 1999,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_29330a9688\",\n",
      "    \"id\": \"chatcmpl-D0LkvmpZcWyTppAoJnFSMYFToyhtm\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain] [4.10s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\\nPREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\\n\\nSELECT ?pou\\nWHERE {\\n    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\\n}\\n```\"\n",
      "}\n",
      "Generated SPARQL:\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\n",
      "PREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
      "\n",
      "SELECT ?pou\n",
      "WHERE {\n",
      "    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\n",
      "}\n",
      "```\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"prompt\": \"Welche POUs ruft 'HRL_SkillSet' auf?\",\n",
      "  \"context\": []\n",
      "}\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTask: Generate a natural language response from the results of a SPARQL query.\n",
      "You are an assistant that creates well-written and human understandable answers.\n",
      "The information part contains the information provided, which you can use to construct an answer.\n",
      "The information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
      "Make your response sound like the information is coming from an AI assistant, but don't add any information.\n",
      "Information:\n",
      "[]\n",
      "\n",
      "Question: Welche POUs ruft 'HRL_SkillSet' auf?\n",
      "Helpful Answer:\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Task: Generate a natural language response from the results of a SPARQL query.\\nYou are an assistant that creates well-written and human understandable answers.\\nThe information part contains the information provided, which you can use to construct an answer.\\nThe information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake your response sound like the information is coming from an AI assistant, but don't add any information.\\nInformation:\\n[]\\n\\nQuestion: Welche POUs ruft 'HRL_SkillSet' auf?\\nHelpful Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain > llm:ChatOpenAI] [1.36s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Es sind keine Informationen zu den POUs, die von 'HRL_SkillSet' aufgerufen werden, verf√ºgbar.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Es sind keine Informationen zu den POUs, die von 'HRL_SkillSet' aufgerufen werden, verf√ºgbar.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 24,\n",
      "                \"prompt_tokens\": 118,\n",
      "                \"total_tokens\": 142,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_provider\": \"openai\",\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_c4585b5b9c\",\n",
      "              \"id\": \"chatcmpl-D0Lkz1KLRNYbTRJQoKml8UbtoQNcW\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"lc_run--019bdf2f-b3c3-7461-9225-987ed069b2e4-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 118,\n",
      "              \"output_tokens\": 24,\n",
      "              \"total_tokens\": 142,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 24,\n",
      "      \"prompt_tokens\": 118,\n",
      "      \"total_tokens\": 142,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_c4585b5b9c\",\n",
      "    \"id\": \"chatcmpl-D0Lkz1KLRNYbTRJQoKml8UbtoQNcW\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain > chain:LLMChain] [1.37s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Es sind keine Informationen zu den POUs, die von 'HRL_SkillSet' aufgerufen werden, verf√ºgbar.\"\n",
      "}\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:GraphSparqlQAChain] [6.88s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"Es sind keine Informationen zu den POUs, die von 'HRL_SkillSet' aufgerufen werden, verf√ºgbar.\",\n",
      "  \"sparql_query\": \"```\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\\nPREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\\n\\nSELECT ?pou\\nWHERE {\\n    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\\n}\\n```\"\n",
      "}\n",
      "\n",
      "--- SPARQL (raw) ---\n",
      "```\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\n",
      "PREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
      "\n",
      "SELECT ?pou\n",
      "WHERE {\n",
      "    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\n",
      "}\n",
      "```\n",
      "\n",
      "--- SPARQL (clean) ---\n",
      "\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX op: <http://www.semanticweb.org/AgentProgramParams/op_>\n",
      "PREFIX dp: <http://www.semanticweb.org/AgentProgramParams/dp_>\n",
      "\n",
      "SELECT ?pou\n",
      "WHERE {\n",
      "    ?pou op:callsPOU <http://www.semanticweb.org/AgentProgramParams/HRL_SkillSet> .\n",
      "}\n",
      "\n",
      "\n",
      "--- Antwort ---\n",
      "Es sind keine Informationen zu den POUs, die von 'HRL_SkillSet' aufgerufen werden, verf√ºgbar.\n"
     ]
    }
   ],
   "source": [
    "# === FIX ZELLE: GraphSparqlQAChain ohne Backticks + Debug/Steps ===\n",
    "\n",
    "from langchain_community.chains.graph_qa.sparql import GraphSparqlQAChain\n",
    "from langchain_community.graphs import RdfGraph\n",
    "\n",
    "# Wichtig: entfernt ```sparql ... ``` oder <sparql>...</sparql>\n",
    "from langchain_community.chains.graph_qa.neptune_sparql import extract_sparql\n",
    "\n",
    "# Debug / Zwischensteps\n",
    "from langchain_core.callbacks.stdout import StdOutCallbackHandler\n",
    "from langchain_core.globals import set_debug, set_verbose\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)\n",
    "\n",
    "# 1) RDF Graph laden\n",
    "lc_graph = RdfGraph(\n",
    "    source_file=TTL_PATH,\n",
    "    serialization=\"ttl\",\n",
    "    standard=\"rdf\",\n",
    ")\n",
    "lc_graph.load_schema()\n",
    "\n",
    "# 2) Monkey-Patch: vor jeder Query automatisch Code-Fences entfernen\n",
    "_orig_query = lc_graph.query\n",
    "\n",
    "def _clean_query(q: str):\n",
    "    q_clean = extract_sparql(q)\n",
    "    return _orig_query(q_clean)\n",
    "\n",
    "lc_graph.query = _clean_query\n",
    "\n",
    "# 3) Chain bauen (verbose=True zeigt SPARQL + Context-Ausgabe)\n",
    "graph_chain = GraphSparqlQAChain.from_llm(\n",
    "    llm=llm_for_chain,\n",
    "    graph=lc_graph,\n",
    "    return_sparql_query=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 4) Call mit Callback (zeigt Prompts/Outputs live)\n",
    "question = \"Welche POUs ruft 'HRL_SkillSet' auf?\"\n",
    "\n",
    "out = graph_chain.invoke(\n",
    "    {\"query\": question},\n",
    "    config={\"callbacks\": [StdOutCallbackHandler()]}\n",
    ")\n",
    "\n",
    "print(\"\\n--- SPARQL (raw) ---\")\n",
    "print(out.get(\"sparql_query\", \"\"))\n",
    "\n",
    "print(\"\\n--- SPARQL (clean) ---\")\n",
    "print(extract_sparql(out.get(\"sparql_query\", \"\")))\n",
    "\n",
    "print(\"\\n--- Antwort ---\")\n",
    "print(out.get(\"result\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1f4820",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "Expected {SelectQuery | ConstructQuery | DescribeQuery | AskQuery}, found '`'  (at char 0), (line:1, col:1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParseException\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Test:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43mrun_graphsparql_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWelche POUs ruft \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mHRL_SkillSet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m auf?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mrun_graphsparql_chain\u001b[39m\u001b[34m(question, max_rows, show_llm_answer)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_graphsparql_chain\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m, max_rows: \u001b[38;5;28mint\u001b[39m = \u001b[32m30\u001b[39m, show_llm_answer: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     35\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m    1) erzeugt SPARQL via GraphSparqlQAChain\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m    2) druckt SPARQL\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    3) f√ºhrt SPARQL mit deiner vorhandenen sparql_select_raw(...) aus\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    4) zeigt DataFrame (wenn Ergebnisse existieren)\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     out = \u001b[43mgraph_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     sparql = out.get(\u001b[33m\"\u001b[39m\u001b[33msparql_query\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sparql:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_classic\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    166\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    172\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    173\u001b[39m         inputs,\n\u001b[32m    174\u001b[39m         outputs,\n\u001b[32m    175\u001b[39m         return_only_outputs,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_community\\chains\\graph_qa\\sparql.py:164\u001b[39m, in \u001b[36mGraphSparqlQAChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    159\u001b[39m _run_manager.on_text(\n\u001b[32m    160\u001b[39m     generated_sparql, color=\u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28mself\u001b[39m.verbose\n\u001b[32m    161\u001b[39m )\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m intent == \u001b[33m\"\u001b[39m\u001b[33mSELECT\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     context = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_sparql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     _run_manager.on_text(\u001b[33m\"\u001b[39m\u001b[33mFull Context:\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m    167\u001b[39m     _run_manager.on_text(\n\u001b[32m    168\u001b[39m         \u001b[38;5;28mstr\u001b[39m(context), color=\u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28mself\u001b[39m.verbose\n\u001b[32m    169\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\langchain_community\\graphs\\rdf_graph.py:218\u001b[39m, in \u001b[36mRdfGraph.query\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrdflib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ResultRow\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParserError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated SPARQL statement is invalid\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\rdflib\\graph.py:1742\u001b[39m, in \u001b[36mGraph.query\u001b[39m\u001b[34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[39m\n\u001b[32m   1739\u001b[39m     processor = plugin.get(processor, query.Processor)(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# type error: Argument 1 to \"Result\" has incompatible type \"Mapping[str, Any]\"; expected \"str\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result(\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitBindings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitNs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\rdflib\\plugins\\sparql\\processor.py:144\u001b[39m, in \u001b[36mSPARQLProcessor.query\u001b[39m\u001b[34m(self, strOrQuery, initBindings, initNs, base, DEBUG)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mEvaluate a query with the given initial bindings, and initial\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03mnamespaces. The given base is used to resolve relative URIs in\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    documentation.\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(strOrQuery, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     strOrQuery = translateQuery(\u001b[43mparseQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrOrQuery\u001b[49m\u001b[43m)\u001b[49m, base, initNs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m evalQuery(\u001b[38;5;28mself\u001b[39m.graph, strOrQuery, initBindings, base)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\rdflib\\plugins\\sparql\\parser.py:1553\u001b[39m, in \u001b[36mparseQuery\u001b[39m\u001b[34m(q)\u001b[39m\n\u001b[32m   1550\u001b[39m     q = q.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1552\u001b[39m q = expandUnicodeEscapes(q)\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparseString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparseAll\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\pyparsing\\util.py:436\u001b[39m, in \u001b[36mreplaced_by_pep8.<locals>._inner\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    433\u001b[39m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[32m    434\u001b[39m     \u001b[38;5;66;03m#     f\"Deprecated - use {fn.__name__}\", DeprecationWarning, stacklevel=2\u001b[39;00m\n\u001b[32m    435\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MA_Python_Agent\\.venv311\\Lib\\site-packages\\pyparsing\\core.py:1318\u001b[39m, in \u001b[36mParserElement.parse_string\u001b[39m\u001b[34m(self, instring, parse_all, parseAll)\u001b[39m\n\u001b[32m   1315\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1317\u001b[39m     \u001b[38;5;66;03m# catch and re-raise exception from here, clearing out pyparsing internal stack trace\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1318\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[31mParseException\u001b[39m: Expected {SelectQuery | ConstructQuery | DescribeQuery | AskQuery}, found '`'  (at char 0), (line:1, col:1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) RDF Graph Wrapper (l√§dt die gleiche TTL wie du bereits nutzt)\n",
    "lc_graph = RdfGraph(\n",
    "    source_file=TTL_PATH,\n",
    "    serialization=\"ttl\",\n",
    "    standard=\"rdf\",   # alternativ: \"owl\" wenn du OWL-lastige Ontologien hast\n",
    ")\n",
    "\n",
    "# Optional: Schema laden (kann helfen, wenn get_schema sonst leer bleibt)\n",
    "lc_graph.load_schema()\n",
    "\n",
    "# 2) LLM wiederverwenden (falls t2s_llm schon existiert)\n",
    "try:\n",
    "    llm_for_chain = t2s_llm\n",
    "except NameError:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm_for_chain = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "# 3) GraphSparqlQAChain bauen\n",
    "graph_chain = GraphSparqlQAChain.from_llm(\n",
    "    llm=llm_for_chain,\n",
    "    graph=lc_graph,\n",
    "    return_sparql_query=True,         # damit du die generierte Query bekommst\n",
    "    allow_dangerous_requests=True,    # required Opt-In (LangChain Security)\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "def run_graphsparql_chain(question: str, max_rows: int = 30, show_llm_answer: bool = False):\n",
    "    \"\"\"\n",
    "    1) erzeugt SPARQL via GraphSparqlQAChain\n",
    "    2) druckt SPARQL\n",
    "    3) f√ºhrt SPARQL mit deiner vorhandenen sparql_select_raw(...) aus\n",
    "    4) zeigt DataFrame (wenn Ergebnisse existieren)\n",
    "    \"\"\"\n",
    "\n",
    "    out = graph_chain.invoke({\"query\": question})\n",
    "\n",
    "    sparql = out.get(\"sparql_query\", \"\").strip()\n",
    "    if sparql:\n",
    "        print(\"üîç Generierte SPARQL Query:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(sparql)\n",
    "        print(\"-\" * 40 + \"\\n\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Keine SPARQL Query erzeugt.\")\n",
    "        return out\n",
    "\n",
    "    # Ergebnis als Tabelle (√ºber deine bestehende rdflib-Ausf√ºhrung)\n",
    "    if \"sparql_select_raw\" in globals():\n",
    "        result = sparql_select_raw(sparql, max_rows=max_rows)\n",
    "\n",
    "        if not result.get(\"ok\"):\n",
    "            print(f\"‚ùå Fehler bei der Ausf√ºhrung: {result.get('error')}\")\n",
    "            return out\n",
    "\n",
    "        if result.get(\"row_count\", 0) == 0:\n",
    "            print(\"‚ö†Ô∏è Keine Ergebnisse gefunden.\")\n",
    "            return out\n",
    "\n",
    "        df = pd.DataFrame(result[\"rows\"])\n",
    "        print(f\"‚úÖ {len(df)} Ergebnisse gefunden:\")\n",
    "        display(df)\n",
    "\n",
    "    if show_llm_answer:\n",
    "        print(\"\\nüß† LLM Antwort:\")\n",
    "        print(out.get(\"result\", \"\"))\n",
    "\n",
    "    return out\n",
    "\n",
    "# Test:\n",
    "run_graphsparql_chain(\"Welche POUs ruft 'HRL_SkillSet' auf?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
